{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 13:56:22.763409: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 13:56:22.789850: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 13:56:22.789874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 13:56:22.790552: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 13:56:22.794565: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 13:56:22.794990: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 13:56:28.292157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.training.training import train_model, train_and_save, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_distribution = 'distr_mixture_linear'\n",
    "distribution_1 = 'distr_trunc_normal'\n",
    "distribution_2 = 'distr_gev'\n",
    "\n",
    "loss = 'loss_twCRPS_sample' # options: loss_CRPS_sample, loss_twCRPS_sample, loss_log_likelihood\n",
    "\n",
    "chain_function = 'chain_function_normal_cdf' # options: chain_function_normal_cdf, chain_function_indicator, chain_function_normal_cdf_plus_constant\n",
    "chain_function_mean = 13\n",
    "chain_function_std = 1\n",
    "chain_function_threshold = 15 # 12 / 15\n",
    "chain_function_constant = 0.03\n",
    "\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 0.01\n",
    "folds = [1,2]\n",
    "parameter_names = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "neighbourhood_size = 11\n",
    "ignore = ['229', '285', '323']\n",
    "epochs = 600\n",
    "\n",
    "samples = 200\n",
    "printing = True\n",
    "pretrained = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameters for weights in Mixture Linear distribution\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameters for weights in Mixture Linear distribution\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameters for weights in Mixture Linear distribution\n",
      "Final loss:  0.045720592\n",
      "Final loss:  0.04515779\n",
      "Parameter weight_a set to [-0.13286905]\n",
      "Parameter weight_b set to [0.0158399]\n",
      "Parameter a_tn set to [0.7367815]\n",
      "Parameter b_tn set to [0.9479947  0.6162499  0.5342818  0.5219145  0.53897816]\n",
      "Parameter c_tn set to [1.364705]\n",
      "Parameter d_tn set to [1.2372928]\n",
      "Parameter a_gev set to [1.1869228]\n",
      "Parameter b_gev set to [ 0.3407244  -0.46779677 -0.11253756 -0.46143267 -0.46886835]\n",
      "Parameter c_gev set to [0.86535263]\n",
      "Parameter d_gev set to [ 0.15583533 -0.18781212 -0.25093645 -0.24452935 -0.17546563]\n",
      "Parameter e_gev set to [0.1566751]\n",
      "Parameter weight_a set to [-0.1269685]\n",
      "Parameter weight_b set to [-0.09601682]\n",
      "Parameter a_tn set to [0.7977291]\n",
      "Parameter b_tn set to [0.9964004  0.6435493  0.5990086  0.57334673 0.5856986 ]\n",
      "Parameter c_tn set to [1.0936193]\n",
      "Parameter d_tn set to [0.8075267]\n",
      "Parameter a_gev set to [1.323084]\n",
      "Parameter b_gev set to [ 0.5541242  -0.49954885  0.17013095 -0.51503587 -0.3999236 ]\n",
      "Parameter c_gev set to [0.77669203]\n",
      "Parameter d_gev set to [ 0.14633475 -0.09059398 -0.3205967  -0.06440027 -0.00332638]\n",
      "Parameter e_gev set to [0.0710436]\n",
      "Step: 0, Loss: 0.04466485232114792\n",
      "Step: 1, Loss: 0.04465903341770172\n",
      "Step: 2, Loss: 0.0440998300909996\n",
      "Step: 3, Loss: 0.044173888862133026\n",
      "Step: 4, Loss: 0.04364820569753647\n",
      "Step: 5, Loss: 0.043572619557380676\n",
      "Step: 6, Loss: 0.04321753978729248\n",
      "Step: 7, Loss: 0.04320598393678665\n",
      "Step: 8, Loss: 0.04305633157491684\n",
      "Step: 9, Loss: 0.04295375943183899\n",
      "Step: 10, Loss: 0.042625486850738525\n",
      "Step: 11, Loss: 0.04238183796405792\n",
      "Step: 12, Loss: 0.04233657196164131\n",
      "Step: 13, Loss: 0.04228993132710457\n",
      "Step: 14, Loss: 0.04232347756624222\n",
      "Step: 15, Loss: 0.04217728599905968\n",
      "Step: 16, Loss: 0.04232819005846977\n",
      "Step: 17, Loss: 0.041732918471097946\n",
      "Step: 18, Loss: 0.04194854572415352\n",
      "Step: 19, Loss: 0.04187506437301636\n",
      "Step: 20, Loss: 0.04145824909210205\n",
      "Step: 21, Loss: 0.04149002581834793\n",
      "Step: 22, Loss: 0.04163298010826111\n",
      "Step: 23, Loss: 0.041861433535814285\n",
      "Step: 24, Loss: 0.041785456240177155\n",
      "Step: 25, Loss: 0.04165433719754219\n",
      "Step: 26, Loss: 0.04129530489444733\n",
      "Step: 27, Loss: 0.04151519387960434\n",
      "Step: 28, Loss: 0.04156374931335449\n",
      "Step: 29, Loss: 0.041123051196336746\n",
      "Step: 30, Loss: 0.04165137559175491\n",
      "Step: 31, Loss: 0.04152561351656914\n",
      "Step: 32, Loss: 0.04120992496609688\n",
      "Step: 33, Loss: 0.04098523408174515\n",
      "Step: 34, Loss: 0.04123663902282715\n",
      "Step: 35, Loss: 0.041242390871047974\n",
      "Step: 36, Loss: 0.04134851321578026\n",
      "Step: 37, Loss: 0.041241876780986786\n",
      "Step: 38, Loss: 0.0410541407763958\n",
      "Step: 39, Loss: 0.04111960157752037\n",
      "Step: 40, Loss: 0.0409800224006176\n",
      "Step: 41, Loss: 0.04095188155770302\n",
      "Step: 42, Loss: 0.0410066656768322\n",
      "Step: 43, Loss: 0.04090098291635513\n",
      "Step: 44, Loss: 0.040826573967933655\n",
      "Step: 45, Loss: 0.04101094976067543\n",
      "Step: 46, Loss: 0.04105770215392113\n",
      "Step: 47, Loss: 0.041042543947696686\n",
      "Step: 48, Loss: 0.04100899398326874\n",
      "Step: 49, Loss: 0.04108758270740509\n",
      "Step: 50, Loss: 0.04113046079874039\n",
      "Step: 51, Loss: 0.040743131190538406\n",
      "Step: 52, Loss: 0.04117714986205101\n",
      "Step: 53, Loss: 0.040925461798906326\n",
      "Step: 54, Loss: 0.04107600823044777\n",
      "Step: 55, Loss: 0.0408623069524765\n",
      "Step: 56, Loss: 0.04088612645864487\n",
      "Step: 57, Loss: 0.04075681045651436\n",
      "Step: 58, Loss: 0.04058033227920532\n",
      "Step: 59, Loss: 0.04067271947860718\n",
      "Step: 60, Loss: 0.041024692356586456\n",
      "Step: 61, Loss: 0.04086920619010925\n",
      "Step: 62, Loss: 0.040811434388160706\n",
      "Step: 63, Loss: 0.040833305567502975\n",
      "Step: 64, Loss: 0.040603432804346085\n",
      "Step: 65, Loss: 0.04077360779047012\n",
      "Step: 66, Loss: 0.04085638001561165\n",
      "Step: 67, Loss: 0.04071888327598572\n",
      "Step: 68, Loss: 0.040508244186639786\n",
      "Step: 69, Loss: 0.04075418412685394\n",
      "Step: 70, Loss: 0.04047703742980957\n",
      "Step: 71, Loss: 0.040442924946546555\n",
      "Step: 72, Loss: 0.04041598364710808\n",
      "Step: 73, Loss: 0.040745340287685394\n",
      "Step: 74, Loss: 0.040493812412023544\n",
      "Step: 75, Loss: 0.040686413645744324\n",
      "Step: 76, Loss: 0.04088539257645607\n",
      "Step: 77, Loss: 0.0406615175306797\n",
      "Step: 78, Loss: 0.040289849042892456\n",
      "Step: 79, Loss: 0.04055667668581009\n",
      "Step: 80, Loss: 0.04051461070775986\n",
      "Step: 81, Loss: 0.040428806096315384\n",
      "Step: 82, Loss: 0.040392741560935974\n",
      "Step: 83, Loss: 0.04063870757818222\n",
      "Step: 84, Loss: 0.040261730551719666\n",
      "Step: 85, Loss: 0.0405091755092144\n",
      "Step: 86, Loss: 0.04046630859375\n",
      "Step: 87, Loss: 0.0402836836874485\n",
      "Step: 88, Loss: 0.040384434163570404\n",
      "Step: 89, Loss: 0.040434736758470535\n",
      "Step: 90, Loss: 0.040518127381801605\n",
      "Step: 91, Loss: 0.0402425117790699\n",
      "Step: 92, Loss: 0.04058406502008438\n",
      "Step: 93, Loss: 0.04017261788249016\n",
      "Step: 94, Loss: 0.04039609804749489\n",
      "Step: 95, Loss: 0.0402551144361496\n",
      "Step: 96, Loss: 0.04046371579170227\n",
      "Step: 97, Loss: 0.040272604674100876\n",
      "Step: 98, Loss: 0.04024962708353996\n",
      "Step: 99, Loss: 0.04050936549901962\n",
      "Step: 100, Loss: 0.04016764461994171\n",
      "Step: 101, Loss: 0.04027733579277992\n",
      "Step: 102, Loss: 0.04043059051036835\n",
      "Step: 103, Loss: 0.04030107334256172\n",
      "Step: 104, Loss: 0.04035056009888649\n",
      "Step: 105, Loss: 0.04018509387969971\n",
      "Step: 106, Loss: 0.040497101843357086\n",
      "Step: 107, Loss: 0.040141087025403976\n",
      "Step: 108, Loss: 0.03999198600649834\n",
      "Step: 109, Loss: 0.04014337435364723\n",
      "Step: 110, Loss: 0.04016200080513954\n",
      "Step: 111, Loss: 0.04021472483873367\n",
      "Step: 112, Loss: 0.040581539273262024\n",
      "Step: 113, Loss: 0.04020480066537857\n",
      "Step: 114, Loss: 0.040105510503053665\n",
      "Step: 115, Loss: 0.0401589497923851\n",
      "Step: 116, Loss: 0.04014139249920845\n",
      "Step: 117, Loss: 0.040071021765470505\n",
      "Step: 118, Loss: 0.040588002651929855\n",
      "Step: 119, Loss: 0.04041771963238716\n",
      "Step: 120, Loss: 0.04018058627843857\n",
      "Step: 121, Loss: 0.04042883962392807\n",
      "Step: 122, Loss: 0.04035772755742073\n",
      "Step: 123, Loss: 0.040205053985118866\n",
      "Step: 124, Loss: 0.04012191668152809\n",
      "Step: 125, Loss: 0.0402299240231514\n",
      "Step: 126, Loss: 0.04047895967960358\n",
      "Step: 127, Loss: 0.040164388716220856\n",
      "Step: 128, Loss: 0.03990825638175011\n",
      "Step: 129, Loss: 0.04021061584353447\n",
      "Step: 130, Loss: 0.04014077037572861\n",
      "Step: 131, Loss: 0.04008530452847481\n",
      "Step: 132, Loss: 0.04019869863986969\n",
      "Step: 133, Loss: 0.04021916165947914\n",
      "Step: 134, Loss: 0.040089916437864304\n",
      "Step: 135, Loss: 0.04006494581699371\n",
      "Step: 136, Loss: 0.04029441997408867\n",
      "Step: 137, Loss: 0.039989177137613297\n",
      "Step: 138, Loss: 0.040032826364040375\n",
      "Step: 139, Loss: 0.0401604063808918\n",
      "Step: 140, Loss: 0.039897602051496506\n",
      "Step: 141, Loss: 0.04010825604200363\n",
      "Step: 142, Loss: 0.04037768393754959\n",
      "Step: 143, Loss: 0.04007657617330551\n",
      "Step: 144, Loss: 0.040324412286281586\n",
      "Step: 145, Loss: 0.04017451032996178\n",
      "Step: 146, Loss: 0.040280018001794815\n",
      "Step: 147, Loss: 0.04029061645269394\n",
      "Step: 148, Loss: 0.04015417397022247\n",
      "Step: 149, Loss: 0.03977040573954582\n",
      "Step: 150, Loss: 0.04010309278964996\n",
      "Step: 151, Loss: 0.0402219220995903\n",
      "Step: 152, Loss: 0.04011452570557594\n",
      "Step: 153, Loss: 0.04016947001218796\n",
      "Step: 154, Loss: 0.04006848484277725\n",
      "Step: 155, Loss: 0.040301620960235596\n",
      "Step: 156, Loss: 0.04023841395974159\n",
      "Step: 157, Loss: 0.040215808898210526\n",
      "Step: 158, Loss: 0.04005178436636925\n",
      "Step: 159, Loss: 0.03996403142809868\n",
      "Step: 160, Loss: 0.0402393564581871\n",
      "Step: 161, Loss: 0.04031151905655861\n",
      "Step: 162, Loss: 0.04037662595510483\n",
      "Step: 163, Loss: 0.04022488370537758\n",
      "Step: 164, Loss: 0.04037998244166374\n",
      "Step: 165, Loss: 0.04021986201405525\n",
      "Step: 166, Loss: 0.040187377482652664\n"
     ]
    }
   ],
   "source": [
    "model = train_and_save(\n",
    "    forecast_distribution,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    learning_rate,\n",
    "    folds,\n",
    "    parameter_names,\n",
    "    neighbourhood_size,\n",
    "    ignore,\n",
    "    epochs,\n",
    "\n",
    "    chain_function = chain_function,\n",
    "    chain_function_mean = chain_function_mean,\n",
    "    chain_function_std = chain_function_std,\n",
    "    chain_function_constant = chain_function_constant,\n",
    "    chain_function_threshold = chain_function_threshold,\n",
    "    samples = samples,\n",
    "    printing = printing,\n",
    "    distribution_1 = distribution_1,\n",
    "    distribution_2 = distribution_2,\n",
    "    pretrained = pretrained\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 200)\n",
      "Forecast distribution: distr_mixture\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_gev\n",
      "Mixture weight: [0.6714824]\n",
      "Parameters:\n",
      "  weight: [0.6714824]\n",
      "  a_tn: [0.8587427]\n",
      "  b_tn: [ 0.9033643  -0.8743947  -0.10445029 -0.27649736  0.85969   ]\n",
      "  c_tn: [1.8735183]\n",
      "  d_tn: [0.7428804]\n",
      "  a_gev: [-0.4236689]\n",
      "  b_gev: [ 0.9333376   0.5409048  -0.3650169   0.3564078   0.61552596]\n",
      "  c_gev: [1.4305779]\n",
      "  d_gev: [ 0.09890767 -0.5423227   0.16434298  0.31506124 -0.69037396]\n",
      "  e_gev: [-0.31247506]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 13.0, Std: 4.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
