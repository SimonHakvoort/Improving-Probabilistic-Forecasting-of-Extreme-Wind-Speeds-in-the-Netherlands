{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 11:51:05.548501: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-13 11:51:05.574736: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-13 11:51:05.574755: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-13 11:51:05.575408: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-13 11:51:05.579342: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-13 11:51:05.579880: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 11:51:11.483288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.training.training import train_model, train_and_save, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NORMAL models\n",
    "## default epochs = 400\n",
    "\n",
    "\n",
    "forecast_distribution = 'distr_log_normal'\n",
    "distribution_1 = 'distr_trunc_normal'\n",
    "distribution_2 = 'distr_gev'\n",
    "\n",
    "loss = 'loss_CRPS_sample' # options: loss_CRPS_sample, loss_twCRPS_sample, loss_log_likelihood\n",
    "\n",
    "chain_function = 'chain_function_normal_cdf' # options: chain_function_normal_cdf, chain_function_indicator\n",
    "chain_function_mean = 16\n",
    "chain_function_std = 6\n",
    "chain_function_threshold = 15 # 12 / 15\n",
    "\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 0.01\n",
    "folds = [1,2]\n",
    "parameter_names = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "neighbourhood_size = 11\n",
    "ignore = ['229', '285', '323']\n",
    "epochs = 200\n",
    "\n",
    "samples = 200\n",
    "printing = True\n",
    "pretrained = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for Log Normal distribution\n",
      "Step: 0, Loss: 3.1657583713531494\n",
      "Step: 1, Loss: 3.048556089401245\n",
      "Step: 2, Loss: 2.9229865074157715\n",
      "Step: 3, Loss: 2.7936980724334717\n",
      "Step: 4, Loss: 2.6612915992736816\n",
      "Step: 5, Loss: 2.52427077293396\n",
      "Step: 6, Loss: 2.394749641418457\n",
      "Step: 7, Loss: 2.2619376182556152\n",
      "Step: 8, Loss: 2.148641347885132\n",
      "Step: 9, Loss: 2.052562952041626\n",
      "Step: 10, Loss: 1.9661564826965332\n",
      "Step: 11, Loss: 1.9084529876708984\n",
      "Step: 12, Loss: 1.8765217065811157\n",
      "Step: 13, Loss: 1.8602099418640137\n",
      "Step: 14, Loss: 1.826812505722046\n",
      "Step: 15, Loss: 1.8599441051483154\n",
      "Step: 16, Loss: 1.85511314868927\n",
      "Step: 17, Loss: 1.8334070444107056\n",
      "Step: 18, Loss: 1.7508876323699951\n",
      "Step: 19, Loss: 1.7513426542282104\n",
      "Step: 20, Loss: 1.74312162399292\n",
      "Step: 21, Loss: 1.7147136926651\n",
      "Step: 22, Loss: 1.6991691589355469\n",
      "Step: 23, Loss: 1.6465262174606323\n",
      "Step: 24, Loss: 1.6183487176895142\n",
      "Step: 25, Loss: 1.6028984785079956\n",
      "Step: 26, Loss: 1.5849363803863525\n",
      "Step: 27, Loss: 1.567740797996521\n",
      "Step: 28, Loss: 1.5591516494750977\n",
      "Step: 29, Loss: 1.5541001558303833\n",
      "Step: 30, Loss: 1.5555927753448486\n",
      "Step: 31, Loss: 1.5449604988098145\n",
      "Step: 32, Loss: 1.5391871929168701\n",
      "Step: 33, Loss: 1.5382009744644165\n",
      "Step: 34, Loss: 1.529753565788269\n",
      "Step: 35, Loss: 1.5135167837142944\n",
      "Step: 36, Loss: 1.5027753114700317\n",
      "Step: 37, Loss: 1.4925564527511597\n",
      "Step: 38, Loss: 1.4904249906539917\n",
      "Step: 39, Loss: 1.484621524810791\n",
      "Step: 40, Loss: 1.4771254062652588\n",
      "Step: 41, Loss: 1.4775190353393555\n",
      "Step: 42, Loss: 1.4693982601165771\n",
      "Step: 43, Loss: 1.4734485149383545\n",
      "Step: 44, Loss: 1.462371826171875\n",
      "Step: 45, Loss: 1.4639675617218018\n",
      "Step: 46, Loss: 1.4551608562469482\n",
      "Step: 47, Loss: 1.448940396308899\n",
      "Step: 48, Loss: 1.445339560508728\n",
      "Step: 49, Loss: 1.4427653551101685\n",
      "Step: 50, Loss: 1.4347188472747803\n",
      "Step: 51, Loss: 1.4297329187393188\n",
      "Step: 52, Loss: 1.4234285354614258\n",
      "Step: 53, Loss: 1.417163610458374\n",
      "Step: 54, Loss: 1.4129456281661987\n",
      "Step: 55, Loss: 1.407692790031433\n",
      "Step: 56, Loss: 1.403282642364502\n",
      "Step: 57, Loss: 1.4081218242645264\n",
      "Step: 58, Loss: 1.3961840867996216\n",
      "Step: 59, Loss: 1.3929177522659302\n",
      "Step: 60, Loss: 1.3851583003997803\n",
      "Step: 61, Loss: 1.3773455619812012\n",
      "Step: 62, Loss: 1.370995283126831\n",
      "Step: 63, Loss: 1.3700634241104126\n",
      "Step: 64, Loss: 1.3682819604873657\n",
      "Step: 65, Loss: 1.3550703525543213\n",
      "Step: 66, Loss: 1.3540589809417725\n",
      "Step: 67, Loss: 1.3493019342422485\n",
      "Step: 68, Loss: 1.3510693311691284\n",
      "Step: 69, Loss: 1.3364027738571167\n",
      "Step: 70, Loss: 1.3329592943191528\n",
      "Step: 71, Loss: 1.3303642272949219\n",
      "Step: 72, Loss: 1.3229660987854004\n",
      "Step: 73, Loss: 1.3185714483261108\n",
      "Step: 74, Loss: 1.3176591396331787\n",
      "Step: 75, Loss: 1.3096517324447632\n",
      "Step: 76, Loss: 1.30130934715271\n",
      "Step: 77, Loss: 1.295736312866211\n",
      "Step: 78, Loss: 1.294692873954773\n",
      "Step: 79, Loss: 1.286929965019226\n",
      "Step: 80, Loss: 1.279684066772461\n",
      "Step: 81, Loss: 1.2801525592803955\n",
      "Step: 82, Loss: 1.2721166610717773\n",
      "Step: 83, Loss: 1.2668377161026\n",
      "Step: 84, Loss: 1.2592252492904663\n",
      "Step: 85, Loss: 1.2559565305709839\n",
      "Step: 86, Loss: 1.2518762350082397\n",
      "Step: 87, Loss: 1.2456282377243042\n",
      "Step: 88, Loss: 1.241952896118164\n",
      "Step: 89, Loss: 1.236077070236206\n",
      "Step: 90, Loss: 1.2319371700286865\n",
      "Step: 91, Loss: 1.2242907285690308\n",
      "Step: 92, Loss: 1.2181384563446045\n",
      "Step: 93, Loss: 1.2126625776290894\n",
      "Step: 94, Loss: 1.2089792490005493\n",
      "Step: 95, Loss: 1.198820948600769\n",
      "Step: 96, Loss: 1.1955686807632446\n",
      "Step: 97, Loss: 1.1914278268814087\n",
      "Step: 98, Loss: 1.1866523027420044\n",
      "Step: 99, Loss: 1.1809635162353516\n",
      "Step: 100, Loss: 1.1759426593780518\n",
      "Step: 101, Loss: 1.172110676765442\n",
      "Step: 102, Loss: 1.1650053262710571\n",
      "Step: 103, Loss: 1.159165859222412\n",
      "Step: 104, Loss: 1.1564618349075317\n",
      "Step: 105, Loss: 1.1497677564620972\n",
      "Step: 106, Loss: 1.1473175287246704\n",
      "Step: 107, Loss: 1.1437479257583618\n",
      "Step: 108, Loss: 1.1368087530136108\n",
      "Step: 109, Loss: 1.1327769756317139\n",
      "Step: 110, Loss: 1.1286120414733887\n",
      "Step: 111, Loss: 1.1265751123428345\n",
      "Step: 112, Loss: 1.1213715076446533\n",
      "Step: 113, Loss: 1.1168543100357056\n",
      "Step: 114, Loss: 1.1112251281738281\n",
      "Step: 115, Loss: 1.1082252264022827\n",
      "Step: 116, Loss: 1.104811668395996\n",
      "Step: 117, Loss: 1.1020394563674927\n",
      "Step: 118, Loss: 1.0985394716262817\n",
      "Step: 119, Loss: 1.0954411029815674\n",
      "Step: 120, Loss: 1.0939362049102783\n",
      "Step: 121, Loss: 1.0917024612426758\n",
      "Step: 122, Loss: 1.0901986360549927\n",
      "Step: 123, Loss: 1.08816659450531\n",
      "Step: 124, Loss: 1.085456132888794\n",
      "Step: 125, Loss: 1.0812010765075684\n",
      "Step: 126, Loss: 1.0813078880310059\n",
      "Step: 127, Loss: 1.079611897468567\n",
      "Step: 128, Loss: 1.0793614387512207\n",
      "Step: 129, Loss: 1.0792378187179565\n",
      "Step: 130, Loss: 1.0750148296356201\n",
      "Step: 131, Loss: 1.0745556354522705\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gev_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecast_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbourhood_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchain_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_function_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchain_function_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_function_std\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchain_function_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_function_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchain_function_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprinting\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprinting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdistribution_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdistribution_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(gev_model)\n",
      "File \u001b[0;32m~/thesiscode/src/training/training.py:71\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(forecast_distribution, loss, optimizer, learning_rate, folds, parameter_names, neighbourhood_size, ignore, epochs, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprinting\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     67\u001b[0m     printing \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprinting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 71\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprinting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/thesiscode/src/models/emos.py:461\u001b[0m, in \u001b[0;36mEMOS.fit\u001b[0;34m(self, X, y, variance, steps, printing)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_made \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m steps\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m--> 461\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss_and_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# check if gradient contains nan\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_any(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mis_nan(grads[\u001b[38;5;241m0\u001b[39m])):\n",
      "File \u001b[0;32m~/thesiscode/src/models/emos.py:435\u001b[0m, in \u001b[0;36mEMOS.compute_loss_and_gradient\u001b[0;34m(self, X, y, variance)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03mCompute the loss and the gradient of the loss with respect to the parameters of the model, \u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03mwhich are the parameters of the forecast distribution.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m- grads: the gradients of the loss with respect to the parameters of the model.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m--> 435\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecast_distribution\u001b[38;5;241m.\u001b[39mget_parameter_dict()\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_value, grads\n",
      "File \u001b[0;32m~/thesiscode/src/models/emos.py:321\u001b[0m, in \u001b[0;36mEMOS.loss_CRPS_sample\u001b[0;34m(self, X, y, variance)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_CRPS_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, variance):\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_CRPS_sample_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesiscode/src/models/emos.py:299\u001b[0m, in \u001b[0;36mEMOS.loss_CRPS_sample_general\u001b[0;34m(self, X, y, variance, samples)\u001b[0m\n\u001b[1;32m    297\u001b[0m forecast_distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecast_distribution\u001b[38;5;241m.\u001b[39mget_distribution(X, variance)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m#X_1 has shape (samples, n), where n is the number of observations\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m X_1 \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m X_2 \u001b[38;5;241m=\u001b[39m forecast_distribution\u001b[38;5;241m.\u001b[39msample(samples)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# y will be broadcasted to the shape of X_1 and X_2\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py:333\u001b[0m, in \u001b[0;36m_TransformedDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m distribution_kwargs, bijector_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs_split_fn(kwargs)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# First, generate samples from the base distribution.\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_broadcast_distribution_batch_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdistribution_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Apply the bijector's forward transformation. For caching to\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# work, it is imperative that this is the last modification to the\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# returned result.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijector\u001b[38;5;241m.\u001b[39mforward(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbijector_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1205\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape, seed, name, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate samples of the specified shape.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mNote that a call to `sample()` without arguments will generate a single\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m  samples: a `Tensor` with prepended dimensions `sample_shape`.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_and_control_scope(name):\n\u001b[0;32m-> 1205\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_sample_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:1182\u001b[0m, in \u001b[0;36mDistribution._call_sample_n\u001b[0;34m(self, sample_shape, seed, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m sample_shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconvert_to_shape_tensor(\n\u001b[1;32m   1179\u001b[0m     ps\u001b[38;5;241m.\u001b[39mcast(sample_shape, tf\u001b[38;5;241m.\u001b[39mint32), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1180\u001b[0m sample_shape, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_sample_shape_to_vector(\n\u001b[1;32m   1181\u001b[0m     sample_shape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1182\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_n\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m samples \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mreshape(x, ps\u001b[38;5;241m.\u001b[39mconcat([sample_shape, ps\u001b[38;5;241m.\u001b[39mshape(x)[\u001b[38;5;241m1\u001b[39m:]], \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m   1186\u001b[0m     samples)\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_sample_static_shape(samples, sample_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow_probability/python/distributions/normal.py:179\u001b[0m, in \u001b[0;36mNormal._sample_n\u001b[0;34m(self, n, seed)\u001b[0m\n\u001b[1;32m    176\u001b[0m scale \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale)\n\u001b[1;32m    177\u001b[0m shape \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39mconcat([[n], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_shape_tensor(loc\u001b[38;5;241m=\u001b[39mloc, scale\u001b[38;5;241m=\u001b[39mscale)],\n\u001b[1;32m    178\u001b[0m                   axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 179\u001b[0m sampled \u001b[38;5;241m=\u001b[39m \u001b[43msamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sampled \u001b[38;5;241m*\u001b[39m scale \u001b[38;5;241m+\u001b[39m loc\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow_probability/python/internal/samplers.py:273\u001b[0m, in \u001b[0;36mnormal\u001b[0;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mname_scope(name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    271\u001b[0m   \u001b[38;5;66;03m# TODO(b/147874898): Remove workaround for seed-sensitive tests.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_stateful_seed(seed):\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m   seed \u001b[38;5;241m=\u001b[39m sanitize_seed(seed)\n\u001b[1;32m    277\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mstateless_normal(\n\u001b[1;32m    278\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape, seed\u001b[38;5;241m=\u001b[39mseed, mean\u001b[38;5;241m=\u001b[39mmean, stddev\u001b[38;5;241m=\u001b[39mstddev, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gev_model = train_model(\n",
    "    forecast_distribution,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    learning_rate,\n",
    "    folds,\n",
    "    parameter_names,\n",
    "    neighbourhood_size,\n",
    "    ignore,\n",
    "    epochs,\n",
    "\n",
    "    chain_function = chain_function,\n",
    "    chain_function_mean = chain_function_mean,\n",
    "    chain_function_std = chain_function_std,\n",
    "    chain_function_threshold = chain_function_threshold,\n",
    "    samples = samples,\n",
    "    printing = printing,\n",
    "    distribution_1 = distribution_1,\n",
    "    distribution_2 = distribution_2,\n",
    "    pretrained = pretrained\n",
    ")\n",
    "\n",
    "print(gev_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
