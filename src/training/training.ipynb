{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 08:57:00.479303: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 08:57:00.506519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 08:57:00.506542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 08:57:00.507314: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 08:57:00.511646: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 08:57:00.511978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 08:57:07.771812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.training.training import train_model, train_and_save, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_distribution = 'distr_mixture'\n",
    "distribution_1 = 'distr_trunc_normal'\n",
    "distribution_2 = 'distr_gev'\n",
    "\n",
    "loss = 'loss_twCRPS_sample' # options: loss_CRPS_sample, loss_twCRPS_sample, loss_log_likelihood\n",
    "\n",
    "chain_function = 'chain_function_normal_cdf_plus_constant' # options: chain_function_normal_cdf, chain_function_indicator, chain_function_normal_cdf_plus_constant\n",
    "chain_function_mean = 13\n",
    "chain_function_std = 1\n",
    "chain_function_threshold = 15 # 12 / 15\n",
    "chain_function_constant = 0.03\n",
    "\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 0.01\n",
    "folds = [1,2]\n",
    "parameter_names = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "neighbourhood_size = 11\n",
    "ignore = ['229', '285', '323']\n",
    "epochs = 600\n",
    "\n",
    "samples = 200\n",
    "printing = True\n",
    "pretrained = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameter for Mixture distribution\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameter for Mixture distribution\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameter for Mixture distribution\n",
      "Final loss:  0.0744778\n",
      "Final loss:  0.07456559\n",
      "Parameter weight set to [0.54538715]\n",
      "Parameter a_tn set to [0.6058377]\n",
      "Parameter b_tn set to [0.9659794  0.5460162  0.51990336 0.535413   0.5561388 ]\n",
      "Parameter c_tn set to [1.3706361]\n",
      "Parameter d_tn set to [0.9614644]\n",
      "Parameter a_gev set to [1.3989383]\n",
      "Parameter b_gev set to [ 0.43136588 -0.40581736  0.03037768 -0.43062606 -0.38748443]\n",
      "Parameter c_gev set to [0.9306379]\n",
      "Parameter d_gev set to [ 0.15250902 -0.2118934  -0.35051635 -0.27117285 -0.18921587]\n",
      "Parameter e_gev set to [0.08129023]\n",
      "Parameter weight set to [0.48784217]\n",
      "Parameter a_tn set to [0.58876723]\n",
      "Parameter b_tn set to [0.9817061  0.55978173 0.53913915 0.5510892  0.5701646 ]\n",
      "Parameter c_tn set to [1.3191433]\n",
      "Parameter d_tn set to [0.9752075]\n",
      "Parameter a_gev set to [1.4201541]\n",
      "Parameter b_gev set to [ 0.45394817 -0.39811885  0.0764048  -0.43052724 -0.37034258]\n",
      "Parameter c_gev set to [0.88624823]\n",
      "Parameter d_gev set to [ 0.12337849 -0.18465993 -0.32014272 -0.24342524 -0.14336273]\n",
      "Parameter e_gev set to [0.15309748]\n",
      "Weight:  [0.4778425]\n",
      "Step: 0, Loss: 0.07478201389312744\n",
      "Weight:  [0.47490537]\n",
      "Step: 1, Loss: 0.07370443642139435\n",
      "Weight:  [0.47196558]\n",
      "Step: 2, Loss: 0.07349437475204468\n",
      "Weight:  [0.4677915]\n",
      "Step: 3, Loss: 0.07337010651826859\n",
      "Weight:  [0.46445596]\n",
      "Step: 4, Loss: 0.07350178062915802\n",
      "Weight:  [0.4612403]\n",
      "Step: 5, Loss: 0.07260358333587646\n",
      "Weight:  [0.45789182]\n",
      "Step: 6, Loss: 0.07238307595252991\n",
      "Weight:  [0.45426983]\n",
      "Step: 7, Loss: 0.07219299674034119\n",
      "Weight:  [0.45048958]\n",
      "Step: 8, Loss: 0.07189804315567017\n",
      "Weight:  [0.44707024]\n",
      "Step: 9, Loss: 0.07200980186462402\n",
      "Weight:  [0.44494545]\n",
      "Step: 10, Loss: 0.07161794602870941\n",
      "Weight:  [0.4419043]\n",
      "Step: 11, Loss: 0.07171095162630081\n",
      "Weight:  [0.44045413]\n",
      "Step: 12, Loss: 0.07116823643445969\n",
      "Weight:  [0.43925312]\n",
      "Step: 13, Loss: 0.07123100012540817\n",
      "Weight:  [0.43615553]\n",
      "Step: 14, Loss: 0.0709179937839508\n",
      "Weight:  [0.43291947]\n",
      "Step: 15, Loss: 0.07075802981853485\n",
      "Weight:  [0.43039986]\n",
      "Step: 16, Loss: 0.07073737680912018\n",
      "Weight:  [0.42900497]\n",
      "Step: 17, Loss: 0.0699487179517746\n",
      "Weight:  [0.42774203]\n",
      "Step: 18, Loss: 0.07018519937992096\n",
      "Weight:  [0.42621952]\n",
      "Step: 19, Loss: 0.07013040035963058\n",
      "Weight:  [0.42501596]\n",
      "Step: 20, Loss: 0.0703214704990387\n",
      "Weight:  [0.42391843]\n",
      "Step: 21, Loss: 0.0695735365152359\n",
      "Weight:  [0.42229593]\n",
      "Step: 22, Loss: 0.06975661218166351\n",
      "Weight:  [0.42098248]\n",
      "Step: 23, Loss: 0.06990135461091995\n",
      "Weight:  [0.42025942]\n",
      "Step: 24, Loss: 0.06980805844068527\n",
      "Weight:  [0.4195869]\n",
      "Step: 25, Loss: 0.06951664388179779\n",
      "Weight:  [0.41953817]\n",
      "Step: 26, Loss: 0.06924451887607574\n",
      "Weight:  [0.41873354]\n",
      "Step: 27, Loss: 0.06920690089464188\n",
      "Weight:  [0.4182136]\n",
      "Step: 28, Loss: 0.0693974569439888\n",
      "Weight:  [0.41798007]\n",
      "Step: 29, Loss: 0.06938283145427704\n",
      "Weight:  [0.41856042]\n",
      "Step: 30, Loss: 0.06950267404317856\n",
      "Weight:  [0.41896045]\n",
      "Step: 31, Loss: 0.06934191286563873\n",
      "Weight:  [0.41876343]\n",
      "Step: 32, Loss: 0.06921658664941788\n",
      "Weight:  [0.41838267]\n",
      "Step: 33, Loss: 0.06912201642990112\n",
      "Weight:  [0.4176737]\n",
      "Step: 34, Loss: 0.06927748769521713\n",
      "Weight:  [0.41745186]\n",
      "Step: 35, Loss: 0.06877564638853073\n",
      "Weight:  [0.4170771]\n",
      "Step: 36, Loss: 0.06897804886102676\n",
      "Weight:  [0.41768575]\n",
      "Step: 37, Loss: 0.06855682283639908\n",
      "Weight:  [0.41854504]\n",
      "Step: 38, Loss: 0.06901812553405762\n",
      "Weight:  [0.41965035]\n",
      "Step: 39, Loss: 0.06902627646923065\n",
      "Weight:  [0.42118755]\n",
      "Step: 40, Loss: 0.06900661438703537\n",
      "Weight:  [0.42197043]\n",
      "Step: 41, Loss: 0.06886816024780273\n",
      "Weight:  [0.42161247]\n",
      "Step: 42, Loss: 0.06866312772035599\n",
      "Weight:  [0.42002326]\n",
      "Step: 43, Loss: 0.0689314752817154\n",
      "Weight:  [0.41963273]\n",
      "Step: 44, Loss: 0.06875891983509064\n",
      "Weight:  [0.41988406]\n",
      "Step: 45, Loss: 0.06868871301412582\n",
      "Weight:  [0.42054966]\n",
      "Step: 46, Loss: 0.0686701312661171\n",
      "Weight:  [0.4218506]\n",
      "Step: 47, Loss: 0.06877270340919495\n",
      "Weight:  [0.42189732]\n",
      "Step: 48, Loss: 0.06864090263843536\n",
      "Weight:  [0.42204687]\n",
      "Step: 49, Loss: 0.06856298446655273\n",
      "Weight:  [0.4226746]\n",
      "Step: 50, Loss: 0.0688902735710144\n",
      "Weight:  [0.42261547]\n",
      "Step: 51, Loss: 0.06863795220851898\n",
      "Weight:  [0.4213526]\n",
      "Step: 52, Loss: 0.06866394728422165\n",
      "Weight:  [0.4193717]\n",
      "Step: 53, Loss: 0.06852409243583679\n",
      "Weight:  [0.41791135]\n",
      "Step: 54, Loss: 0.0686962902545929\n",
      "Weight:  [0.4174161]\n",
      "Step: 55, Loss: 0.06847134232521057\n",
      "Weight:  [0.4170348]\n",
      "Step: 56, Loss: 0.06849891692399979\n",
      "Weight:  [0.4153956]\n",
      "Step: 57, Loss: 0.06844538450241089\n",
      "Weight:  [0.41373143]\n",
      "Step: 58, Loss: 0.06863366812467575\n",
      "Weight:  [0.41169113]\n",
      "Step: 59, Loss: 0.06830815970897675\n",
      "Weight:  [0.410501]\n",
      "Step: 60, Loss: 0.06842628866434097\n",
      "Weight:  [0.41069722]\n",
      "Step: 61, Loss: 0.06868138909339905\n",
      "Weight:  [0.41201892]\n",
      "Step: 62, Loss: 0.06866136193275452\n",
      "Weight:  [0.41430458]\n",
      "Step: 63, Loss: 0.06861545890569687\n",
      "Weight:  [0.41507137]\n",
      "Step: 64, Loss: 0.0684923306107521\n",
      "Weight:  [0.41617778]\n",
      "Step: 65, Loss: 0.06845007091760635\n",
      "Weight:  [0.41801155]\n",
      "Step: 66, Loss: 0.06858757883310318\n",
      "Weight:  [0.41998723]\n",
      "Step: 67, Loss: 0.0683295875787735\n",
      "Weight:  [0.4212884]\n",
      "Step: 68, Loss: 0.06883688271045685\n",
      "Weight:  [0.4223485]\n",
      "Step: 69, Loss: 0.06850496679544449\n",
      "Weight:  [0.4233419]\n",
      "Step: 70, Loss: 0.0684523656964302\n",
      "Weight:  [0.4242029]\n",
      "Step: 71, Loss: 0.06843835860490799\n",
      "Weight:  [0.42590898]\n",
      "Step: 72, Loss: 0.06849265098571777\n",
      "Weight:  [0.42837527]\n",
      "Step: 73, Loss: 0.06853107362985611\n",
      "Weight:  [0.43005416]\n",
      "Step: 74, Loss: 0.06843999773263931\n",
      "Weight:  [0.4298743]\n",
      "Step: 75, Loss: 0.06838897615671158\n",
      "Weight:  [0.42930323]\n",
      "Step: 76, Loss: 0.06800198554992676\n",
      "Weight:  [0.42887506]\n",
      "Step: 77, Loss: 0.06834090501070023\n",
      "Weight:  [0.4291552]\n",
      "Step: 78, Loss: 0.06833375245332718\n",
      "Weight:  [0.42974237]\n",
      "Step: 79, Loss: 0.06860905140638351\n",
      "Weight:  [0.4314253]\n",
      "Step: 80, Loss: 0.06822104007005692\n",
      "Weight:  [0.4329441]\n",
      "Step: 81, Loss: 0.0681917741894722\n",
      "Weight:  [0.4346216]\n",
      "Step: 82, Loss: 0.06835349649190903\n",
      "Weight:  [0.43549502]\n",
      "Step: 83, Loss: 0.06849557906389236\n",
      "Weight:  [0.4360189]\n",
      "Step: 84, Loss: 0.06853342801332474\n",
      "Weight:  [0.43698338]\n",
      "Step: 85, Loss: 0.06810274720191956\n",
      "Weight:  [0.43663993]\n",
      "Step: 86, Loss: 0.06837523728609085\n",
      "Weight:  [0.4368782]\n",
      "Step: 87, Loss: 0.06843683868646622\n",
      "Weight:  [0.43793297]\n",
      "Step: 88, Loss: 0.06837920844554901\n",
      "Weight:  [0.43947542]\n",
      "Step: 89, Loss: 0.06837568432092667\n",
      "Weight:  [0.4407469]\n",
      "Step: 90, Loss: 0.06837842613458633\n",
      "Weight:  [0.44171688]\n",
      "Step: 91, Loss: 0.06866726279258728\n",
      "Weight:  [0.44252613]\n",
      "Step: 92, Loss: 0.06826521456241608\n",
      "Weight:  [0.4432099]\n",
      "Step: 93, Loss: 0.06819241493940353\n",
      "Weight:  [0.44340548]\n",
      "Step: 94, Loss: 0.0683448314666748\n",
      "Weight:  [0.44329843]\n",
      "Step: 95, Loss: 0.06828250735998154\n",
      "Weight:  [0.44244966]\n",
      "Step: 96, Loss: 0.06829161942005157\n",
      "Weight:  [0.4414354]\n",
      "Step: 97, Loss: 0.06815492361783981\n",
      "Weight:  [0.43830344]\n",
      "Step: 98, Loss: 0.06831424683332443\n",
      "Weight:  [0.43503383]\n",
      "Step: 99, Loss: 0.06813980638980865\n",
      "Weight:  [0.4322746]\n",
      "Step: 100, Loss: 0.06857322156429291\n",
      "Weight:  [0.42905888]\n",
      "Step: 101, Loss: 0.06832514703273773\n",
      "Weight:  [0.4258187]\n",
      "Step: 102, Loss: 0.0684734508395195\n",
      "Weight:  [0.42189446]\n",
      "Step: 103, Loss: 0.06825927644968033\n",
      "Weight:  [0.41780195]\n",
      "Step: 104, Loss: 0.06863843649625778\n",
      "Weight:  [0.41363358]\n",
      "Step: 105, Loss: 0.06827490031719208\n",
      "Weight:  [0.4103076]\n",
      "Step: 106, Loss: 0.06850181519985199\n",
      "Weight:  [0.40674242]\n",
      "Step: 107, Loss: 0.06839025020599365\n",
      "Weight:  [0.4031765]\n",
      "Step: 108, Loss: 0.06828135997056961\n",
      "Weight:  [0.40109387]\n",
      "Step: 109, Loss: 0.06818775087594986\n",
      "Weight:  [0.39759433]\n",
      "Step: 110, Loss: 0.06839766353368759\n",
      "Weight:  [0.39319694]\n",
      "Step: 111, Loss: 0.06835360080003738\n",
      "Weight:  [0.38820094]\n",
      "Step: 112, Loss: 0.068291075527668\n",
      "Weight:  [0.3827046]\n",
      "Step: 113, Loss: 0.06836067140102386\n",
      "Weight:  [0.37761867]\n",
      "Step: 114, Loss: 0.06824197620153427\n",
      "Weight:  [0.3737876]\n",
      "Step: 115, Loss: 0.06851755827665329\n",
      "Weight:  [0.37108517]\n",
      "Step: 116, Loss: 0.06839814782142639\n",
      "Weight:  [0.36811712]\n",
      "Step: 117, Loss: 0.06832967698574066\n",
      "Weight:  [0.3650384]\n",
      "Step: 118, Loss: 0.06828662753105164\n",
      "Weight:  [0.3623606]\n",
      "Step: 119, Loss: 0.06825841218233109\n",
      "Weight:  [0.35921583]\n",
      "Step: 120, Loss: 0.0682881623506546\n",
      "Weight:  [0.35630134]\n",
      "Step: 121, Loss: 0.06837796419858932\n",
      "Weight:  [0.35253805]\n",
      "Step: 122, Loss: 0.06851807981729507\n",
      "Weight:  [0.34885818]\n",
      "Step: 123, Loss: 0.06830348819494247\n",
      "Weight:  [0.3447695]\n",
      "Step: 124, Loss: 0.06861156970262527\n",
      "Weight:  [0.34148243]\n",
      "Step: 125, Loss: 0.06808913499116898\n",
      "Weight:  [0.3398694]\n",
      "Step: 126, Loss: 0.06847091764211655\n",
      "Weight:  [0.33859497]\n",
      "Step: 127, Loss: 0.06851530075073242\n",
      "Weight:  [0.33786505]\n",
      "Step: 128, Loss: 0.06852596253156662\n",
      "Weight:  [0.33797193]\n",
      "Step: 129, Loss: 0.06829540431499481\n",
      "Weight:  [0.33689296]\n",
      "Step: 130, Loss: 0.06820975244045258\n",
      "Weight:  [0.33660322]\n",
      "Step: 131, Loss: 0.06837131828069687\n",
      "Weight:  [0.33528072]\n",
      "Step: 132, Loss: 0.06791455298662186\n",
      "Weight:  [0.33352104]\n",
      "Step: 133, Loss: 0.0685025230050087\n",
      "Weight:  [0.33260667]\n",
      "Step: 134, Loss: 0.06808780878782272\n",
      "Weight:  [0.33277658]\n",
      "Step: 135, Loss: 0.06845685839653015\n",
      "Weight:  [0.33320296]\n",
      "Step: 136, Loss: 0.06834036111831665\n",
      "Weight:  [0.3348146]\n",
      "Step: 137, Loss: 0.06817260384559631\n",
      "Weight:  [0.3358789]\n",
      "Step: 138, Loss: 0.06796590238809586\n",
      "Weight:  [0.3358968]\n",
      "Step: 139, Loss: 0.0682791993021965\n",
      "Weight:  [0.33637595]\n",
      "Step: 140, Loss: 0.06815645098686218\n",
      "Weight:  [0.3361908]\n",
      "Step: 141, Loss: 0.0682278573513031\n",
      "Weight:  [0.33627924]\n",
      "Step: 142, Loss: 0.06823969632387161\n",
      "Weight:  [0.3369831]\n",
      "Step: 143, Loss: 0.06823638826608658\n",
      "Weight:  [0.33727065]\n",
      "Step: 144, Loss: 0.06805603951215744\n",
      "Weight:  [0.33704492]\n",
      "Step: 145, Loss: 0.06851941347122192\n",
      "Weight:  [0.33750343]\n",
      "Step: 146, Loss: 0.06829039007425308\n",
      "Weight:  [0.3384961]\n",
      "Step: 147, Loss: 0.0681627094745636\n",
      "Weight:  [0.34029606]\n",
      "Step: 148, Loss: 0.06834826618432999\n",
      "Weight:  [0.34192726]\n",
      "Step: 149, Loss: 0.06855171918869019\n",
      "Weight:  [0.3447364]\n",
      "Step: 150, Loss: 0.06816692650318146\n",
      "Weight:  [0.34722376]\n",
      "Step: 151, Loss: 0.06824028491973877\n",
      "Weight:  [0.35089746]\n",
      "Step: 152, Loss: 0.06818877905607224\n",
      "Weight:  [0.35367075]\n",
      "Step: 153, Loss: 0.06849472224712372\n",
      "Weight:  [0.3571929]\n",
      "Step: 154, Loss: 0.06818218529224396\n",
      "Weight:  [0.3608753]\n",
      "Step: 155, Loss: 0.06824582070112228\n",
      "Weight:  [0.36321902]\n",
      "Step: 156, Loss: 0.0682189017534256\n",
      "Weight:  [0.36593342]\n",
      "Step: 157, Loss: 0.06818225979804993\n",
      "Weight:  [0.36858234]\n",
      "Step: 158, Loss: 0.06814759969711304\n",
      "Weight:  [0.37015355]\n",
      "Step: 159, Loss: 0.06844144314527512\n",
      "Weight:  [0.37162188]\n",
      "Step: 160, Loss: 0.06824275106191635\n",
      "Weight:  [0.37273404]\n",
      "Step: 161, Loss: 0.068318210542202\n",
      "Weight:  [0.37250254]\n",
      "Step: 162, Loss: 0.06835602223873138\n",
      "Weight:  [0.3702389]\n",
      "Step: 163, Loss: 0.06856872886419296\n",
      "Weight:  [0.36726984]\n",
      "Step: 164, Loss: 0.06831955164670944\n",
      "Weight:  [0.36437407]\n",
      "Step: 165, Loss: 0.06840065866708755\n",
      "Weight:  [0.36234292]\n",
      "Step: 166, Loss: 0.06803449243307114\n",
      "Weight:  [0.3620286]\n",
      "Step: 167, Loss: 0.06835085898637772\n",
      "Weight:  [0.36249825]\n",
      "Step: 168, Loss: 0.06826460361480713\n",
      "Weight:  [0.36300793]\n",
      "Step: 169, Loss: 0.06817560642957687\n",
      "Weight:  [0.36426553]\n",
      "Step: 170, Loss: 0.06818293780088425\n",
      "Weight:  [0.36557093]\n",
      "Step: 171, Loss: 0.0684211328625679\n",
      "Weight:  [0.366308]\n",
      "Step: 172, Loss: 0.06830371916294098\n",
      "Weight:  [0.3666088]\n",
      "Step: 173, Loss: 0.06809617578983307\n",
      "Weight:  [0.36705732]\n",
      "Step: 174, Loss: 0.0681324377655983\n",
      "Weight:  [0.36737895]\n",
      "Step: 175, Loss: 0.068184033036232\n",
      "Weight:  [0.36879972]\n",
      "Step: 176, Loss: 0.06834657490253448\n",
      "Weight:  [0.3708211]\n",
      "Step: 177, Loss: 0.06810002028942108\n",
      "Weight:  [0.37298706]\n",
      "Step: 178, Loss: 0.06824114918708801\n",
      "Weight:  [0.37426794]\n",
      "Step: 179, Loss: 0.06823413819074631\n",
      "Weight:  [0.37526497]\n",
      "Step: 180, Loss: 0.06834658980369568\n",
      "Weight:  [0.37663263]\n",
      "Step: 181, Loss: 0.06835245341062546\n",
      "Weight:  [0.37694457]\n",
      "Step: 182, Loss: 0.06796736270189285\n",
      "Weight:  [0.37657794]\n",
      "Step: 183, Loss: 0.06830320507287979\n",
      "Weight:  [0.37679008]\n",
      "Step: 184, Loss: 0.06816243380308151\n",
      "Weight:  [0.37645346]\n",
      "Step: 185, Loss: 0.06806568801403046\n",
      "Weight:  [0.3755357]\n",
      "Step: 186, Loss: 0.06801073253154755\n",
      "Weight:  [0.37507978]\n",
      "Step: 187, Loss: 0.0681011900305748\n",
      "Weight:  [0.37289485]\n",
      "Step: 188, Loss: 0.06807371228933334\n",
      "Weight:  [0.3717731]\n",
      "Step: 189, Loss: 0.06808748841285706\n",
      "Weight:  [0.3700122]\n",
      "Step: 190, Loss: 0.06818857789039612\n",
      "Weight:  [0.3681916]\n",
      "Step: 191, Loss: 0.06831400096416473\n",
      "Weight:  [0.3669835]\n",
      "Step: 192, Loss: 0.06837774813175201\n",
      "Weight:  [0.36624432]\n",
      "Step: 193, Loss: 0.06838518381118774\n",
      "Weight:  [0.3644587]\n",
      "Step: 194, Loss: 0.06803607940673828\n",
      "Weight:  [0.36201182]\n",
      "Step: 195, Loss: 0.068547822535038\n",
      "Weight:  [0.3597129]\n",
      "Step: 196, Loss: 0.06823968887329102\n",
      "Weight:  [0.3576521]\n",
      "Step: 197, Loss: 0.06781623512506485\n",
      "Weight:  [0.35673457]\n",
      "Step: 198, Loss: 0.06834826618432999\n",
      "Weight:  [0.35623112]\n",
      "Step: 199, Loss: 0.06829488277435303\n",
      "Weight:  [0.354902]\n",
      "Step: 200, Loss: 0.06826130300760269\n",
      "Weight:  [0.35240614]\n",
      "Step: 201, Loss: 0.06793586164712906\n",
      "Weight:  [0.34891966]\n",
      "Step: 202, Loss: 0.06825173646211624\n",
      "Weight:  [0.34578723]\n",
      "Step: 203, Loss: 0.06779246777296066\n",
      "Weight:  [0.34365162]\n",
      "Step: 204, Loss: 0.06810132414102554\n",
      "Weight:  [0.33907756]\n",
      "Step: 205, Loss: 0.06816831976175308\n",
      "Weight:  [0.33410206]\n",
      "Step: 206, Loss: 0.0682726725935936\n",
      "Weight:  [0.33042142]\n",
      "Step: 207, Loss: 0.06829671561717987\n",
      "Weight:  [0.3273147]\n",
      "Step: 208, Loss: 0.06815443187952042\n",
      "Weight:  [0.32418275]\n",
      "Step: 209, Loss: 0.06835765391588211\n",
      "Weight:  [0.32216567]\n",
      "Step: 210, Loss: 0.06844039261341095\n",
      "Weight:  [0.3213216]\n",
      "Step: 211, Loss: 0.06802371144294739\n",
      "Weight:  [0.3212118]\n",
      "Step: 212, Loss: 0.0685047134757042\n",
      "Weight:  [0.32071003]\n",
      "Step: 213, Loss: 0.06804122775793076\n",
      "Weight:  [0.3202194]\n",
      "Step: 214, Loss: 0.06812073290348053\n",
      "Weight:  [0.3188743]\n",
      "Step: 215, Loss: 0.06824552267789841\n",
      "Weight:  [0.31758878]\n",
      "Step: 216, Loss: 0.0683998167514801\n",
      "Weight:  [0.31677192]\n",
      "Step: 217, Loss: 0.06806083023548126\n",
      "Weight:  [0.31589857]\n",
      "Step: 218, Loss: 0.0681731104850769\n",
      "Weight:  [0.31537423]\n",
      "Step: 219, Loss: 0.06800582259893417\n",
      "Weight:  [0.3151867]\n",
      "Step: 220, Loss: 0.06819283217191696\n",
      "Weight:  [0.31515262]\n",
      "Step: 221, Loss: 0.06834867596626282\n",
      "Weight:  [0.31466118]\n",
      "Step: 222, Loss: 0.06836573034524918\n",
      "Weight:  [0.31404543]\n",
      "Step: 223, Loss: 0.06808064877986908\n",
      "Weight:  [0.31388873]\n",
      "Step: 224, Loss: 0.06789960712194443\n",
      "Weight:  [0.3133166]\n",
      "Step: 225, Loss: 0.06835486739873886\n",
      "Weight:  [0.31242338]\n",
      "Step: 226, Loss: 0.06825504451990128\n",
      "Weight:  [0.31084508]\n",
      "Step: 227, Loss: 0.06814319640398026\n",
      "Weight:  [0.3079419]\n",
      "Step: 228, Loss: 0.06825639307498932\n",
      "Weight:  [0.30382833]\n",
      "Step: 229, Loss: 0.06788547337055206\n",
      "Weight:  [0.29929173]\n",
      "Step: 230, Loss: 0.06833934783935547\n",
      "Weight:  [0.29540244]\n",
      "Step: 231, Loss: 0.06823795288801193\n",
      "Weight:  [0.292024]\n",
      "Step: 232, Loss: 0.06813495606184006\n",
      "Weight:  [0.29007733]\n",
      "Step: 233, Loss: 0.06822270900011063\n",
      "Weight:  [0.2877469]\n",
      "Step: 234, Loss: 0.06802806258201599\n",
      "Weight:  [0.28571203]\n",
      "Step: 235, Loss: 0.06833822280168533\n",
      "Weight:  [0.2851662]\n",
      "Step: 236, Loss: 0.06815130263566971\n",
      "Weight:  [0.28490305]\n",
      "Step: 237, Loss: 0.06819101423025131\n",
      "Weight:  [0.2849997]\n",
      "Step: 238, Loss: 0.06803300976753235\n",
      "Weight:  [0.28481424]\n",
      "Step: 239, Loss: 0.06790678948163986\n",
      "Weight:  [0.28334293]\n",
      "Step: 240, Loss: 0.06799633800983429\n",
      "Weight:  [0.28194803]\n",
      "Step: 241, Loss: 0.06854406744241714\n",
      "Weight:  [0.28150806]\n",
      "Step: 242, Loss: 0.06805720180273056\n",
      "Weight:  [0.28202945]\n",
      "Step: 243, Loss: 0.06814641505479813\n",
      "Weight:  [0.28221405]\n",
      "Step: 244, Loss: 0.06802887469530106\n",
      "Weight:  [0.2816925]\n",
      "Step: 245, Loss: 0.0678216814994812\n",
      "Weight:  [0.28131664]\n",
      "Step: 246, Loss: 0.06827767938375473\n",
      "Weight:  [0.28221276]\n",
      "Step: 247, Loss: 0.06821580231189728\n",
      "Weight:  [0.28272635]\n",
      "Step: 248, Loss: 0.06825447827577591\n",
      "Weight:  [0.28167796]\n",
      "Step: 249, Loss: 0.06835780292749405\n",
      "Weight:  [0.27962756]\n",
      "Step: 250, Loss: 0.0681890919804573\n",
      "Weight:  [0.277001]\n",
      "Step: 251, Loss: 0.06809981167316437\n",
      "Weight:  [0.2738053]\n",
      "Step: 252, Loss: 0.0682404562830925\n",
      "Weight:  [0.2704762]\n",
      "Step: 253, Loss: 0.06835584342479706\n",
      "Weight:  [0.2671799]\n",
      "Step: 254, Loss: 0.06800563633441925\n",
      "Weight:  [0.26551828]\n",
      "Step: 255, Loss: 0.068640798330307\n",
      "Weight:  [0.26393864]\n",
      "Step: 256, Loss: 0.06815271824598312\n",
      "Weight:  [0.2626452]\n",
      "Step: 257, Loss: 0.06819698214530945\n",
      "Weight:  [0.26135734]\n",
      "Step: 258, Loss: 0.06802255660295486\n",
      "Weight:  [0.25994688]\n",
      "Step: 259, Loss: 0.06797342002391815\n",
      "Weight:  [0.26088542]\n",
      "Step: 260, Loss: 0.06802096962928772\n",
      "Weight:  [0.26296717]\n",
      "Step: 261, Loss: 0.06795218586921692\n",
      "Weight:  [0.26492822]\n",
      "Step: 262, Loss: 0.06825288385152817\n",
      "Weight:  [0.26598722]\n",
      "Step: 263, Loss: 0.06787265837192535\n",
      "Weight:  [0.2674418]\n",
      "Step: 264, Loss: 0.06810496002435684\n",
      "Weight:  [0.2687575]\n",
      "Step: 265, Loss: 0.06816544383764267\n",
      "Weight:  [0.26859912]\n",
      "Step: 266, Loss: 0.06812591850757599\n",
      "Weight:  [0.26614323]\n",
      "Step: 267, Loss: 0.06814710795879364\n",
      "Weight:  [0.26502708]\n",
      "Step: 268, Loss: 0.06824281811714172\n",
      "Weight:  [0.2641872]\n",
      "Step: 269, Loss: 0.06768161803483963\n",
      "Weight:  [0.26264042]\n",
      "Step: 270, Loss: 0.06807415932416916\n",
      "Weight:  [0.2620368]\n",
      "Step: 271, Loss: 0.06838487088680267\n",
      "Weight:  [0.26145038]\n",
      "Step: 272, Loss: 0.0679791271686554\n",
      "Weight:  [0.26051006]\n",
      "Step: 273, Loss: 0.06817363947629929\n",
      "Weight:  [0.26159978]\n",
      "Step: 274, Loss: 0.06784354150295258\n",
      "Weight:  [0.26324412]\n",
      "Step: 275, Loss: 0.06826741248369217\n",
      "Weight:  [0.26351756]\n",
      "Step: 276, Loss: 0.06809788197278976\n",
      "Weight:  [0.26212034]\n",
      "Step: 277, Loss: 0.06789703667163849\n",
      "Weight:  [0.26113003]\n",
      "Step: 278, Loss: 0.0681033506989479\n",
      "Weight:  [0.26113155]\n",
      "Step: 279, Loss: 0.06789899617433548\n",
      "Weight:  [0.26050633]\n",
      "Step: 280, Loss: 0.06791892647743225\n",
      "Weight:  [0.26071274]\n",
      "Step: 281, Loss: 0.06802748143672943\n",
      "Weight:  [0.26164258]\n",
      "Step: 282, Loss: 0.06814099848270416\n",
      "Weight:  [0.2598556]\n",
      "Step: 283, Loss: 0.06806647777557373\n",
      "Weight:  [0.25894973]\n",
      "Step: 284, Loss: 0.06806937605142593\n",
      "Weight:  [0.2600117]\n",
      "Step: 285, Loss: 0.06828238070011139\n",
      "Weight:  [0.26215696]\n",
      "Step: 286, Loss: 0.06807910650968552\n",
      "Weight:  [0.2629244]\n",
      "Step: 287, Loss: 0.06801614910364151\n",
      "Weight:  [0.26334167]\n",
      "Step: 288, Loss: 0.0680706575512886\n",
      "Weight:  [0.2639417]\n",
      "Step: 289, Loss: 0.06785610318183899\n",
      "Weight:  [0.26427543]\n",
      "Step: 290, Loss: 0.06823648512363434\n",
      "Weight:  [0.26390097]\n",
      "Step: 291, Loss: 0.06811653077602386\n",
      "Weight:  [0.2626322]\n",
      "Step: 292, Loss: 0.06827504932880402\n",
      "Weight:  [0.26208767]\n",
      "Step: 293, Loss: 0.06820198148488998\n",
      "Weight:  [0.2619971]\n",
      "Step: 294, Loss: 0.06807353347539902\n",
      "Weight:  [0.2623878]\n",
      "Step: 295, Loss: 0.06808135658502579\n",
      "Weight:  [0.26419923]\n",
      "Step: 296, Loss: 0.06803648918867111\n",
      "Weight:  [0.26469085]\n",
      "Step: 297, Loss: 0.06796158850193024\n",
      "Weight:  [0.26433808]\n",
      "Step: 298, Loss: 0.06803882122039795\n",
      "Weight:  [0.2627906]\n",
      "Step: 299, Loss: 0.06805659830570221\n",
      "Weight:  [0.2609749]\n",
      "Step: 300, Loss: 0.06824415922164917\n",
      "Weight:  [0.2584794]\n",
      "Step: 301, Loss: 0.06788178533315659\n",
      "Weight:  [0.2576775]\n",
      "Step: 302, Loss: 0.06778587400913239\n",
      "Weight:  [0.25628456]\n",
      "Step: 303, Loss: 0.06800305098295212\n",
      "Weight:  [0.25601262]\n",
      "Step: 304, Loss: 0.06824666261672974\n",
      "Weight:  [0.255771]\n",
      "Step: 305, Loss: 0.06836148351430893\n",
      "Weight:  [0.25498298]\n",
      "Step: 306, Loss: 0.06786394119262695\n",
      "Weight:  [0.25390878]\n",
      "Step: 307, Loss: 0.06815579533576965\n",
      "Weight:  [0.2530699]\n",
      "Step: 308, Loss: 0.06809800863265991\n",
      "Weight:  [0.25399217]\n",
      "Step: 309, Loss: 0.0679614245891571\n",
      "Weight:  [0.25491133]\n",
      "Step: 310, Loss: 0.06792666763067245\n",
      "Weight:  [0.2570695]\n",
      "Step: 311, Loss: 0.06830836832523346\n",
      "Weight:  [0.25850618]\n",
      "Step: 312, Loss: 0.06795880943536758\n",
      "Weight:  [0.25691438]\n",
      "Step: 313, Loss: 0.06798896938562393\n",
      "Weight:  [0.25624433]\n",
      "Step: 314, Loss: 0.06804656237363815\n",
      "Weight:  [0.25688207]\n",
      "Step: 315, Loss: 0.068202443420887\n",
      "Weight:  [0.2578027]\n",
      "Step: 316, Loss: 0.06815407425165176\n",
      "Weight:  [0.2580134]\n",
      "Step: 317, Loss: 0.06809894740581512\n",
      "Weight:  [0.25851348]\n",
      "Step: 318, Loss: 0.06804672628641129\n",
      "Weight:  [0.25898486]\n",
      "Step: 319, Loss: 0.06833536922931671\n",
      "Weight:  [0.2580488]\n",
      "Step: 320, Loss: 0.06808038800954819\n",
      "Weight:  [0.2571749]\n",
      "Step: 321, Loss: 0.0680643767118454\n",
      "Weight:  [0.2559338]\n",
      "Step: 322, Loss: 0.06794430315494537\n",
      "Weight:  [0.2538251]\n",
      "Step: 323, Loss: 0.06794391572475433\n",
      "Weight:  [0.25313336]\n",
      "Step: 324, Loss: 0.06833530217409134\n",
      "Weight:  [0.2534074]\n",
      "Step: 325, Loss: 0.0680851936340332\n",
      "Weight:  [0.2542102]\n",
      "Step: 326, Loss: 0.06798258423805237\n",
      "Weight:  [0.2551937]\n",
      "Step: 327, Loss: 0.06829001754522324\n",
      "Weight:  [0.25573924]\n",
      "Step: 328, Loss: 0.06815367937088013\n",
      "Weight:  [0.25678876]\n",
      "Step: 329, Loss: 0.06810280680656433\n",
      "Weight:  [0.25850496]\n",
      "Step: 330, Loss: 0.0680377408862114\n",
      "Weight:  [0.25938654]\n",
      "Step: 331, Loss: 0.06786669790744781\n",
      "Weight:  [0.2598847]\n",
      "Step: 332, Loss: 0.06833754479885101\n",
      "Weight:  [0.2599247]\n",
      "Step: 333, Loss: 0.0678446963429451\n",
      "Weight:  [0.26012245]\n",
      "Step: 334, Loss: 0.06820372492074966\n",
      "Weight:  [0.25985393]\n",
      "Step: 335, Loss: 0.067886121571064\n",
      "Weight:  [0.25906754]\n",
      "Step: 336, Loss: 0.06809389591217041\n",
      "Weight:  [0.258219]\n",
      "Step: 337, Loss: 0.06792380660772324\n",
      "Weight:  [0.2573205]\n",
      "Step: 338, Loss: 0.06830841302871704\n",
      "Weight:  [0.25646693]\n",
      "Step: 339, Loss: 0.06827780604362488\n",
      "Weight:  [0.25561604]\n",
      "Step: 340, Loss: 0.06814379245042801\n",
      "Weight:  [0.25517634]\n",
      "Step: 341, Loss: 0.06794077903032303\n",
      "Weight:  [0.25542322]\n",
      "Step: 342, Loss: 0.06805019825696945\n",
      "Weight:  [0.25599515]\n",
      "Step: 343, Loss: 0.06799647957086563\n",
      "Weight:  [0.25746584]\n",
      "Step: 344, Loss: 0.06817850470542908\n",
      "Weight:  [0.2597995]\n",
      "Step: 345, Loss: 0.06796317547559738\n",
      "Weight:  [0.26327494]\n",
      "Step: 346, Loss: 0.06800341606140137\n",
      "Weight:  [0.26610467]\n",
      "Step: 347, Loss: 0.0681421235203743\n",
      "Weight:  [0.26912862]\n",
      "Step: 348, Loss: 0.0682048499584198\n",
      "Weight:  [0.27092192]\n",
      "Step: 349, Loss: 0.06812845170497894\n",
      "Weight:  [0.2720297]\n",
      "Step: 350, Loss: 0.06789255142211914\n",
      "Weight:  [0.27384883]\n",
      "Step: 351, Loss: 0.0679188072681427\n",
      "Weight:  [0.27424228]\n",
      "Step: 352, Loss: 0.0680084303021431\n",
      "Weight:  [0.27250195]\n",
      "Step: 353, Loss: 0.06806813925504684\n",
      "Weight:  [0.27142683]\n",
      "Step: 354, Loss: 0.06799440830945969\n",
      "Weight:  [0.27107817]\n",
      "Step: 355, Loss: 0.06809447705745697\n",
      "Weight:  [0.27048633]\n",
      "Step: 356, Loss: 0.06820136308670044\n",
      "Weight:  [0.2713454]\n",
      "Step: 357, Loss: 0.06802193820476532\n",
      "Weight:  [0.27346593]\n",
      "Step: 358, Loss: 0.06819397211074829\n",
      "Weight:  [0.27512652]\n",
      "Step: 359, Loss: 0.06808691471815109\n",
      "Weight:  [0.27666354]\n",
      "Step: 360, Loss: 0.0680113136768341\n",
      "Weight:  [0.27749804]\n",
      "Step: 361, Loss: 0.06815946102142334\n",
      "Weight:  [0.27791205]\n",
      "Step: 362, Loss: 0.06799052655696869\n",
      "Weight:  [0.28006357]\n",
      "Step: 363, Loss: 0.06804239004850388\n",
      "Weight:  [0.28195015]\n",
      "Step: 364, Loss: 0.06787566840648651\n",
      "Weight:  [0.28203115]\n",
      "Step: 365, Loss: 0.06807296723127365\n",
      "Weight:  [0.2817403]\n",
      "Step: 366, Loss: 0.06815510988235474\n",
      "Weight:  [0.28122616]\n",
      "Step: 367, Loss: 0.068155936896801\n",
      "Weight:  [0.28006488]\n",
      "Step: 368, Loss: 0.06780712306499481\n",
      "Weight:  [0.27843225]\n",
      "Step: 369, Loss: 0.0683620348572731\n",
      "Weight:  [0.27747965]\n",
      "Step: 370, Loss: 0.0679764375090599\n",
      "Weight:  [0.27641]\n",
      "Step: 371, Loss: 0.06801030784845352\n",
      "Weight:  [0.276373]\n",
      "Step: 372, Loss: 0.06793129444122314\n",
      "Weight:  [0.27574563]\n",
      "Step: 373, Loss: 0.0680822879076004\n",
      "Weight:  [0.27472478]\n",
      "Step: 374, Loss: 0.06808813661336899\n",
      "Weight:  [0.27297089]\n",
      "Step: 375, Loss: 0.06833372265100479\n",
      "Weight:  [0.27159625]\n",
      "Step: 376, Loss: 0.06801401823759079\n",
      "Weight:  [0.2704762]\n",
      "Step: 377, Loss: 0.06792696565389633\n",
      "Weight:  [0.26940206]\n",
      "Step: 378, Loss: 0.06798240542411804\n",
      "Weight:  [0.26855865]\n",
      "Step: 379, Loss: 0.0681256577372551\n",
      "Weight:  [0.2664092]\n",
      "Step: 380, Loss: 0.06799007207155228\n",
      "Weight:  [0.2636304]\n",
      "Step: 381, Loss: 0.068021759390831\n",
      "Weight:  [0.25853193]\n",
      "Step: 382, Loss: 0.06809381395578384\n",
      "Weight:  [0.25399536]\n",
      "Step: 383, Loss: 0.06799600273370743\n",
      "Weight:  [0.24991821]\n",
      "Step: 384, Loss: 0.06828045845031738\n",
      "Weight:  [0.24623883]\n",
      "Step: 385, Loss: 0.06794784963130951\n",
      "Weight:  [0.24381547]\n",
      "Step: 386, Loss: 0.06812373548746109\n",
      "Weight:  [0.24001856]\n",
      "Step: 387, Loss: 0.06836004555225372\n",
      "Weight:  [0.23707946]\n",
      "Step: 388, Loss: 0.06813845038414001\n",
      "Weight:  [0.23590712]\n",
      "Step: 389, Loss: 0.06796340644359589\n",
      "Weight:  [0.2351944]\n",
      "Step: 390, Loss: 0.06788099557161331\n",
      "Weight:  [0.23351271]\n",
      "Step: 391, Loss: 0.0680486261844635\n",
      "Weight:  [0.23268771]\n",
      "Step: 392, Loss: 0.06806956976652145\n",
      "Weight:  [0.23318577]\n",
      "Step: 393, Loss: 0.06817310303449631\n",
      "Weight:  [0.23313601]\n",
      "Step: 394, Loss: 0.06817549467086792\n",
      "Weight:  [0.23392732]\n",
      "Step: 395, Loss: 0.0682433620095253\n",
      "Weight:  [0.23647381]\n",
      "Step: 396, Loss: 0.06795813143253326\n",
      "Weight:  [0.23842202]\n",
      "Step: 397, Loss: 0.06813311576843262\n",
      "Weight:  [0.24018285]\n",
      "Step: 398, Loss: 0.0679752379655838\n",
      "Weight:  [0.24262874]\n",
      "Step: 399, Loss: 0.06801145523786545\n",
      "Weight:  [0.24456125]\n",
      "Step: 400, Loss: 0.06798898428678513\n",
      "Weight:  [0.2479411]\n",
      "Step: 401, Loss: 0.06788704544305801\n",
      "Weight:  [0.2522981]\n",
      "Step: 402, Loss: 0.06790224462747574\n",
      "Weight:  [0.25498837]\n",
      "Step: 403, Loss: 0.06818854063749313\n",
      "Weight:  [0.25650993]\n",
      "Step: 404, Loss: 0.06809356808662415\n",
      "Weight:  [0.25698525]\n",
      "Step: 405, Loss: 0.0681300237774849\n",
      "Weight:  [0.2582392]\n",
      "Step: 406, Loss: 0.06819517910480499\n",
      "Weight:  [0.25969866]\n",
      "Step: 407, Loss: 0.06795477122068405\n",
      "Weight:  [0.26083583]\n",
      "Step: 408, Loss: 0.06784767657518387\n",
      "Weight:  [0.2631927]\n",
      "Step: 409, Loss: 0.0679483711719513\n",
      "Weight:  [0.2647565]\n",
      "Step: 410, Loss: 0.06831890344619751\n",
      "Weight:  [0.2679218]\n",
      "Step: 411, Loss: 0.0680966004729271\n",
      "Weight:  [0.2706044]\n",
      "Step: 412, Loss: 0.0679904893040657\n",
      "Weight:  [0.272678]\n",
      "Step: 413, Loss: 0.06796184182167053\n",
      "Weight:  [0.27492464]\n",
      "Step: 414, Loss: 0.0679979994893074\n",
      "Weight:  [0.27728307]\n",
      "Step: 415, Loss: 0.06792362779378891\n",
      "Weight:  [0.28095677]\n",
      "Step: 416, Loss: 0.06815861165523529\n",
      "Weight:  [0.28453562]\n",
      "Step: 417, Loss: 0.06793230026960373\n",
      "Weight:  [0.2865873]\n",
      "Step: 418, Loss: 0.0682874470949173\n",
      "Weight:  [0.28787705]\n",
      "Step: 419, Loss: 0.06797035038471222\n",
      "Weight:  [0.29044896]\n",
      "Step: 420, Loss: 0.06793894618749619\n",
      "Weight:  [0.29315725]\n",
      "Step: 421, Loss: 0.06811348348855972\n",
      "Weight:  [0.29571733]\n",
      "Step: 422, Loss: 0.06795115768909454\n",
      "Weight:  [0.29705822]\n",
      "Step: 423, Loss: 0.06803113967180252\n",
      "Weight:  [0.29916576]\n",
      "Step: 424, Loss: 0.06804732233285904\n",
      "Weight:  [0.29996932]\n",
      "Step: 425, Loss: 0.06803345680236816\n",
      "Weight:  [0.30185753]\n",
      "Step: 426, Loss: 0.06798291206359863\n",
      "Weight:  [0.30436224]\n",
      "Step: 427, Loss: 0.06793094426393509\n",
      "Weight:  [0.30860186]\n",
      "Step: 428, Loss: 0.06832484900951385\n",
      "Weight:  [0.31314]\n",
      "Step: 429, Loss: 0.06815966218709946\n",
      "Weight:  [0.31878498]\n",
      "Step: 430, Loss: 0.06794636696577072\n",
      "Weight:  [0.32364753]\n",
      "Step: 431, Loss: 0.06772265583276749\n",
      "Weight:  [0.32719806]\n",
      "Step: 432, Loss: 0.06777001172304153\n",
      "Weight:  [0.32935435]\n",
      "Step: 433, Loss: 0.0677608847618103\n",
      "Weight:  [0.3312287]\n",
      "Step: 434, Loss: 0.06799201667308807\n",
      "Weight:  [0.33235303]\n",
      "Step: 435, Loss: 0.06807823479175568\n",
      "Weight:  [0.3331548]\n",
      "Step: 436, Loss: 0.06810153275728226\n",
      "Weight:  [0.3346652]\n",
      "Step: 437, Loss: 0.06809215247631073\n",
      "Weight:  [0.33610493]\n",
      "Step: 438, Loss: 0.06792519986629486\n",
      "Weight:  [0.33903167]\n",
      "Step: 439, Loss: 0.06801112741231918\n",
      "Weight:  [0.34260345]\n",
      "Step: 440, Loss: 0.06775742769241333\n",
      "Weight:  [0.34576413]\n",
      "Step: 441, Loss: 0.06779919564723969\n",
      "Weight:  [0.3488591]\n",
      "Step: 442, Loss: 0.06778854876756668\n",
      "Weight:  [0.35210598]\n",
      "Step: 443, Loss: 0.06786497682332993\n",
      "Weight:  [0.3556053]\n",
      "Step: 444, Loss: 0.06804631650447845\n",
      "Weight:  [0.36099505]\n",
      "Step: 445, Loss: 0.06793323159217834\n",
      "Weight:  [0.3657746]\n",
      "Step: 446, Loss: 0.0681951716542244\n",
      "Weight:  [0.37003544]\n",
      "Step: 447, Loss: 0.0681154653429985\n",
      "Weight:  [0.37368742]\n",
      "Step: 448, Loss: 0.06804300844669342\n",
      "Weight:  [0.37589115]\n",
      "Step: 449, Loss: 0.06808032840490341\n",
      "Weight:  [0.3780525]\n",
      "Step: 450, Loss: 0.0677933320403099\n",
      "Weight:  [0.37942377]\n",
      "Step: 451, Loss: 0.06797796487808228\n",
      "Weight:  [0.3810292]\n",
      "Step: 452, Loss: 0.06798898428678513\n",
      "Weight:  [0.3813289]\n",
      "Step: 453, Loss: 0.06809869408607483\n",
      "Weight:  [0.38136962]\n",
      "Step: 454, Loss: 0.06797271221876144\n",
      "Weight:  [0.3825728]\n",
      "Step: 455, Loss: 0.06786823272705078\n",
      "Weight:  [0.384558]\n",
      "Step: 456, Loss: 0.06794312596321106\n",
      "Weight:  [0.3845099]\n",
      "Step: 457, Loss: 0.06791482865810394\n",
      "Weight:  [0.3839562]\n",
      "Step: 458, Loss: 0.0682821050286293\n",
      "Weight:  [0.38374156]\n",
      "Step: 459, Loss: 0.06798586249351501\n",
      "Weight:  [0.38428372]\n",
      "Step: 460, Loss: 0.06805258244276047\n",
      "Weight:  [0.38401106]\n",
      "Step: 461, Loss: 0.06811689585447311\n",
      "Weight:  [0.3843425]\n",
      "Step: 462, Loss: 0.06793894618749619\n",
      "Weight:  [0.38361332]\n",
      "Step: 463, Loss: 0.06790104508399963\n",
      "Weight:  [0.38259256]\n",
      "Step: 464, Loss: 0.06808211654424667\n",
      "Weight:  [0.3812836]\n",
      "Step: 465, Loss: 0.06805780529975891\n",
      "Weight:  [0.38121134]\n",
      "Step: 466, Loss: 0.06801662594079971\n",
      "Weight:  [0.38011095]\n",
      "Step: 467, Loss: 0.06800024211406708\n",
      "Weight:  [0.37883383]\n",
      "Step: 468, Loss: 0.06768788397312164\n",
      "Weight:  [0.3765732]\n",
      "Step: 469, Loss: 0.0680728405714035\n",
      "Weight:  [0.37409365]\n",
      "Step: 470, Loss: 0.06796439737081528\n",
      "Weight:  [0.37051234]\n",
      "Step: 471, Loss: 0.06830311566591263\n",
      "Weight:  [0.36750036]\n",
      "Step: 472, Loss: 0.06804950535297394\n",
      "Weight:  [0.3654025]\n",
      "Step: 473, Loss: 0.0679810419678688\n",
      "Weight:  [0.36191326]\n",
      "Step: 474, Loss: 0.06778404861688614\n",
      "Weight:  [0.36008897]\n",
      "Step: 475, Loss: 0.06833765655755997\n",
      "Weight:  [0.35871267]\n",
      "Step: 476, Loss: 0.06778787076473236\n",
      "Weight:  [0.35729137]\n",
      "Step: 477, Loss: 0.06768141686916351\n",
      "Weight:  [0.35712713]\n",
      "Step: 478, Loss: 0.06810955703258514\n",
      "Weight:  [0.35735258]\n",
      "Step: 479, Loss: 0.06830443441867828\n",
      "Weight:  [0.35755426]\n",
      "Step: 480, Loss: 0.06797221302986145\n",
      "Weight:  [0.35962865]\n",
      "Step: 481, Loss: 0.0680161714553833\n",
      "Weight:  [0.3618909]\n",
      "Step: 482, Loss: 0.06785549223423004\n",
      "Weight:  [0.36475366]\n",
      "Step: 483, Loss: 0.06792782992124557\n",
      "Weight:  [0.36670333]\n",
      "Step: 484, Loss: 0.0681801438331604\n",
      "Weight:  [0.3678337]\n",
      "Step: 485, Loss: 0.06810414791107178\n",
      "Weight:  [0.36886486]\n",
      "Step: 486, Loss: 0.06777253746986389\n"
     ]
    }
   ],
   "source": [
    "model = train_and_save(\n",
    "    forecast_distribution,\n",
    "    loss,\n",
    "    optimizer,\n",
    "    learning_rate,\n",
    "    folds,\n",
    "    parameter_names,\n",
    "    neighbourhood_size,\n",
    "    ignore,\n",
    "    epochs,\n",
    "\n",
    "    chain_function = chain_function,\n",
    "    chain_function_mean = chain_function_mean,\n",
    "    chain_function_std = chain_function_std,\n",
    "    chain_function_constant = chain_function_constant,\n",
    "    chain_function_threshold = chain_function_threshold,\n",
    "    samples = samples,\n",
    "    printing = printing,\n",
    "    distribution_1 = distribution_1,\n",
    "    distribution_2 = distribution_2,\n",
    "    pretrained = pretrained\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 200)\n",
      "Forecast distribution: distr_mixture\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_gev\n",
      "Mixture weight: [0.6714824]\n",
      "Parameters:\n",
      "  weight: [0.6714824]\n",
      "  a_tn: [0.8587427]\n",
      "  b_tn: [ 0.9033643  -0.8743947  -0.10445029 -0.27649736  0.85969   ]\n",
      "  c_tn: [1.8735183]\n",
      "  d_tn: [0.7428804]\n",
      "  a_gev: [-0.4236689]\n",
      "  b_gev: [ 0.9333376   0.5409048  -0.3650169   0.3564078   0.61552596]\n",
      "  c_gev: [1.4305779]\n",
      "  d_gev: [ 0.09890767 -0.5423227   0.16434298  0.31506124 -0.69037396]\n",
      "  e_gev: [-0.31247506]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 13.0, Std: 4.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
