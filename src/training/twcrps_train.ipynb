{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 16:15:54.057296: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-07 16:15:54.083805: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-07 16:15:54.083837: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-07 16:15:54.084591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-07 16:15:54.088809: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-07 16:15:54.089345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 16:15:59.838234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from src.models.train_emos import train_emos, train_and_test_emos\n",
    "from src.visualization.pit import make_cpit_diagram_emos, make_cpit_hist_emos \n",
    "from src.visualization.brier_score import brier_skill_plot, brier_plot\n",
    "from src.models.get_data import get_tensors, get_normalized_tensor\n",
    "from src.models.emos import EMOS\n",
    "from src.visualization.scoring_tables import make_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15733, 5)\n"
     ]
    }
   ],
   "source": [
    "neighbourhood_size = 11\n",
    "parameter_names = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "ignore = ['229', '285', '323']\n",
    "train_folds = [1, 2]\n",
    "train_data = get_normalized_tensor(neighbourhood_size, parameter_names, train_folds, ignore)\n",
    "\n",
    "X_train = train_data['X']\n",
    "y_train = train_data['y']\n",
    "variances_train = train_data['variances']\n",
    "mean_train = train_data['mean']\n",
    "std_train = train_data['std']\n",
    "\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7780, 5)\n"
     ]
    }
   ],
   "source": [
    "test_fold = 3\n",
    "\n",
    "X_test, y_test, variances_test = get_tensors(neighbourhood_size, parameter_names, test_fold, ignore)\n",
    "X_test = (X_test - mean_train) / std_train\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {}\n",
    "\n",
    "setup[\"num_features\"] = len(parameter_names)\n",
    "setup[\"feature_mean\"] = mean_train\n",
    "setup[\"feature_std\"] = std_train\n",
    "setup[\"features\"] = parameter_names\n",
    "setup[\"neighbourhood_size\"] = neighbourhood_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Log Normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default parameters for Frechet distribution\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "models_twcrps = {}\n",
    "setup1 = setup\n",
    "\n",
    "setup1[\"loss\"] = \"loss_twCRPS_sample\"\n",
    "setup1[\"chain_function\"] = \"chain_function_normal_cdf\"\n",
    "setup1[\"chain_function_mean\"] = 11\n",
    "setup1[\"chain_function_std\"] = 1\n",
    "setup1[\"samples\"] = 300\n",
    "setup1[\"optimizer\"] = \"Adam\"\n",
    "setup1[\"learning_rate\"] = 0.01\n",
    "setup1[\"forecast_distribution\"] = \"distr_trunc_normal\"\n",
    "\n",
    "twcrps_tn = EMOS(setup1)\n",
    "\n",
    "setup1[\"forecast_distribution\"] = \"distr_log_normal\"\n",
    "\n",
    "twcrps_ln = EMOS(setup1)\n",
    "\n",
    "setup1[\"forecast_distribution\"] = \"distr_gev\"\n",
    "setup1[\"samples\"] = 300\n",
    "\n",
    "twcrps_gev = EMOS(setup1)\n",
    "\n",
    "setup1[\"forecast_distribution\"] = \"distr_frechet\"\n",
    "\n",
    "twcrps_frechet = EMOS(setup1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models_twcrps[\"twcrps_tn\"] = twcrps_tn\n",
    "models_twcrps[\"twcrps_ln\"] = twcrps_ln\n",
    "models_twcrps[\"twcrps_gev\"] = twcrps_gev\n",
    "models_twcrps[\"twcrps_frechet\"] = twcrps_frechet\n",
    "\n",
    "\n",
    "print(len(models_twcrps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss:  0.08807499\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_trunc_normal\n",
      "Parameters:\n",
      "  a_tn: [0.9534113]\n",
      "  b_tn: [ 0.8797114  -1.1838744  -0.1318484  -0.14606379  1.2007395 ]\n",
      "  c_tn: [2.9175513]\n",
      "  d_tn: [0.725646]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n",
      "Final loss:  0.08865459\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_log_normal\n",
      "Parameters:\n",
      "  a_ln: [1.6291347]\n",
      "  b_ln: [ 0.06679348 -0.10326554 -0.00933671 -0.0155539   0.10231003]\n",
      "  c_ln: [0.02253972]\n",
      "  d_ln: [0.00232143]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n",
      "Final loss:  0.087120906\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_gev\n",
      "Parameters:\n",
      "  a_gev: [1.3011674]\n",
      "  b_gev: [ 0.81226045 -0.9397855  -0.1333115  -0.15215431  1.3413646 ]\n",
      "  c_gev: [0.6168851]\n",
      "  d_gev: [ 0.10680288 -0.15241647 -0.02441501  0.0288957  -0.35290807]\n",
      "  e_gev: [-0.26645383]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n",
      "Final loss:  0.086748004\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_frechet\n",
      "Parameters:\n",
      "  a_fr: [1.4941868]\n",
      "  b_fr: [ 0.79374945 -1.1009941  -0.12904409 -0.195281    1.4099872 ]\n",
      "  c_fr: [0.23710474]\n",
      "  d_fr: [ 0.11024628  0.01497647 -0.02048045  0.05502564 -0.33087912]\n",
      "  e_fr: [-0.]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 600\n",
    "\n",
    "for model in models_twcrps:\n",
    "    models_twcrps[model].fit(X_train, y_train, variances_train, epochs, printing=False)\n",
    "    print(\"Model: \", models_twcrps[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Log Normal distribution\n",
      "Using default weight parameter for Mixture distribution\n",
      "Parameter a_tn set to [0.9534113]\n",
      "Parameter b_tn set to [ 0.8797114  -1.1838744  -0.1318484  -0.14606379  1.2007395 ]\n",
      "Parameter c_tn set to [2.9175513]\n",
      "Parameter d_tn set to [0.725646]\n",
      "Parameter a_ln set to [1.6291347]\n",
      "Parameter b_ln set to [ 0.06679348 -0.10326554 -0.00933671 -0.0155539   0.10231003]\n",
      "Parameter c_ln set to [0.02253972]\n",
      "Parameter d_ln set to [0.00232143]\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameter for Mixture distribution\n",
      "Parameter a_tn set to [0.9534113]\n",
      "Parameter b_tn set to [ 0.8797114  -1.1838744  -0.1318484  -0.14606379  1.2007395 ]\n",
      "Parameter c_tn set to [2.9175513]\n",
      "Parameter d_tn set to [0.725646]\n",
      "Parameter a_gev set to [1.3011674]\n",
      "Parameter b_gev set to [ 0.81226045 -0.9397855  -0.1333115  -0.15215431  1.3413646 ]\n",
      "Parameter c_gev set to [0.6168851]\n",
      "Parameter d_gev set to [ 0.10680288 -0.15241647 -0.02441501  0.0288957  -0.35290807]\n",
      "Parameter e_gev set to [-0.26645383]\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Frechet distribution\n",
      "Using default weight parameter for Mixture distribution\n",
      "Parameter a_tn set to [0.9534113]\n",
      "Parameter b_tn set to [ 0.8797114  -1.1838744  -0.1318484  -0.14606379  1.2007395 ]\n",
      "Parameter c_tn set to [2.9175513]\n",
      "Parameter d_tn set to [0.725646]\n",
      "Parameter a_fr set to [1.4941868]\n",
      "Parameter b_fr set to [ 0.79374945 -1.1009941  -0.12904409 -0.195281    1.4099872 ]\n",
      "Parameter c_fr set to [0.23710474]\n",
      "Parameter d_fr set to [ 0.11024628  0.01497647 -0.02048045  0.05502564 -0.33087912]\n",
      "Parameter e_fr set to [-0.]\n"
     ]
    }
   ],
   "source": [
    "setup1[\"forecast_distribution\"] = \"distr_mixture\"\n",
    "setup1[\"distribution_1\"] = \"distr_trunc_normal\"\n",
    "setup1[\"distribution_2\"] = \"distr_log_normal\"\n",
    "\n",
    "twcrps_mix_tn_ln = EMOS(setup1)\n",
    "twcrps_mix_tn_ln.set_parameters(models_twcrps[\"twcrps_tn\"].get_parameters())\n",
    "twcrps_mix_tn_ln.set_parameters(models_twcrps[\"twcrps_ln\"].get_parameters())\n",
    "\n",
    "setup1[\"distribution_2\"] = \"distr_gev\"\n",
    "twcrps_mix_tn_gev = EMOS(setup1)\n",
    "\n",
    "twcrps_mix_tn_gev.set_parameters(models_twcrps[\"twcrps_tn\"].get_parameters())\n",
    "twcrps_mix_tn_gev.set_parameters(models_twcrps[\"twcrps_gev\"].get_parameters())\n",
    "\n",
    "setup1[\"distribution_2\"] = \"distr_frechet\"\n",
    "twcrps_mix_tn_frechet = EMOS(setup1)\n",
    "\n",
    "twcrps_mix_tn_frechet.set_parameters(models_twcrps[\"twcrps_tn\"].get_parameters())\n",
    "twcrps_mix_tn_frechet.set_parameters(models_twcrps[\"twcrps_frechet\"].get_parameters())\n",
    "\n",
    "models_twcrps[\"twcrps_mix_tn_ln\"] = twcrps_mix_tn_ln\n",
    "models_twcrps[\"twcrps_mix_tn_gev\"] = twcrps_mix_tn_gev\n",
    "models_twcrps[\"twcrps_mix_tn_frechet\"] = twcrps_mix_tn_frechet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss:  0.08729197\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_mixture\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_log_normal\n",
      "Mixture weight: [0.815861]\n",
      "Parameters:\n",
      "  weight: [0.815861]\n",
      "  a_tn: [0.8410446]\n",
      "  b_tn: [ 0.95003873 -0.5831397  -0.2337767   0.7219191   1.2121167 ]\n",
      "  c_tn: [3.564786]\n",
      "  d_tn: [0.7669719]\n",
      "  a_ln: [1.6238265]\n",
      "  b_ln: [ 0.04070468 -0.35114396  0.01846181 -0.2688914   0.16095191]\n",
      "  c_ln: [0.13998362]\n",
      "  d_ln: [-0.]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n",
      "Final loss:  0.08670479\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_mixture\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_gev\n",
      "Mixture weight: [0.4392965]\n",
      "Parameters:\n",
      "  weight: [0.4392965]\n",
      "  a_tn: [0.9310167]\n",
      "  b_tn: [ 0.8569393  -1.4139242  -0.15821086 -0.22407182  1.5888988 ]\n",
      "  c_tn: [2.5550318]\n",
      "  d_tn: [1.8088522]\n",
      "  a_gev: [1.2887068]\n",
      "  b_gev: [ 0.79921776 -1.1730573  -0.14743268 -0.24392915  1.7454745 ]\n",
      "  c_gev: [0.9222183]\n",
      "  d_gev: [ 0.18368971  0.28095564  0.01588156  0.27375    -1.3347136 ]\n",
      "  e_gev: [-0.35204118]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n",
      "Final loss:  0.08687732\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_mixture\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_frechet\n",
      "Mixture weight: [0.5187032]\n",
      "Parameters:\n",
      "  weight: [0.5187032]\n",
      "  a_tn: [1.1086823]\n",
      "  b_tn: [ 0.83811325 -1.4852406  -0.15189467 -0.24250464  1.7029363 ]\n",
      "  c_tn: [3.8315425]\n",
      "  d_tn: [1.4945604]\n",
      "  a_fr: [1.6435679]\n",
      "  b_fr: [ 0.7653867  -1.3558252  -0.13877797 -0.28894684  1.8616893 ]\n",
      "  c_fr: [-0.27583528]\n",
      "  d_fr: [ 0.22426042  0.50954694  0.00878317  0.33814234 -1.4113777 ]\n",
      "  e_fr: [-0.]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_twcrps[\"twcrps_mix_tn_ln\"].fit(X_train, y_train, variances_train, epochs, printing=False)\n",
    "print(\"Model: \", models_twcrps[\"twcrps_mix_tn_ln\"])\n",
    "\n",
    "models_twcrps[\"twcrps_mix_tn_gev\"].fit(X_train, y_train, variances_train, epochs, printing=False)\n",
    "print(\"Model: \", models_twcrps[\"twcrps_mix_tn_gev\"])\n",
    "\n",
    "models_twcrps[\"twcrps_mix_tn_frechet\"].fit(X_train, y_train, variances_train, epochs, printing=False)\n",
    "print(\"Model: \", models_twcrps[\"twcrps_mix_tn_frechet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Log Normal distribution\n",
      "Using default weight parameters for weights in Mixture Linear distribution\n",
      "Parameter a_tn set to [0.9534113]\n",
      "Parameter b_tn set to [ 0.8797114  -1.1838744  -0.1318484  -0.14606379  1.2007395 ]\n",
      "Parameter c_tn set to [2.9175513]\n",
      "Parameter d_tn set to [0.725646]\n",
      "Parameter a_ln set to [1.6291347]\n",
      "Parameter b_ln set to [ 0.06679348 -0.10326554 -0.00933671 -0.0155539   0.10231003]\n",
      "Parameter c_ln set to [0.02253972]\n",
      "Parameter d_ln set to [0.00232143]\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default weight parameters for weights in Mixture Linear distribution\n",
      "Parameter a_tn set to [0.9534113]\n",
      "Parameter b_tn set to [ 0.8797114  -1.1838744  -0.1318484  -0.14606379  1.2007395 ]\n",
      "Parameter c_tn set to [2.9175513]\n",
      "Parameter d_tn set to [0.725646]\n",
      "Parameter a_gev set to [1.3011674]\n",
      "Parameter b_gev set to [ 0.81226045 -0.9397855  -0.1333115  -0.15215431  1.3413646 ]\n",
      "Parameter c_gev set to [0.6168851]\n",
      "Parameter d_gev set to [ 0.10680288 -0.15241647 -0.02441501  0.0288957  -0.35290807]\n",
      "Parameter e_gev set to [-0.26645383]\n",
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for Frechet distribution\n",
      "Using default weight parameters for weights in Mixture Linear distribution\n",
      "Parameter a_tn set to [0.9534113]\n",
      "Parameter b_tn set to [ 0.8797114  -1.1838744  -0.1318484  -0.14606379  1.2007395 ]\n",
      "Parameter c_tn set to [2.9175513]\n",
      "Parameter d_tn set to [0.725646]\n",
      "Parameter a_fr set to [1.4941868]\n",
      "Parameter b_fr set to [ 0.79374945 -1.1009941  -0.12904409 -0.195281    1.4099872 ]\n",
      "Parameter c_fr set to [0.23710474]\n",
      "Parameter d_fr set to [ 0.11024628  0.01497647 -0.02048045  0.05502564 -0.33087912]\n",
      "Parameter e_fr set to [-0.]\n"
     ]
    }
   ],
   "source": [
    "setup1[\"forecast_distribution\"] = \"distr_mixture_linear\"\n",
    "setup1[\"distribution_1\"] = \"distr_trunc_normal\"\n",
    "setup1[\"distribution_2\"] = \"distr_log_normal\"\n",
    "\n",
    "twcrps_mixlinear_tn_ln = EMOS(setup1)\n",
    "twcrps_mixlinear_tn_ln.set_parameters(models_twcrps[\"twcrps_tn\"].get_parameters())\n",
    "twcrps_mixlinear_tn_ln.set_parameters(models_twcrps[\"twcrps_ln\"].get_parameters())\n",
    "\n",
    "setup1[\"distribution_2\"] = \"distr_gev\"\n",
    "twcrps_mixlinear_tn_gev = EMOS(setup1)\n",
    "\n",
    "twcrps_mixlinear_tn_gev.set_parameters(models_twcrps[\"twcrps_tn\"].get_parameters())\n",
    "twcrps_mixlinear_tn_gev.set_parameters(models_twcrps[\"twcrps_gev\"].get_parameters())\n",
    "\n",
    "setup1[\"distribution_2\"] = \"distr_frechet\"\n",
    "twcrps_mixlinear_tn_frechet = EMOS(setup1)\n",
    "\n",
    "twcrps_mixlinear_tn_frechet.set_parameters(models_twcrps[\"twcrps_tn\"].get_parameters())\n",
    "twcrps_mixlinear_tn_frechet.set_parameters(models_twcrps[\"twcrps_frechet\"].get_parameters())\n",
    "\n",
    "models_twcrps[\"twcrps_mixlinear_tn_ln\"] = twcrps_mixlinear_tn_ln\n",
    "models_twcrps[\"twcrps_mixlinear_tn_gev\"] = twcrps_mixlinear_tn_gev\n",
    "models_twcrps[\"twcrps_mixlinear_tn_frechet\"] = twcrps_mixlinear_tn_frechet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Gradient contains NaN\n",
      "Final loss:  nan\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_mixture_linear\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_log_normal\n",
      "Mixture weight a: [0.9836162]\n",
      "Mixture weight b: [0.95269144]\n",
      "Parameters:\n",
      "  weight_a: [0.9836162]\n",
      "  weight_b: [0.95269144]\n",
      "  a_tn: [0.9602615]\n",
      "  b_tn: [ 0.88499755 -1.1973009  -0.12923862 -0.14778566  1.2060355 ]\n",
      "  c_tn: [2.9868488]\n",
      "  d_tn: [0.7100836]\n",
      "  a_ln: [1.5933089]\n",
      "  b_ln: [-0.00281443 -0.12860696  0.00487967  0.02148308  0.05947179]\n",
      "  c_ln: [nan]\n",
      "  d_ln: [nan]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n",
      "Final loss:  0.08611962\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_mixture_linear\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_gev\n",
      "Mixture weight a: [-0.72179437]\n",
      "Mixture weight b: [0.08867916]\n",
      "Parameters:\n",
      "  weight_a: [-0.72179437]\n",
      "  weight_b: [0.08867916]\n",
      "  a_tn: [0.98948723]\n",
      "  b_tn: [ 0.6852069  -1.7993132  -0.43794805 -2.2223036   2.8904467 ]\n",
      "  c_tn: [3.6310956]\n",
      "  d_tn: [1.3187474]\n",
      "  a_gev: [-0.6827281]\n",
      "  b_gev: [ 1.2172048  -1.1108638   0.27776527  2.6654224   0.3134561 ]\n",
      "  c_gev: [-1.5952152]\n",
      "  d_gev: [ 0.4441672   0.81094235 -0.03878386  0.1061859  -1.8316519 ]\n",
      "  e_gev: [-0.33873802]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n",
      "Final loss:  0.08592372\n",
      "Model:  EMOS Model Information:\n",
      "Loss function: loss_twCRPS_sample (Samples: 300)\n",
      "Forecast distribution: distr_mixture_linear\n",
      "Distribution 1: distr_trunc_normal\n",
      "Distribution 2: distr_frechet\n",
      "Mixture weight a: [-0.88403064]\n",
      "Mixture weight b: [0.11134996]\n",
      "Parameters:\n",
      "  weight_a: [-0.88403064]\n",
      "  weight_b: [0.11134996]\n",
      "  a_tn: [1.0699908]\n",
      "  b_tn: [ 0.70310265 -1.9941587  -0.39651534 -1.9710293   2.9335496 ]\n",
      "  c_tn: [5.114095]\n",
      "  d_tn: [1.2725552]\n",
      "  a_fr: [-0.57922816]\n",
      "  b_fr: [ 1.2103021  -0.99832124  0.29213884  2.6228662   0.3136615 ]\n",
      "  c_fr: [-2.032981]\n",
      "  d_fr: [ 0.35258532  0.8914934  -0.06085485 -0.02185799 -1.7832264 ]\n",
      "  e_fr: [-0.]\n",
      "Features: wind_speed, press, kinetic, humid, geopot\n",
      "Number of features: 5\n",
      "Neighbourhood size: 11\n",
      "Chaining function: chain_function_normal_cdf (Mean: 11.0, Std: 1.0)\n",
      "Optimizer: Adam\n",
      "Learning rate: 0.009999999776482582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_twcrps[\"twcrps_mixlinear_tn_ln\"].fit(X_train, y_train, variances_train, epochs, printing=False)\n",
    "print(\"Model: \", models_twcrps[\"twcrps_mixlinear_tn_ln\"])\n",
    "\n",
    "models_twcrps[\"twcrps_mixlinear_tn_gev\"].fit(X_train, y_train, variances_train, epochs, printing=False)\n",
    "print(\"Model: \", models_twcrps[\"twcrps_mixlinear_tn_gev\"])\n",
    "\n",
    "models_twcrps[\"twcrps_mixlinear_tn_frechet\"].fit(X_train, y_train, variances_train, epochs, printing=False)\n",
    "print(\"Model: \", models_twcrps[\"twcrps_mixlinear_tn_frechet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parameter dict as pkl file\n"
     ]
    }
   ],
   "source": [
    "parameter_dict = {}\n",
    "\n",
    "for name, model in models_twcrps.items():\n",
    "    parameter_dict[name] = model.to_dict()\n",
    "\n",
    "# save the parameter_dict as pkl file in /net/pc200239/nobackup/users/hakvoort/models\n",
    "\n",
    "with open('/net/pc200239/nobackup/users/hakvoort/models/emos_twcrps_mean_11_std_1.pkl', 'wb') as f:\n",
    "    pkl.dump(parameter_dict, f)\n",
    "\n",
    "print(\"Saved parameter dict as pkl file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twcrps_tn 0.9380642\n",
      "twcrps_ln 2.0098855\n",
      "twcrps_gev 1.048202\n",
      "twcrps_frechet 1.1024867\n",
      "twcrps_mix_tn_ln 1.0611806\n",
      "twcrps_mix_tn_gev 1.0010288\n",
      "twcrps_mix_tn_frechet 0.9838235\n",
      "twcrps_mixlinear_tn_ln nan\n",
      "twcrps_mixlinear_tn_gev 1.0632433\n",
      "twcrps_mixlinear_tn_frechet 1.1045941\n"
     ]
    }
   ],
   "source": [
    "for name, model in models_twcrps.items():\n",
    "    loss = model.loss_CRPS_sample_general(X_test, y_test, variances_test, 10000)\n",
    "    print(name, loss.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
