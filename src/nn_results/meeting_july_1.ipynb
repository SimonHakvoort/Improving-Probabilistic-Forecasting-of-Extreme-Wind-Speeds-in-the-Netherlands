{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 10:05:56.871635: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 10:05:56.874361: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-21 10:05:56.908408: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 10:06:02.805300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from src.neural_networks.get_data import get_tf_data, stack_1d_features, normalize_1d_features_with_mean_std, load_cv_data, make_importance_sampling_dataset\n",
    "from src.neural_networks.nn_forecast import NNForecast\n",
    "from src.visualization.twcrpss_plot import make_twcrpss_plot_tf\n",
    "from src.visualization.brier_score import make_brier_skill_plot_tf\n",
    "from src.visualization.pit import make_cpit_diagram_tf, comp_multiple_pit_scores\n",
    "from src.visualization.reliability_diagram import make_reliability_and_sharpness_tf\n",
    "from src.training.training import load_model\n",
    "from src.visualization.plot_forecasts import plot_forecast_pdf_tf\n",
    "from src.climatology.climatology import Climatology\n",
    "from src.visualization.brier_score import get_brier_scores_tf\n",
    "from src.models.emos import BootstrapEmos, EMOS\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from scipy.stats import norm, pareto\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "\n",
    "location_features = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "\n",
    "scale_features = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "\n",
    "features_names_dict = {name: 1 for name in all_features}\n",
    "\n",
    "features_names_dict['wind_speed'] = 15\n",
    "\n",
    "ignore = ['229', '285', '323']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, data_info = load_cv_data(3, features_names_dict)\n",
    "\n",
    "train_data_is = make_importance_sampling_dataset(train_data)\n",
    "\n",
    "train_data_is = train_data_is.shuffle(30000)\n",
    "\n",
    "train_data_is = train_data_is.batch(32)\n",
    "\n",
    "train_data_is = train_data_is.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.shuffle(30000)\n",
    "\n",
    "train_data = train_data.batch(32)\n",
    "\n",
    "train_data = train_data.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = \"loss_CRPS_sample\"\n",
    "#loss = \"loss_cPIT\"\n",
    "samples = 200\n",
    "\n",
    "# possible chain functions: 'chain_function_indicator' and 'chain_function_normal_cdf'\n",
    "# if chain_function_indicator is chosen, threshold is not necessary\n",
    "# if chain_function_normal_cdf is chosen, threshold is necessary\n",
    "chain_function = \"chain_function_normal_cdf_plus_constant\"\n",
    "threshold = 100\n",
    "chain_function_mean = 9\n",
    "chain_function_std = 0.5\n",
    "chain_function_constant = 0.001\n",
    "\n",
    "\n",
    "# possible optimizers: 'SGD', 'Adam'\n",
    "optimizer = \"Adam\"\n",
    "learning_rate = 0.01\n",
    "\n",
    "# possible forecast distributions: 'distr_trunc_normal', 'distr_log_normal', 'distr_gev' and 'distr_mixture'/'distr_mixture_linear', which can be a mixture distribution of two previously mentioned distributions.\n",
    "forecast_distribution = \"distr_trunc_normal\"\n",
    "\n",
    "# necessary in case of a mixture distribution\n",
    "distribution_1 = \"distr_trunc_normal\"\n",
    "distribution_2 = \"distr_log_normal\"\n",
    "\n",
    "random_init = False\n",
    "printing = True\n",
    "subset_size = None\n",
    "\n",
    "setup = {'loss': loss,\n",
    "         'samples': samples, \n",
    "         'optimizer': optimizer, \n",
    "         'learning_rate': learning_rate, \n",
    "         'forecast_distribution': forecast_distribution,\n",
    "         'chain_function': chain_function,\n",
    "         'threshold': threshold,\n",
    "         'distribution_1': distribution_1,\n",
    "         'distribution_2': distribution_2,\n",
    "         'chain_function_mean': chain_function_mean,\n",
    "         'chain_function_std': chain_function_std,\n",
    "         'chain_function_constant': chain_function_constant,\n",
    "         'all_features': all_features,\n",
    "         'location_features': location_features,\n",
    "         'scale_features': scale_features,\n",
    "         'random_init': random_init,\n",
    "         'subset_size': subset_size,\n",
    "        'printing': printing,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos_is = EMOS(setup)\n",
    "\n",
    "emos_base = EMOS(setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses_is = emos_is.fit(train_data_is, epochs, True)['time_hist']\n",
    "\n",
    "losses = emos_base.fit(train_data, epochs, True)['time_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(losses_is.keys()), list(losses_is.values()), label='Importance Sampling')\n",
    "plt.plot(list(losses.keys()), list(losses.values()), label='Regular Sampling')\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel(\"Loss Values\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Models trained on the CRPS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup['loss'] = 'loss_twCRPS_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emos_weight_is = EMOS(setup)\n",
    "\n",
    "emos_weight_base = EMOS(setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "losses_is_w = emos_weight_is.fit(train_data_is, epochs, True)['time_hist']\n",
    "\n",
    "losses_w = emos_weight_base.fit(train_data, epochs, True)['time_hist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(losses_is_w.keys()), list(losses_is_w.values()), label='Importance Sampling')\n",
    "plt.plot(list(losses_w.keys()), list(losses_w.values()), label='Regular Sampling')\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel(\"Loss Values\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"Models trained on the twCRPS\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
