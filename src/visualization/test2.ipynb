{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 09:21:13.461849: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-01 09:21:13.488177: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-01 09:21:13.488196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-01 09:21:13.488978: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-01 09:21:13.493193: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-01 09:21:13.493678: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-01 09:21:23.125928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.models.train_emos import train_emos, train_and_test_emos\n",
    "from pit import make_cpit_diagram_emos, make_cpit_hist_emos \n",
    "from brier_score import brier_skill_plot, brier_plot\n",
    "from src.models.get_data import get_tensors, get_normalized_tensor\n",
    "from src.models.emos import EMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15733, 5)\n"
     ]
    }
   ],
   "source": [
    "neighbourhood_size = 11\n",
    "parameter_names = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "ignore = ['229', '285', '323']\n",
    "train_folds = [1, 2]\n",
    "train_data = get_normalized_tensor(neighbourhood_size, parameter_names, train_folds, ignore)\n",
    "\n",
    "X_train = train_data['X']\n",
    "y_train = train_data['y']\n",
    "variances_train = train_data['variances']\n",
    "mean_train = train_data['mean']\n",
    "std_train = train_data['std']\n",
    "\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7780, 5)\n"
     ]
    }
   ],
   "source": [
    "test_fold = 3\n",
    "\n",
    "X_test, y_test, variances_test = get_tensors(neighbourhood_size, parameter_names, test_fold, ignore)\n",
    "X_test = (X_test - mean_train) / std_train\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {}\n",
    "\n",
    "setup[\"num_features\"] = len(parameter_names)\n",
    "setup[\"feature_mean\"] = mean_train\n",
    "setup[\"feature_std\"] = std_train\n",
    "setup[\"features\"] = parameter_names\n",
    "setup[\"neighbourhood_size\"] = neighbourhood_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for truncated normal distribution\n"
     ]
    }
   ],
   "source": [
    "setup1 = setup\n",
    "\n",
    "setup1[\"loss\"] = \"loss_CRPS_sample\"\n",
    "setup1[\"samples\"] = 100\n",
    "setup1[\"optimizer\"] = \"Adam\"\n",
    "setup1[\"learning_rate\"] = 0.01\n",
    "setup1[\"forecast_distribution\"] = \"distr_trunc_normal\"\n",
    "\n",
    "trunc_normal_crps = EMOS(setup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 1.6884312629699707\n",
      "Step: 1, Loss: 1.6674045324325562\n",
      "Step: 2, Loss: 1.6425449848175049\n",
      "Step: 3, Loss: 1.6212313175201416\n",
      "Step: 4, Loss: 1.5989294052124023\n",
      "Step: 5, Loss: 1.5796879529953003\n",
      "Step: 6, Loss: 1.5594357252120972\n",
      "Step: 7, Loss: 1.5428332090377808\n",
      "Step: 8, Loss: 1.5268560647964478\n",
      "Step: 9, Loss: 1.511104941368103\n",
      "Step: 10, Loss: 1.4972862005233765\n",
      "Step: 11, Loss: 1.4818412065505981\n",
      "Step: 12, Loss: 1.469557285308838\n",
      "Step: 13, Loss: 1.4578388929367065\n",
      "Step: 14, Loss: 1.4444080591201782\n",
      "Step: 15, Loss: 1.435276985168457\n",
      "Step: 16, Loss: 1.422216534614563\n",
      "Step: 17, Loss: 1.4115030765533447\n",
      "Step: 18, Loss: 1.39873468875885\n",
      "Step: 19, Loss: 1.3891730308532715\n",
      "Step: 20, Loss: 1.3779594898223877\n",
      "Step: 21, Loss: 1.3680294752120972\n",
      "Step: 22, Loss: 1.3556177616119385\n",
      "Step: 23, Loss: 1.3447786569595337\n",
      "Step: 24, Loss: 1.336028814315796\n",
      "Step: 25, Loss: 1.3241889476776123\n",
      "Step: 26, Loss: 1.3140934705734253\n",
      "Step: 27, Loss: 1.3037840127944946\n",
      "Step: 28, Loss: 1.2944855690002441\n",
      "Step: 29, Loss: 1.2818163633346558\n",
      "Step: 30, Loss: 1.2732130289077759\n",
      "Step: 31, Loss: 1.2631930112838745\n",
      "Step: 32, Loss: 1.2553820610046387\n",
      "Step: 33, Loss: 1.2455493211746216\n",
      "Step: 34, Loss: 1.235674262046814\n",
      "Step: 35, Loss: 1.226601004600525\n",
      "Step: 36, Loss: 1.219398021697998\n",
      "Step: 37, Loss: 1.2109017372131348\n",
      "Step: 38, Loss: 1.2020069360733032\n",
      "Step: 39, Loss: 1.196943759918213\n",
      "Step: 40, Loss: 1.1857364177703857\n",
      "Step: 41, Loss: 1.177714228630066\n",
      "Step: 42, Loss: 1.1711937189102173\n",
      "Step: 43, Loss: 1.1629425287246704\n",
      "Step: 44, Loss: 1.1557072401046753\n",
      "Step: 45, Loss: 1.1472476720809937\n",
      "Step: 46, Loss: 1.1407487392425537\n",
      "Step: 47, Loss: 1.1294851303100586\n",
      "Step: 48, Loss: 1.1249864101409912\n",
      "Step: 49, Loss: 1.1182347536087036\n",
      "Step: 50, Loss: 1.110909342765808\n",
      "Step: 51, Loss: 1.1059906482696533\n",
      "Step: 52, Loss: 1.0993547439575195\n",
      "Step: 53, Loss: 1.0925387144088745\n",
      "Step: 54, Loss: 1.0848027467727661\n",
      "Step: 55, Loss: 1.0799438953399658\n",
      "Step: 56, Loss: 1.076682448387146\n",
      "Step: 57, Loss: 1.0699864625930786\n",
      "Step: 58, Loss: 1.0642796754837036\n",
      "Step: 59, Loss: 1.0573527812957764\n",
      "Step: 60, Loss: 1.0534029006958008\n",
      "Step: 61, Loss: 1.0488346815109253\n",
      "Step: 62, Loss: 1.0441255569458008\n",
      "Step: 63, Loss: 1.0387437343597412\n",
      "Step: 64, Loss: 1.032768726348877\n",
      "Step: 65, Loss: 1.0294686555862427\n",
      "Step: 66, Loss: 1.0260928869247437\n",
      "Step: 67, Loss: 1.0211995840072632\n",
      "Step: 68, Loss: 1.0173872709274292\n",
      "Step: 69, Loss: 1.0140794515609741\n",
      "Step: 70, Loss: 1.008143424987793\n",
      "Step: 71, Loss: 1.0044803619384766\n",
      "Step: 72, Loss: 1.000307321548462\n",
      "Step: 73, Loss: 0.9978542923927307\n",
      "Step: 74, Loss: 0.9945849776268005\n",
      "Step: 75, Loss: 0.9909600019454956\n",
      "Step: 76, Loss: 0.9881500601768494\n",
      "Step: 77, Loss: 0.9860113263130188\n",
      "Step: 78, Loss: 0.9795771837234497\n",
      "Step: 79, Loss: 0.9764461517333984\n",
      "Step: 80, Loss: 0.9758007526397705\n",
      "Step: 81, Loss: 0.973706841468811\n",
      "Step: 82, Loss: 0.9692763686180115\n",
      "Step: 83, Loss: 0.9687416553497314\n",
      "Step: 84, Loss: 0.9640561938285828\n",
      "Step: 85, Loss: 0.9614325761795044\n",
      "Step: 86, Loss: 0.9583261013031006\n",
      "Step: 87, Loss: 0.9581974148750305\n",
      "Step: 88, Loss: 0.9568127393722534\n",
      "Step: 89, Loss: 0.9530698657035828\n",
      "Step: 90, Loss: 0.9515601992607117\n",
      "Step: 91, Loss: 0.9483124017715454\n",
      "Step: 92, Loss: 0.9476445317268372\n",
      "Step: 93, Loss: 0.9465007781982422\n",
      "Step: 94, Loss: 0.9423540234565735\n",
      "Step: 95, Loss: 0.9424563646316528\n",
      "Step: 96, Loss: 0.9426827430725098\n",
      "Step: 97, Loss: 0.938927412033081\n",
      "Step: 98, Loss: 0.9388449788093567\n",
      "Step: 99, Loss: 0.9349071979522705\n",
      "Step: 100, Loss: 0.9339901208877563\n",
      "Step: 101, Loss: 0.9341554641723633\n",
      "Step: 102, Loss: 0.9306941628456116\n",
      "Step: 103, Loss: 0.9297968745231628\n",
      "Step: 104, Loss: 0.929239809513092\n",
      "Step: 105, Loss: 0.9286879301071167\n",
      "Step: 106, Loss: 0.9294239282608032\n",
      "Step: 107, Loss: 0.9263501763343811\n",
      "Step: 108, Loss: 0.9261914491653442\n",
      "Step: 109, Loss: 0.9251471757888794\n",
      "Step: 110, Loss: 0.924824595451355\n",
      "Step: 111, Loss: 0.9235736727714539\n",
      "Step: 112, Loss: 0.9237443208694458\n",
      "Step: 113, Loss: 0.9200302362442017\n",
      "Step: 114, Loss: 0.9217658638954163\n",
      "Step: 115, Loss: 0.9194040894508362\n",
      "Step: 116, Loss: 0.9191163182258606\n",
      "Step: 117, Loss: 0.9208711385726929\n",
      "Step: 118, Loss: 0.9174402952194214\n",
      "Step: 119, Loss: 0.9162102937698364\n",
      "Step: 120, Loss: 0.9176182746887207\n",
      "Step: 121, Loss: 0.9159995317459106\n",
      "Step: 122, Loss: 0.9162434339523315\n",
      "Step: 123, Loss: 0.9130750894546509\n",
      "Step: 124, Loss: 0.9145650267601013\n",
      "Step: 125, Loss: 0.9137569069862366\n",
      "Step: 126, Loss: 0.912261962890625\n",
      "Step: 127, Loss: 0.9130300283432007\n",
      "Step: 128, Loss: 0.913347065448761\n",
      "Step: 129, Loss: 0.9099329710006714\n",
      "Step: 130, Loss: 0.9129462242126465\n",
      "Step: 131, Loss: 0.9118189215660095\n",
      "Step: 132, Loss: 0.9119505882263184\n",
      "Step: 133, Loss: 0.9130402207374573\n",
      "Step: 134, Loss: 0.9110857844352722\n",
      "Step: 135, Loss: 0.9104718565940857\n",
      "Step: 136, Loss: 0.9113344550132751\n",
      "Step: 137, Loss: 0.9116919040679932\n",
      "Step: 138, Loss: 0.9105536341667175\n",
      "Step: 139, Loss: 0.9091017842292786\n",
      "Step: 140, Loss: 0.9099447131156921\n",
      "Step: 141, Loss: 0.9075003862380981\n",
      "Step: 142, Loss: 0.9081317186355591\n",
      "Step: 143, Loss: 0.908744752407074\n",
      "Step: 144, Loss: 0.9092531204223633\n",
      "Step: 145, Loss: 0.9086476564407349\n",
      "Step: 146, Loss: 0.9090680480003357\n",
      "Step: 147, Loss: 0.90829998254776\n",
      "Step: 148, Loss: 0.9080930948257446\n",
      "Step: 149, Loss: 0.9075523614883423\n",
      "Step: 150, Loss: 0.9072250723838806\n",
      "Step: 151, Loss: 0.9074618816375732\n",
      "Step: 152, Loss: 0.9087418913841248\n",
      "Step: 153, Loss: 0.9070221781730652\n",
      "Step: 154, Loss: 0.9070464968681335\n",
      "Step: 155, Loss: 0.9065569639205933\n",
      "Step: 156, Loss: 0.908355712890625\n",
      "Step: 157, Loss: 0.9065002799034119\n",
      "Step: 158, Loss: 0.9081266522407532\n",
      "Step: 159, Loss: 0.908272922039032\n",
      "Step: 160, Loss: 0.9073789715766907\n",
      "Step: 161, Loss: 0.9064306020736694\n",
      "Step: 162, Loss: 0.9074335694313049\n",
      "Step: 163, Loss: 0.9085786938667297\n",
      "Step: 164, Loss: 0.9050288796424866\n",
      "Step: 165, Loss: 0.9077299237251282\n",
      "Step: 166, Loss: 0.909435510635376\n",
      "Step: 167, Loss: 0.9070361852645874\n",
      "Step: 168, Loss: 0.9071210622787476\n",
      "Step: 169, Loss: 0.9088122844696045\n",
      "Step: 170, Loss: 0.9067025184631348\n",
      "Step: 171, Loss: 0.9070113897323608\n",
      "Step: 172, Loss: 0.9064616560935974\n",
      "Step: 173, Loss: 0.9053554534912109\n",
      "Step: 174, Loss: 0.9062480926513672\n",
      "Step: 175, Loss: 0.9063144326210022\n",
      "Step: 176, Loss: 0.9049829840660095\n",
      "Step: 177, Loss: 0.9054368734359741\n",
      "Step: 178, Loss: 0.9074129462242126\n",
      "Step: 179, Loss: 0.9060074090957642\n",
      "Step: 180, Loss: 0.9063935279846191\n",
      "Step: 181, Loss: 0.9060233235359192\n",
      "Step: 182, Loss: 0.9050902724266052\n",
      "Step: 183, Loss: 0.905182421207428\n",
      "Step: 184, Loss: 0.9086436033248901\n",
      "Step: 185, Loss: 0.9056901335716248\n",
      "Step: 186, Loss: 0.9066844582557678\n",
      "Step: 187, Loss: 0.9085450768470764\n",
      "Step: 188, Loss: 0.9062480330467224\n",
      "Step: 189, Loss: 0.9077132344245911\n",
      "Step: 190, Loss: 0.9061937928199768\n",
      "Step: 191, Loss: 0.9078735113143921\n",
      "Step: 192, Loss: 0.9079590439796448\n",
      "Step: 193, Loss: 0.9084197282791138\n",
      "Step: 194, Loss: 0.9073254466056824\n",
      "Step: 195, Loss: 0.9056811928749084\n",
      "Step: 196, Loss: 0.9080060124397278\n",
      "Step: 197, Loss: 0.9054115414619446\n",
      "Step: 198, Loss: 0.9079538583755493\n",
      "Step: 199, Loss: 0.9060189127922058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=1.6884313>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6674045>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.642545>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6212313>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5989294>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.579688>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5594357>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5428332>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5268561>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.511105>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4972862>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4818412>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4695573>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4578389>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.444408>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.435277>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4222165>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4115031>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3987347>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.389173>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3779595>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3680295>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3556178>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3447787>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3360288>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.324189>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3140935>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.303784>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2944856>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2818164>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.273213>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.263193>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2553821>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2455493>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2356743>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.226601>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.219398>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2109017>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2020069>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1969438>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1857364>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1777142>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1711937>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1629425>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1557072>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1472477>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1407487>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1294851>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1249864>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1182348>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1109093>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1059906>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0993547>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0925387>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0848027>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0799439>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0766824>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0699865>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0642797>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0573528>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0534029>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0488347>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0441256>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0387437>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0327687>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0294687>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0260929>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0211996>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0173873>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0140795>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0081434>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0044804>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0003073>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9978543>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.994585>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.99096>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.98815006>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9860113>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9795772>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.97644615>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.97580075>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.97370684>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.96927637>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.96874166>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9640562>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9614326>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9583261>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9581974>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.95681274>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.95306987>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9515602>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9483124>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.94764453>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9465008>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.942354>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.94245636>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.94268274>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9389274>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.938845>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9349072>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9339901>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.93415546>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.93069416>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9297969>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9292398>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.92868793>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9294239>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9263502>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.92619145>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9251472>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9248246>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9235737>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9237443>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.92003024>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.92176586>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9194041>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9191163>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.92087114>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9174403>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9162103>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9176183>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91599953>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91624343>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9130751>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.914565>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9137569>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91226196>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91303>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91334707>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.909933>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9129462>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9118189>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9119506>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9130402>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9110858>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91047186>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91133446>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9116919>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.91055363>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9091018>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9099447>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9075004>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9081317>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90874475>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9092531>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90864766>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90906805>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9083>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9080931>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90755236>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9072251>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9074619>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9087419>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9070222>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9070465>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90655696>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9083557>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9065003>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90812665>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9082729>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.907379>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9064306>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90743357>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9085787>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9050289>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9077299>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9094355>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9070362>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90712106>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9088123>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9067025>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9070114>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90646166>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90535545>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9062481>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90631443>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.904983>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9054369>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90741295>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9060074>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9063935>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9060233>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9050903>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9051824>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9086436>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90569013>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90668446>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9085451>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90624803>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90771323>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9061938>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9078735>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90795904>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9084197>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90732545>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9056812>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.908006>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90541154>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.90795386>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.9060189>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_normal_crps.fit(X_train, y_train, variances_train, 200, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TruncatedNormal' object has no attribute 'get_forecast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmake_cpit_hist_emos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrunc_normal_crps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariances_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesiscode/src/visualization/pit.py:58\u001b[0m, in \u001b[0;36mmake_cpit_hist_emos\u001b[0;34m(emos, X, y, variance, bins, title, t)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     56\u001b[0m     X, y, variance \u001b[38;5;241m=\u001b[39m threshold(X, y, variance, t)\n\u001b[0;32m---> 58\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[43memos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast_distribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_forecast\u001b[49m(X, variance)\n\u001b[1;32m     59\u001b[0m make_cpit_hist(distribution\u001b[38;5;241m.\u001b[39mcdf, y, bins, title, t)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TruncatedNormal' object has no attribute 'get_forecast'"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "make_cpit_hist_emos(trunc_normal_crps, X_test, y_test, variances_test, t=t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
