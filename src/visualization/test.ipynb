{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'brier_skill_plot' from 'brier_score' (/usr/people/hakvoort/thesiscode/src/visualization/brier_score.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_emos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_emos, train_and_test_emos\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbrier_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m brier_plot, brier_skill_plot\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mget_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tensors, get_normalized_tensor\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01memos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EMOS\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'brier_skill_plot' from 'brier_score' (/usr/people/hakvoort/thesiscode/src/visualization/brier_score.py)"
     ]
    }
   ],
   "source": [
    "from src.models.train_emos import train_emos, train_and_test_emos\n",
    "from brier_score import brier_plot, brier_skill_plot\n",
    "from src.models.get_data import get_tensors, get_normalized_tensor\n",
    "from src.models.emos import EMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15733, 5)\n"
     ]
    }
   ],
   "source": [
    "neighbourhood_size = 11\n",
    "parameter_names = ['wind_speed', 'press', 'kinetic', 'humid', 'geopot']\n",
    "ignore = ['229', '285', '323']\n",
    "train_folds = [1, 2]\n",
    "train_data = get_normalized_tensor(neighbourhood_size, parameter_names, train_folds, ignore)\n",
    "\n",
    "X_train = train_data['X']\n",
    "y_train = train_data['y']\n",
    "variances_train = train_data['variances']\n",
    "mean_train = train_data['mean']\n",
    "std_train = train_data['std']\n",
    "\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7780, 5)\n"
     ]
    }
   ],
   "source": [
    "test_fold = 3\n",
    "\n",
    "X_test, y_test, variances_test = get_tensors(neighbourhood_size, parameter_names, test_fold, ignore)\n",
    "X_test = (X_test - mean_train) / std_train\n",
    "\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {}\n",
    "\n",
    "setup[\"num_features\"] = len(parameter_names)\n",
    "setup[\"feature_mean\"] = mean_train\n",
    "setup[\"feature_std\"] = std_train\n",
    "setup[\"features\"] = parameter_names\n",
    "setup[\"neighbourhood_size\"] = neighbourhood_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible settings for EMOS class:\n",
    "\n",
    "loss:\n",
    "\n",
    "    loss_CRPS_sample\n",
    "    loss_log_likelihood\n",
    "    loss_Brier_score \n",
    "    loss_twCRPS_sample\n",
    "\n",
    "in case sample is used loss: sample\n",
    "\n",
    "chaining_functions\n",
    "\n",
    "    chain_function_indicator \n",
    "        includes:\n",
    "        \n",
    "         threshold\n",
    "    chain_function_normal_cdf\n",
    "        includes: \n",
    "        \n",
    "        chain_function_mean\n",
    "         chain_function_std\n",
    "\n",
    "optimizer:\n",
    "\n",
    "    Adam\n",
    "    SGD\n",
    "\n",
    "learning_rate:\n",
    "    -Positive real valued number\n",
    "\n",
    "forecast_distribution:\n",
    "\n",
    "    distr_trunc_normal\n",
    "    distr_log_normal\n",
    "    distr_gev(2/3)\n",
    "\n",
    "    distr_mixture (which contains two of the above distributions)\n",
    "    distr_mixture_linear\n",
    "\n",
    "they must contain distribution_1/distribution_2\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default parameters for truncated normal distribution\n",
      "Using default parameters for log normal distribution\n",
      "Using default parameters for Generalized Extreme Value distribution\n",
      "Using default parameters for Generalized Extreme Value distribution 2\n",
      "Using default parameters for Generalized Extreme Value distribution 3\n"
     ]
    }
   ],
   "source": [
    "models_crps = {}\n",
    "setup1 = setup\n",
    "\n",
    "setup1[\"loss\"] = \"loss_CRPS_sample\"\n",
    "setup1[\"samples\"] = 100\n",
    "setup1[\"optimizer\"] = \"Adam\"\n",
    "setup1[\"learning_rate\"] = 0.01\n",
    "setup1[\"forecast_distribution\"] = \"distr_trunc_normal\"\n",
    "\n",
    "trunc_normal_crps = EMOS(setup1)\n",
    "\n",
    "setup1[\"forecast_distribution\"] = \"distr_log_normal\"\n",
    "\n",
    "log_normal_crps = EMOS(setup1)\n",
    "\n",
    "setup1[\"forecast_distribution\"] = \"distr_gev\"\n",
    "setup1[\"samples\"] = 300\n",
    "\n",
    "gev_crps = EMOS(setup1)\n",
    "\n",
    "setup1[\"forecast_distribution\"] = \"distr_gev2\"\n",
    "\n",
    "gev2_crps = EMOS(setup1)\n",
    "\n",
    "setup1[\"forecast_distribution\"] = \"distr_gev3\"\n",
    "\n",
    "gev3_crps = EMOS(setup1)\n",
    "\n",
    "\n",
    "models_crps[\"trunc_normal_crps\"] = trunc_normal_crps\n",
    "models_crps[\"log_normal_crps\"] = log_normal_crps\n",
    "models_crps[\"gev_crps\"] = gev_crps\n",
    "models_crps[\"gev2_crps\"] = gev2_crps\n",
    "models_crps[\"gev3_crps\"] = gev3_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 1.6915428638458252\n",
      "Step: 1, Loss: 1.6638262271881104\n",
      "Step: 2, Loss: 1.6431360244750977\n",
      "Step: 3, Loss: 1.6190475225448608\n",
      "Step: 4, Loss: 1.6009337902069092\n",
      "Step: 5, Loss: 1.5789989233016968\n",
      "Step: 6, Loss: 1.5618631839752197\n",
      "Step: 7, Loss: 1.5434913635253906\n",
      "Step: 8, Loss: 1.5256328582763672\n",
      "Step: 9, Loss: 1.512081503868103\n",
      "Step: 10, Loss: 1.495106816291809\n",
      "Step: 11, Loss: 1.4811674356460571\n",
      "Step: 12, Loss: 1.470380425453186\n",
      "Step: 13, Loss: 1.458040475845337\n",
      "Step: 14, Loss: 1.4454883337020874\n",
      "Step: 15, Loss: 1.4336292743682861\n",
      "Step: 16, Loss: 1.4219497442245483\n",
      "Step: 17, Loss: 1.4128551483154297\n",
      "Step: 18, Loss: 1.4001286029815674\n",
      "Step: 19, Loss: 1.38970947265625\n",
      "Step: 20, Loss: 1.37860107421875\n",
      "Step: 21, Loss: 1.3667492866516113\n",
      "Step: 22, Loss: 1.3557112216949463\n",
      "Step: 23, Loss: 1.3453161716461182\n",
      "Step: 24, Loss: 1.3323020935058594\n",
      "Step: 25, Loss: 1.3223164081573486\n",
      "Step: 26, Loss: 1.3128893375396729\n",
      "Step: 27, Loss: 1.3031203746795654\n",
      "Step: 28, Loss: 1.293677806854248\n",
      "Step: 29, Loss: 1.2825541496276855\n",
      "Step: 30, Loss: 1.2718580961227417\n",
      "Step: 31, Loss: 1.2645798921585083\n",
      "Step: 32, Loss: 1.2527505159378052\n",
      "Step: 33, Loss: 1.2448724508285522\n",
      "Step: 34, Loss: 1.2357827425003052\n",
      "Step: 35, Loss: 1.2285212278366089\n",
      "Step: 36, Loss: 1.2195343971252441\n",
      "Step: 37, Loss: 1.2084075212478638\n",
      "Step: 38, Loss: 1.2037642002105713\n",
      "Step: 39, Loss: 1.1958385705947876\n",
      "Step: 40, Loss: 1.1875501871109009\n",
      "Step: 41, Loss: 1.1794646978378296\n",
      "Step: 42, Loss: 1.1703274250030518\n",
      "Step: 43, Loss: 1.1620166301727295\n",
      "Step: 44, Loss: 1.1549060344696045\n",
      "Step: 45, Loss: 1.1482771635055542\n",
      "Step: 46, Loss: 1.1394778490066528\n",
      "Step: 47, Loss: 1.1330125331878662\n",
      "Step: 48, Loss: 1.1271525621414185\n",
      "Step: 49, Loss: 1.1186103820800781\n",
      "Step: 50, Loss: 1.111966609954834\n",
      "Step: 51, Loss: 1.1046067476272583\n",
      "Step: 52, Loss: 1.0984894037246704\n",
      "Step: 53, Loss: 1.0935286283493042\n",
      "Step: 54, Loss: 1.087294340133667\n",
      "Step: 55, Loss: 1.0811679363250732\n",
      "Step: 56, Loss: 1.0748085975646973\n",
      "Step: 57, Loss: 1.0704467296600342\n",
      "Step: 58, Loss: 1.0652971267700195\n",
      "Step: 59, Loss: 1.0593477487564087\n",
      "Step: 60, Loss: 1.0527158975601196\n",
      "Step: 61, Loss: 1.0477792024612427\n",
      "Step: 62, Loss: 1.0431561470031738\n",
      "Step: 63, Loss: 1.0393762588500977\n",
      "Step: 64, Loss: 1.033759593963623\n",
      "Step: 65, Loss: 1.0301169157028198\n",
      "Step: 66, Loss: 1.0257855653762817\n",
      "Step: 67, Loss: 1.0202486515045166\n",
      "Step: 68, Loss: 1.0172854661941528\n",
      "Step: 69, Loss: 1.0136932134628296\n",
      "Step: 70, Loss: 1.0088756084442139\n",
      "Step: 71, Loss: 1.0060970783233643\n",
      "Step: 72, Loss: 1.0016828775405884\n",
      "Step: 73, Loss: 0.99733567237854\n",
      "Step: 74, Loss: 0.9940240383148193\n",
      "Step: 75, Loss: 0.9914374351501465\n",
      "Step: 76, Loss: 0.9894589781761169\n",
      "Step: 77, Loss: 0.9830620884895325\n",
      "Step: 78, Loss: 0.981770396232605\n",
      "Step: 79, Loss: 0.9792527556419373\n",
      "Step: 80, Loss: 0.9743287563323975\n",
      "Step: 81, Loss: 0.9740991592407227\n",
      "Step: 82, Loss: 0.9687193036079407\n",
      "Step: 83, Loss: 0.9688550233840942\n",
      "Step: 84, Loss: 0.9651529788970947\n",
      "Step: 85, Loss: 0.962655246257782\n",
      "Step: 86, Loss: 0.9597924947738647\n",
      "Step: 87, Loss: 0.9595357179641724\n",
      "Step: 88, Loss: 0.9546226859092712\n",
      "Step: 89, Loss: 0.9536858797073364\n",
      "Step: 90, Loss: 0.9523360729217529\n",
      "Step: 91, Loss: 0.9487951993942261\n",
      "Step: 92, Loss: 0.948064386844635\n",
      "Step: 93, Loss: 0.9472281336784363\n",
      "Step: 94, Loss: 0.9448333382606506\n",
      "Step: 95, Loss: 0.9432119131088257\n",
      "Step: 96, Loss: 0.9419846534729004\n",
      "Step: 97, Loss: 0.9388919472694397\n",
      "Step: 98, Loss: 0.9368060231208801\n",
      "Step: 99, Loss: 0.9350490570068359\n",
      "Step: 100, Loss: 0.9341176748275757\n",
      "Step: 101, Loss: 0.9330758452415466\n",
      "Step: 102, Loss: 0.9331299662590027\n",
      "Step: 103, Loss: 0.9311426281929016\n",
      "Step: 104, Loss: 0.929313600063324\n",
      "Step: 105, Loss: 0.930225133895874\n",
      "Step: 106, Loss: 0.9265199899673462\n",
      "Step: 107, Loss: 0.926677942276001\n",
      "Step: 108, Loss: 0.9248478412628174\n",
      "Step: 109, Loss: 0.9263216257095337\n",
      "Step: 110, Loss: 0.9226478934288025\n",
      "Step: 111, Loss: 0.9206091165542603\n",
      "Step: 112, Loss: 0.9211104512214661\n",
      "Step: 113, Loss: 0.9218385815620422\n",
      "Step: 114, Loss: 0.9193154573440552\n",
      "Step: 115, Loss: 0.9201326966285706\n",
      "Step: 116, Loss: 0.9195064306259155\n",
      "Step: 117, Loss: 0.9188404679298401\n",
      "Step: 118, Loss: 0.9174278378486633\n",
      "Step: 119, Loss: 0.9199422597885132\n",
      "Step: 120, Loss: 0.9172829985618591\n",
      "Step: 121, Loss: 0.9152223467826843\n",
      "Step: 122, Loss: 0.9161695837974548\n",
      "Step: 123, Loss: 0.9149649739265442\n",
      "Step: 124, Loss: 0.9136503338813782\n",
      "Step: 125, Loss: 0.9132007360458374\n",
      "Step: 126, Loss: 0.9144255518913269\n",
      "Step: 127, Loss: 0.9140761494636536\n",
      "Step: 128, Loss: 0.913058340549469\n",
      "Step: 129, Loss: 0.9125255942344666\n",
      "Step: 130, Loss: 0.914084792137146\n",
      "Step: 131, Loss: 0.9110569953918457\n",
      "Step: 132, Loss: 0.9133201241493225\n",
      "Step: 133, Loss: 0.9114541411399841\n",
      "Step: 134, Loss: 0.9116793274879456\n",
      "Step: 135, Loss: 0.9130204916000366\n",
      "Step: 136, Loss: 0.9113683104515076\n",
      "Step: 137, Loss: 0.9122787117958069\n",
      "Step: 138, Loss: 0.9101353883743286\n",
      "Step: 139, Loss: 0.9085344076156616\n",
      "Step: 140, Loss: 0.9094365835189819\n",
      "Step: 141, Loss: 0.9094540476799011\n",
      "Step: 142, Loss: 0.9076979756355286\n",
      "Step: 143, Loss: 0.9076144099235535\n",
      "Step: 144, Loss: 0.9082196950912476\n",
      "Step: 145, Loss: 0.9090927243232727\n",
      "Step: 146, Loss: 0.9093669652938843\n",
      "Step: 147, Loss: 0.9076186418533325\n",
      "Step: 148, Loss: 0.905367374420166\n",
      "Step: 149, Loss: 0.909143328666687\n",
      "Step: 150, Loss: 0.9075563549995422\n",
      "Step: 151, Loss: 0.9053029417991638\n",
      "Step: 152, Loss: 0.9076380133628845\n",
      "Step: 153, Loss: 0.9096933007240295\n",
      "Step: 154, Loss: 0.9088521599769592\n",
      "Step: 155, Loss: 0.9092146158218384\n",
      "Step: 156, Loss: 0.9097431302070618\n",
      "Step: 157, Loss: 0.9084129333496094\n",
      "Step: 158, Loss: 0.9090615510940552\n",
      "Step: 159, Loss: 0.9083380699157715\n",
      "Step: 160, Loss: 0.908846914768219\n",
      "Step: 161, Loss: 0.90793377161026\n",
      "Step: 162, Loss: 0.9067946076393127\n",
      "Step: 163, Loss: 0.9066668748855591\n",
      "Step: 164, Loss: 0.907357394695282\n",
      "Step: 165, Loss: 0.9077826142311096\n",
      "Step: 166, Loss: 0.9077713489532471\n",
      "Step: 167, Loss: 0.9077346920967102\n",
      "Step: 168, Loss: 0.9064951539039612\n",
      "Step: 169, Loss: 0.9077679514884949\n",
      "Step: 170, Loss: 0.908318281173706\n",
      "Step: 171, Loss: 0.9064345955848694\n",
      "Step: 172, Loss: 0.9061882495880127\n",
      "Step: 173, Loss: 0.9079935550689697\n",
      "Step: 174, Loss: 0.9069275856018066\n",
      "Step: 175, Loss: 0.9061022996902466\n",
      "Step: 176, Loss: 0.9058713912963867\n",
      "Step: 177, Loss: 0.9060873985290527\n",
      "Step: 178, Loss: 0.906981348991394\n",
      "Step: 179, Loss: 0.9069317579269409\n",
      "Step: 180, Loss: 0.9065313935279846\n",
      "Step: 181, Loss: 0.9073920845985413\n",
      "Step: 182, Loss: 0.906774640083313\n",
      "Step: 183, Loss: 0.908140242099762\n",
      "Step: 184, Loss: 0.9061216711997986\n",
      "Step: 185, Loss: 0.9082741141319275\n",
      "Step: 186, Loss: 0.905522346496582\n",
      "Step: 187, Loss: 0.9056861400604248\n",
      "Step: 188, Loss: 0.9078245162963867\n",
      "Step: 189, Loss: 0.9062410593032837\n",
      "Step: 190, Loss: 0.9066360592842102\n",
      "Step: 191, Loss: 0.9065890312194824\n",
      "Step: 192, Loss: 0.9079340100288391\n",
      "Step: 193, Loss: 0.9061611294746399\n",
      "Step: 194, Loss: 0.9077231287956238\n",
      "Step: 195, Loss: 0.9081791043281555\n",
      "Step: 196, Loss: 0.9066919684410095\n",
      "Step: 197, Loss: 0.9074370265007019\n",
      "Step: 198, Loss: 0.9072303771972656\n",
      "Step: 199, Loss: 0.906897246837616\n",
      "Step: 200, Loss: 0.9073017239570618\n",
      "Step: 201, Loss: 0.9070045351982117\n",
      "Step: 202, Loss: 0.9076194763183594\n",
      "Step: 203, Loss: 0.9054630398750305\n",
      "Step: 204, Loss: 0.9078533053398132\n",
      "Step: 205, Loss: 0.9062551856040955\n",
      "Step: 206, Loss: 0.9074212908744812\n",
      "Step: 207, Loss: 0.9080958366394043\n",
      "Step: 208, Loss: 0.9051579236984253\n",
      "Step: 209, Loss: 0.9074286222457886\n",
      "Step: 210, Loss: 0.906745970249176\n",
      "Step: 211, Loss: 0.9071962237358093\n",
      "Step: 212, Loss: 0.9067205190658569\n",
      "Step: 213, Loss: 0.9075275659561157\n",
      "Step: 214, Loss: 0.9068200588226318\n",
      "Step: 215, Loss: 0.9081977605819702\n",
      "Step: 216, Loss: 0.9069744944572449\n",
      "Step: 217, Loss: 0.9060064554214478\n",
      "Step: 218, Loss: 0.9067686796188354\n",
      "Step: 219, Loss: 0.9076104760169983\n",
      "Step: 220, Loss: 0.9068098664283752\n",
      "Step: 221, Loss: 0.9070024490356445\n",
      "Step: 222, Loss: 0.9059075713157654\n",
      "Step: 223, Loss: 0.9072179198265076\n",
      "Step: 224, Loss: 0.9064614176750183\n",
      "Step: 225, Loss: 0.9060901403427124\n",
      "Step: 226, Loss: 0.9085561633110046\n",
      "Step: 227, Loss: 0.9064523577690125\n",
      "Step: 228, Loss: 0.9067577123641968\n",
      "Step: 229, Loss: 0.9057464599609375\n",
      "Step: 230, Loss: 0.9073639512062073\n",
      "Step: 231, Loss: 0.9084985852241516\n",
      "Step: 232, Loss: 0.9051387310028076\n",
      "Step: 233, Loss: 0.9047738313674927\n",
      "Step: 234, Loss: 0.9074137210845947\n",
      "Step: 235, Loss: 0.9080372452735901\n",
      "Step: 236, Loss: 0.9074318408966064\n",
      "Step: 237, Loss: 0.9078904390335083\n",
      "Step: 238, Loss: 0.9065843224525452\n",
      "Step: 239, Loss: 0.9068029522895813\n",
      "Step: 240, Loss: 0.9091746807098389\n",
      "Step: 241, Loss: 0.9079726934432983\n",
      "Step: 242, Loss: 0.9094811677932739\n",
      "Step: 243, Loss: 0.9068735837936401\n",
      "Step: 244, Loss: 0.907020092010498\n",
      "Step: 245, Loss: 0.9070935249328613\n",
      "Step: 246, Loss: 0.908357560634613\n",
      "Step: 247, Loss: 0.907537579536438\n",
      "Step: 248, Loss: 0.9083810448646545\n",
      "Step: 249, Loss: 0.9070689082145691\n",
      "Step: 250, Loss: 0.9059365391731262\n",
      "Step: 251, Loss: 0.9070919156074524\n",
      "Step: 252, Loss: 0.9071879982948303\n",
      "Step: 253, Loss: 0.9069769978523254\n",
      "Step: 254, Loss: 0.9063290953636169\n",
      "Step: 255, Loss: 0.9060548543930054\n",
      "Step: 256, Loss: 0.9066673517227173\n",
      "Step: 257, Loss: 0.9056727290153503\n",
      "Step: 258, Loss: 0.9071215987205505\n",
      "Step: 259, Loss: 0.9052650332450867\n",
      "Step: 260, Loss: 0.9075422286987305\n",
      "Step: 261, Loss: 0.9058534502983093\n",
      "Step: 262, Loss: 0.9066972732543945\n",
      "Step: 263, Loss: 0.9076979756355286\n",
      "Step: 264, Loss: 0.9074593186378479\n",
      "Step: 265, Loss: 0.9082357883453369\n",
      "Step: 266, Loss: 0.9073202013969421\n",
      "Step: 267, Loss: 0.9064432978630066\n",
      "Step: 268, Loss: 0.9053904414176941\n",
      "Step: 269, Loss: 0.9042741656303406\n",
      "Step: 270, Loss: 0.9062886238098145\n",
      "Step: 271, Loss: 0.9067321419715881\n",
      "Step: 272, Loss: 0.905758798122406\n",
      "Step: 273, Loss: 0.9070495367050171\n",
      "Step: 274, Loss: 0.9055809378623962\n",
      "Step: 275, Loss: 0.9067465662956238\n",
      "Step: 276, Loss: 0.9059550166130066\n",
      "Step: 277, Loss: 0.9068419337272644\n",
      "Step: 278, Loss: 0.9079561233520508\n",
      "Step: 279, Loss: 0.9072580337524414\n",
      "Step: 280, Loss: 0.9071708917617798\n",
      "Step: 281, Loss: 0.906346321105957\n",
      "Step: 282, Loss: 0.9065502882003784\n",
      "Step: 283, Loss: 0.9060364365577698\n",
      "Step: 284, Loss: 0.9070040583610535\n",
      "Step: 285, Loss: 0.9071053266525269\n",
      "Step: 286, Loss: 0.9073436856269836\n",
      "Step: 287, Loss: 0.9067379236221313\n",
      "Step: 288, Loss: 0.9058786630630493\n",
      "Step: 289, Loss: 0.907058596611023\n",
      "Step: 290, Loss: 0.906535804271698\n",
      "Step: 291, Loss: 0.9068952798843384\n",
      "Step: 292, Loss: 0.9076653718948364\n",
      "Step: 293, Loss: 0.9080355763435364\n",
      "Step: 294, Loss: 0.9072575569152832\n",
      "Step: 295, Loss: 0.9068682193756104\n",
      "Step: 296, Loss: 0.9057990908622742\n",
      "Step: 297, Loss: 0.9077203273773193\n",
      "Step: 298, Loss: 0.9073823094367981\n",
      "Step: 299, Loss: 0.9077698588371277\n",
      "Step: 300, Loss: 0.9070950150489807\n",
      "Step: 301, Loss: 0.9066755175590515\n",
      "Step: 302, Loss: 0.9052228331565857\n",
      "Step: 303, Loss: 0.905394434928894\n",
      "Step: 304, Loss: 0.9065011143684387\n",
      "Step: 305, Loss: 0.9073348641395569\n",
      "Step: 306, Loss: 0.9066715836524963\n",
      "Step: 307, Loss: 0.9076564311981201\n",
      "Step: 308, Loss: 0.9066848754882812\n",
      "Step: 309, Loss: 0.9082760214805603\n",
      "Step: 310, Loss: 0.9063217639923096\n",
      "Step: 311, Loss: 0.9055611491203308\n",
      "Step: 312, Loss: 0.9076165556907654\n",
      "Step: 313, Loss: 0.9091941714286804\n",
      "Step: 314, Loss: 0.9053100943565369\n",
      "Step: 315, Loss: 0.9074123501777649\n",
      "Step: 316, Loss: 0.9088360071182251\n",
      "Step: 317, Loss: 0.9071354269981384\n",
      "Step: 318, Loss: 0.9058091640472412\n",
      "Step: 319, Loss: 0.9081698656082153\n",
      "Step: 320, Loss: 0.9054874181747437\n",
      "Step: 321, Loss: 0.9069916009902954\n",
      "Step: 322, Loss: 0.9072322249412537\n",
      "Step: 323, Loss: 0.9062723517417908\n",
      "Step: 324, Loss: 0.9052994251251221\n",
      "Step: 325, Loss: 0.9062622785568237\n",
      "Step: 326, Loss: 0.9063934087753296\n",
      "Step: 327, Loss: 0.9063369035720825\n",
      "Step: 328, Loss: 0.9074108600616455\n",
      "Step: 329, Loss: 0.9072389006614685\n",
      "Step: 330, Loss: 0.9054052233695984\n",
      "Step: 331, Loss: 0.9073877334594727\n",
      "Step: 332, Loss: 0.9070941805839539\n",
      "Step: 333, Loss: 0.9058220386505127\n",
      "Step: 334, Loss: 0.9068818688392639\n",
      "Step: 335, Loss: 0.9065907597541809\n",
      "Step: 336, Loss: 0.9077146053314209\n",
      "Step: 337, Loss: 0.9079852104187012\n",
      "Step: 338, Loss: 0.9086065292358398\n",
      "Step: 339, Loss: 0.9069955945014954\n",
      "Step: 340, Loss: 0.9064948558807373\n",
      "Step: 341, Loss: 0.9077084064483643\n",
      "Step: 342, Loss: 0.9062718749046326\n",
      "Step: 343, Loss: 0.9076429009437561\n",
      "Step: 344, Loss: 0.9066400527954102\n",
      "Step: 345, Loss: 0.9084809422492981\n",
      "Step: 346, Loss: 0.9060421586036682\n",
      "Step: 347, Loss: 0.9062178134918213\n",
      "Step: 348, Loss: 0.9057973623275757\n",
      "Step: 349, Loss: 0.9059842228889465\n",
      "Step: 350, Loss: 0.9062249064445496\n",
      "Step: 351, Loss: 0.9088127017021179\n",
      "Step: 352, Loss: 0.9066268801689148\n",
      "Step: 353, Loss: 0.9058979749679565\n",
      "Step: 354, Loss: 0.9063109755516052\n",
      "Step: 355, Loss: 0.9081016182899475\n",
      "Step: 356, Loss: 0.9066966772079468\n",
      "Step: 357, Loss: 0.905875027179718\n",
      "Step: 358, Loss: 0.907759964466095\n",
      "Step: 359, Loss: 0.9071878790855408\n",
      "Step: 360, Loss: 0.9067269563674927\n",
      "Step: 361, Loss: 0.9072252511978149\n",
      "Step: 362, Loss: 0.9060251712799072\n",
      "Step: 363, Loss: 0.9059224128723145\n",
      "Step: 364, Loss: 0.9066755771636963\n",
      "Step: 365, Loss: 0.9074357151985168\n",
      "Step: 366, Loss: 0.9079059362411499\n",
      "Step: 367, Loss: 0.9076723456382751\n",
      "Step: 368, Loss: 0.9065608382225037\n",
      "Step: 369, Loss: 0.9056535959243774\n",
      "Step: 370, Loss: 0.9053637981414795\n",
      "Step: 371, Loss: 0.9076579213142395\n",
      "Step: 372, Loss: 0.9048894047737122\n",
      "Step: 373, Loss: 0.9071837067604065\n",
      "Step: 374, Loss: 0.9069349765777588\n",
      "Step: 375, Loss: 0.9063193202018738\n",
      "Step: 376, Loss: 0.908047080039978\n",
      "Step: 377, Loss: 0.9061096906661987\n",
      "Step: 378, Loss: 0.9065806865692139\n",
      "Step: 379, Loss: 0.9078011512756348\n",
      "Step: 380, Loss: 0.9054831862449646\n",
      "Step: 381, Loss: 0.9062799215316772\n",
      "Step: 382, Loss: 0.9061391353607178\n",
      "Step: 383, Loss: 0.9060071110725403\n",
      "Step: 384, Loss: 0.9079737067222595\n",
      "Step: 385, Loss: 0.9067542552947998\n",
      "Step: 386, Loss: 0.9067551493644714\n",
      "Step: 387, Loss: 0.9056230783462524\n",
      "Step: 388, Loss: 0.9068694710731506\n",
      "Step: 389, Loss: 0.908000648021698\n",
      "Step: 390, Loss: 0.9068560600280762\n",
      "Step: 391, Loss: 0.9064308404922485\n",
      "Step: 392, Loss: 0.9069516062736511\n",
      "Step: 393, Loss: 0.9069197177886963\n",
      "Step: 394, Loss: 0.9067787528038025\n",
      "Step: 395, Loss: 0.9065325260162354\n",
      "Step: 396, Loss: 0.9055404663085938\n",
      "Step: 397, Loss: 0.9059898257255554\n",
      "Step: 398, Loss: 0.9071950912475586\n",
      "Step: 399, Loss: 0.9077487587928772\n",
      "Step: 400, Loss: 0.9060801863670349\n",
      "Step: 401, Loss: 0.9068043231964111\n",
      "Step: 402, Loss: 0.9066817760467529\n",
      "Step: 403, Loss: 0.9073448181152344\n",
      "Step: 404, Loss: 0.9061005115509033\n",
      "Step: 405, Loss: 0.9061886668205261\n",
      "Step: 406, Loss: 0.9071290493011475\n",
      "Step: 407, Loss: 0.9056088328361511\n",
      "Step: 408, Loss: 0.9073068499565125\n",
      "Step: 409, Loss: 0.907132625579834\n",
      "Step: 410, Loss: 0.9064601063728333\n",
      "Step: 411, Loss: 0.9066882133483887\n",
      "Step: 412, Loss: 0.9078185558319092\n",
      "Step: 413, Loss: 0.9064014554023743\n",
      "Step: 414, Loss: 0.9075676798820496\n",
      "Step: 415, Loss: 0.9066986441612244\n",
      "Step: 416, Loss: 0.9071462750434875\n",
      "Step: 417, Loss: 0.9057425260543823\n",
      "Step: 418, Loss: 0.9056572914123535\n",
      "Step: 419, Loss: 0.9059956073760986\n",
      "Step: 420, Loss: 0.9088225960731506\n",
      "Step: 421, Loss: 0.9059133529663086\n",
      "Step: 422, Loss: 0.9064319729804993\n",
      "Step: 423, Loss: 0.9070107340812683\n",
      "Step: 424, Loss: 0.906525731086731\n",
      "Step: 425, Loss: 0.9068540930747986\n",
      "Step: 426, Loss: 0.9060229659080505\n",
      "Step: 427, Loss: 0.9064101576805115\n",
      "Step: 428, Loss: 0.9074540734291077\n",
      "Step: 429, Loss: 0.9076905250549316\n",
      "Step: 430, Loss: 0.9068920612335205\n",
      "Step: 431, Loss: 0.9078757762908936\n",
      "Step: 432, Loss: 0.9083746671676636\n",
      "Step: 433, Loss: 0.9064935445785522\n",
      "Step: 434, Loss: 0.9059174060821533\n",
      "Step: 435, Loss: 0.9063960909843445\n",
      "Step: 436, Loss: 0.9071670174598694\n",
      "Step: 437, Loss: 0.9064204692840576\n",
      "Step: 438, Loss: 0.9067213535308838\n",
      "Step: 439, Loss: 0.9089258909225464\n",
      "Step: 440, Loss: 0.9083440899848938\n",
      "Step: 441, Loss: 0.9056473970413208\n",
      "Step: 442, Loss: 0.9053869843482971\n",
      "Step: 443, Loss: 0.9064861536026001\n",
      "Step: 444, Loss: 0.9056687951087952\n",
      "Step: 445, Loss: 0.9059774279594421\n",
      "Step: 446, Loss: 0.9071464538574219\n",
      "Step: 447, Loss: 0.9059982299804688\n",
      "Step: 448, Loss: 0.9058496356010437\n",
      "Step: 449, Loss: 0.9056479334831238\n",
      "Step: 450, Loss: 0.9070154428482056\n",
      "Step: 451, Loss: 0.9072076678276062\n",
      "Step: 452, Loss: 0.907509982585907\n",
      "Step: 453, Loss: 0.9060351848602295\n",
      "Step: 454, Loss: 0.9075912237167358\n",
      "Step: 455, Loss: 0.9072451591491699\n",
      "Step: 456, Loss: 0.9074994921684265\n",
      "Step: 457, Loss: 0.9073793292045593\n",
      "Step: 458, Loss: 0.9057839512825012\n",
      "Step: 459, Loss: 0.9066079258918762\n",
      "Step: 460, Loss: 0.9054737687110901\n",
      "Step: 461, Loss: 0.9087490439414978\n",
      "Step: 462, Loss: 0.9079559445381165\n",
      "Step: 463, Loss: 0.9086540341377258\n",
      "Step: 464, Loss: 0.9047607779502869\n",
      "Step: 465, Loss: 0.9069972038269043\n",
      "Step: 466, Loss: 0.9089624881744385\n",
      "Step: 467, Loss: 0.9068267345428467\n",
      "Step: 468, Loss: 0.9073747396469116\n",
      "Step: 469, Loss: 0.9066630005836487\n",
      "Step: 470, Loss: 0.9071341753005981\n",
      "Step: 471, Loss: 0.9073630571365356\n",
      "Step: 472, Loss: 0.9063079357147217\n",
      "Step: 473, Loss: 0.9083903431892395\n",
      "Step: 474, Loss: 0.9077396988868713\n",
      "Step: 475, Loss: 0.9063910245895386\n",
      "Step: 476, Loss: 0.9058566689491272\n",
      "Step: 477, Loss: 0.9061193466186523\n",
      "Step: 478, Loss: 0.9072535634040833\n",
      "Step: 479, Loss: 0.906902551651001\n",
      "Step: 480, Loss: 0.9063397645950317\n",
      "Step: 481, Loss: 0.9057257771492004\n",
      "Step: 482, Loss: 0.9075877070426941\n",
      "Step: 483, Loss: 0.9070530533790588\n",
      "Step: 484, Loss: 0.9072532057762146\n",
      "Step: 485, Loss: 0.9082675576210022\n",
      "Step: 486, Loss: 0.9067476987838745\n",
      "Step: 487, Loss: 0.90718013048172\n",
      "Step: 488, Loss: 0.9065123200416565\n",
      "Step: 489, Loss: 0.9064085483551025\n",
      "Step: 490, Loss: 0.9071224927902222\n",
      "Step: 491, Loss: 0.9059838652610779\n",
      "Step: 492, Loss: 0.9060071706771851\n",
      "Step: 493, Loss: 0.9079824090003967\n",
      "Step: 494, Loss: 0.9065151810646057\n",
      "Step: 495, Loss: 0.9059373140335083\n",
      "Step: 496, Loss: 0.907785177230835\n",
      "Step: 497, Loss: 0.9087633490562439\n",
      "Step: 498, Loss: 0.9078307151794434\n",
      "Step: 499, Loss: 0.9065078496932983\n",
      "Step: 0, Loss: 3.1662161350250244\n",
      "Step: 1, Loss: 3.0496633052825928\n",
      "Step: 2, Loss: 2.9243102073669434\n",
      "Step: 3, Loss: 2.7941274642944336\n",
      "Step: 4, Loss: 2.659036159515381\n",
      "Step: 5, Loss: 2.5248827934265137\n",
      "Step: 6, Loss: 2.390573024749756\n",
      "Step: 7, Loss: 2.265169382095337\n",
      "Step: 8, Loss: 2.1492483615875244\n",
      "Step: 9, Loss: 2.041778326034546\n",
      "Step: 10, Loss: 1.9738115072250366\n",
      "Step: 11, Loss: 1.9152644872665405\n",
      "Step: 12, Loss: 1.8682132959365845\n",
      "Step: 13, Loss: 1.8510030508041382\n",
      "Step: 14, Loss: 1.7212351560592651\n",
      "Step: 15, Loss: 1.8367674350738525\n",
      "Step: 16, Loss: 1.8349006175994873\n",
      "Step: 17, Loss: 1.8334896564483643\n",
      "Step: 18, Loss: 1.8004261255264282\n",
      "Step: 19, Loss: 1.7848262786865234\n",
      "Step: 20, Loss: 1.7587178945541382\n",
      "Step: 21, Loss: 1.6098824739456177\n",
      "Step: 22, Loss: 1.7135045528411865\n",
      "Step: 23, Loss: 1.68299400806427\n",
      "Step: 24, Loss: 1.6911540031433105\n",
      "Step: 25, Loss: 1.6279618740081787\n",
      "Step: 26, Loss: 1.623010277748108\n",
      "Step: 27, Loss: 1.589978575706482\n",
      "Step: 28, Loss: 1.6353483200073242\n",
      "Step: 29, Loss: 1.6137614250183105\n",
      "Step: 30, Loss: 1.6034045219421387\n",
      "Step: 31, Loss: 1.603463053703308\n",
      "Step: 32, Loss: 1.6106754541397095\n",
      "Step: 33, Loss: 1.5930382013320923\n",
      "Step: 34, Loss: 1.5893772840499878\n",
      "Step: 35, Loss: 1.5869249105453491\n",
      "Step: 36, Loss: 1.5799611806869507\n",
      "Step: 37, Loss: 1.5760033130645752\n",
      "Step: 38, Loss: 1.5352184772491455\n",
      "Step: 39, Loss: 1.5613155364990234\n",
      "Step: 40, Loss: 1.5426654815673828\n",
      "Step: 41, Loss: 1.534285306930542\n",
      "Step: 42, Loss: 1.519801139831543\n",
      "Step: 43, Loss: 1.514482855796814\n",
      "Step: 44, Loss: 1.5132745504379272\n",
      "Step: 45, Loss: 1.5044586658477783\n",
      "Step: 46, Loss: 1.4951586723327637\n",
      "Step: 47, Loss: 1.4915030002593994\n",
      "Step: 48, Loss: 1.4856646060943604\n",
      "Step: 49, Loss: 1.487657904624939\n",
      "Step: 50, Loss: 1.473894476890564\n",
      "Step: 51, Loss: 1.4604041576385498\n",
      "Step: 52, Loss: 1.4530036449432373\n",
      "Step: 53, Loss: 1.4327375888824463\n",
      "Step: 54, Loss: 1.4363973140716553\n",
      "Step: 55, Loss: 1.4274837970733643\n",
      "Step: 56, Loss: 1.404209852218628\n",
      "Step: 57, Loss: 1.4100207090377808\n",
      "Step: 58, Loss: 1.3962526321411133\n",
      "Step: 59, Loss: 1.3883527517318726\n",
      "Step: 60, Loss: 1.3819479942321777\n",
      "Step: 61, Loss: 1.3624446392059326\n",
      "Step: 62, Loss: 1.3581643104553223\n",
      "Step: 63, Loss: 1.354017734527588\n",
      "Step: 64, Loss: 1.3422654867172241\n",
      "Step: 65, Loss: 1.3377183675765991\n",
      "Step: 66, Loss: 1.3271188735961914\n",
      "Step: 67, Loss: 1.3262951374053955\n",
      "Step: 68, Loss: 1.3137047290802002\n",
      "Step: 69, Loss: 1.2995234727859497\n",
      "Step: 70, Loss: 1.2974509000778198\n",
      "Step: 71, Loss: 1.2902333736419678\n",
      "Step: 72, Loss: 1.2882007360458374\n",
      "Step: 73, Loss: 1.2838760614395142\n",
      "Step: 74, Loss: 1.2765611410140991\n",
      "Step: 75, Loss: 1.2720636129379272\n",
      "Step: 76, Loss: 1.2626457214355469\n",
      "Step: 77, Loss: 1.2653039693832397\n",
      "Step: 78, Loss: 1.2537164688110352\n",
      "Step: 79, Loss: 1.2552660703659058\n",
      "Step: 80, Loss: 1.2501360177993774\n",
      "Step: 81, Loss: 1.2488209009170532\n",
      "Step: 82, Loss: 1.2465804815292358\n",
      "Step: 83, Loss: 1.2458194494247437\n",
      "Step: 84, Loss: 1.2258837223052979\n",
      "Step: 85, Loss: 1.230514407157898\n",
      "Step: 86, Loss: 1.2319825887680054\n",
      "Step: 87, Loss: 1.229219675064087\n",
      "Step: 88, Loss: 1.2338778972625732\n",
      "Step: 89, Loss: 1.2158297300338745\n",
      "Step: 90, Loss: 1.2330799102783203\n",
      "Step: 91, Loss: 1.2135759592056274\n",
      "Step: 92, Loss: 1.2069004774093628\n",
      "Step: 93, Loss: 1.2099661827087402\n",
      "Step: 94, Loss: 1.1971877813339233\n",
      "Step: 95, Loss: 1.192034363746643\n",
      "Step: 96, Loss: 1.198632836341858\n",
      "Step: 97, Loss: 1.190543532371521\n",
      "Step: 98, Loss: 1.1250993013381958\n",
      "Step: 99, Loss: 1.1823749542236328\n",
      "Step: 100, Loss: 1.1739197969436646\n",
      "Step: 101, Loss: 1.180356740951538\n",
      "Step: 102, Loss: 1.1792378425598145\n",
      "Step: 103, Loss: 1.1679737567901611\n",
      "Step: 104, Loss: 1.1678438186645508\n",
      "Step: 105, Loss: 1.1657378673553467\n",
      "Step: 106, Loss: 1.1625949144363403\n",
      "Step: 107, Loss: 1.1656748056411743\n",
      "Step: 108, Loss: 1.1536380052566528\n",
      "Step: 109, Loss: 1.154502272605896\n",
      "Step: 110, Loss: 1.154942512512207\n",
      "Step: 111, Loss: 1.1486939191818237\n",
      "Step: 112, Loss: 1.1502805948257446\n",
      "Step: 113, Loss: 1.1358129978179932\n",
      "Step: 114, Loss: 1.1381133794784546\n",
      "Step: 115, Loss: 1.1337225437164307\n",
      "Step: 116, Loss: 1.131925106048584\n",
      "Step: 117, Loss: 1.1121562719345093\n",
      "Step: 118, Loss: 1.127590298652649\n",
      "Step: 119, Loss: 1.1307755708694458\n",
      "Step: 120, Loss: 1.1180963516235352\n",
      "Step: 121, Loss: 1.1208122968673706\n",
      "Step: 122, Loss: 1.118933916091919\n",
      "Step: 123, Loss: 1.1150331497192383\n",
      "Step: 124, Loss: 1.1101458072662354\n",
      "Step: 125, Loss: 1.1095681190490723\n",
      "Step: 126, Loss: 1.1079427003860474\n",
      "Step: 127, Loss: 1.1045109033584595\n",
      "Step: 128, Loss: 1.1036970615386963\n",
      "Step: 129, Loss: 1.1030287742614746\n",
      "Step: 130, Loss: 1.0977411270141602\n",
      "Step: 131, Loss: 1.0996819734573364\n",
      "Step: 132, Loss: 1.0960067510604858\n",
      "Step: 133, Loss: 1.0934466123580933\n",
      "Step: 134, Loss: 1.0902934074401855\n",
      "Step: 135, Loss: 1.0911736488342285\n",
      "Step: 136, Loss: 1.0861986875534058\n",
      "Step: 137, Loss: 1.0839899778366089\n",
      "Step: 138, Loss: 1.085713267326355\n",
      "Step: 139, Loss: 1.0819594860076904\n",
      "Step: 140, Loss: 1.0848653316497803\n",
      "Step: 141, Loss: 1.078705906867981\n",
      "Step: 142, Loss: 1.0791704654693604\n",
      "Step: 143, Loss: 1.0766764879226685\n",
      "Step: 144, Loss: 1.074670433998108\n",
      "Step: 145, Loss: 1.0705443620681763\n",
      "Step: 146, Loss: 1.0675071477890015\n",
      "Step: 147, Loss: 1.0682883262634277\n",
      "Step: 148, Loss: 1.0660301446914673\n",
      "Step: 149, Loss: 1.0643157958984375\n",
      "Step: 150, Loss: 1.0667804479599\n",
      "Step: 151, Loss: 1.0642763376235962\n",
      "Step: 152, Loss: 1.065986156463623\n",
      "Step: 153, Loss: 1.0658013820648193\n",
      "Step: 154, Loss: 1.0616689920425415\n",
      "Step: 155, Loss: 1.063533902168274\n",
      "Step: 156, Loss: 1.0605711936950684\n",
      "Step: 157, Loss: 1.0584156513214111\n",
      "Step: 158, Loss: 1.0579332113265991\n",
      "Step: 159, Loss: 1.0556997060775757\n",
      "Step: 160, Loss: 1.0560593605041504\n",
      "Step: 161, Loss: 1.0565632581710815\n",
      "Step: 162, Loss: 1.0562264919281006\n",
      "Step: 163, Loss: 1.0551124811172485\n",
      "Step: 164, Loss: 1.054235577583313\n",
      "Step: 165, Loss: 1.0555181503295898\n",
      "Step: 166, Loss: 1.054468035697937\n",
      "Step: 167, Loss: 1.0547817945480347\n",
      "Step: 168, Loss: 1.0541261434555054\n",
      "Step: 169, Loss: 1.0521780252456665\n",
      "Step: 170, Loss: 1.054934024810791\n",
      "Step: 171, Loss: 1.0531114339828491\n",
      "Step: 172, Loss: 1.0556058883666992\n",
      "Step: 173, Loss: 1.0523898601531982\n",
      "Step: 174, Loss: 1.0533798933029175\n",
      "Step: 175, Loss: 1.0524303913116455\n",
      "Step: 176, Loss: 1.054556131362915\n",
      "Step: 177, Loss: 1.0530122518539429\n",
      "Step: 178, Loss: 1.0559766292572021\n",
      "Step: 179, Loss: 1.0555943250656128\n",
      "Step: 180, Loss: 1.0531418323516846\n",
      "Step: 181, Loss: 1.0550169944763184\n",
      "Step: 182, Loss: 1.0517377853393555\n",
      "Step: 183, Loss: 1.0540921688079834\n",
      "Step: 184, Loss: 1.0526561737060547\n",
      "Step: 185, Loss: 1.0541670322418213\n",
      "Step: 186, Loss: 1.0541660785675049\n",
      "Step: 187, Loss: 1.0534584522247314\n",
      "Step: 188, Loss: 1.055067539215088\n",
      "Step: 189, Loss: 1.0537787675857544\n",
      "Step: 190, Loss: 1.0537025928497314\n",
      "Step: 191, Loss: 1.0550872087478638\n",
      "Step: 192, Loss: 1.0522685050964355\n",
      "Step: 193, Loss: 1.0516282320022583\n",
      "Step: 194, Loss: 1.0517820119857788\n",
      "Step: 195, Loss: 1.0531530380249023\n",
      "Step: 196, Loss: 1.054341435432434\n",
      "Step: 197, Loss: 1.0536037683486938\n",
      "Step: 198, Loss: 1.0527584552764893\n",
      "Step: 199, Loss: 1.0545982122421265\n",
      "Step: 200, Loss: 1.0534206628799438\n",
      "Step: 201, Loss: 1.052890419960022\n",
      "Step: 202, Loss: 1.0540847778320312\n",
      "Step: 203, Loss: 1.0525230169296265\n",
      "Step: 204, Loss: 1.0545321702957153\n",
      "Step: 205, Loss: 1.0520025491714478\n",
      "Step: 206, Loss: 1.0523722171783447\n",
      "Step: 207, Loss: 1.0522751808166504\n",
      "Step: 208, Loss: 1.0515934228897095\n",
      "Step: 209, Loss: 1.051089882850647\n",
      "Step: 210, Loss: 1.0525274276733398\n",
      "Step: 211, Loss: 1.0512818098068237\n",
      "Step: 212, Loss: 1.0543606281280518\n",
      "Step: 213, Loss: 1.0520433187484741\n",
      "Step: 214, Loss: 1.0532422065734863\n",
      "Step: 215, Loss: 1.051896572113037\n",
      "Step: 216, Loss: 1.051340937614441\n",
      "Step: 217, Loss: 1.0536926984786987\n",
      "Step: 218, Loss: 1.0528093576431274\n",
      "Step: 219, Loss: 1.050892949104309\n",
      "Step: 220, Loss: 1.0508406162261963\n",
      "Step: 221, Loss: 1.051044225692749\n",
      "Step: 222, Loss: 1.0544763803482056\n",
      "Step: 223, Loss: 1.0516172647476196\n",
      "Step: 224, Loss: 1.0516345500946045\n",
      "Step: 225, Loss: 1.0530319213867188\n",
      "Step: 226, Loss: 1.0523200035095215\n",
      "Step: 227, Loss: 1.0529507398605347\n",
      "Step: 228, Loss: 1.052526831626892\n",
      "Step: 229, Loss: 1.0520939826965332\n",
      "Step: 230, Loss: 1.0528548955917358\n",
      "Step: 231, Loss: 1.053078055381775\n",
      "Step: 232, Loss: 1.0528569221496582\n",
      "Step: 233, Loss: 1.0508642196655273\n",
      "Step: 234, Loss: 1.0529279708862305\n",
      "Step: 235, Loss: 1.0538004636764526\n",
      "Step: 236, Loss: 1.052947759628296\n",
      "Step: 237, Loss: 1.0518876314163208\n",
      "Step: 238, Loss: 1.0528061389923096\n",
      "Step: 239, Loss: 1.05396568775177\n",
      "Step: 240, Loss: 1.0515938997268677\n",
      "Step: 241, Loss: 1.051591157913208\n",
      "Step: 242, Loss: 1.0531442165374756\n",
      "Step: 243, Loss: 1.0528470277786255\n",
      "Step: 244, Loss: 1.0502163171768188\n",
      "Step: 245, Loss: 1.0519037246704102\n",
      "Step: 246, Loss: 1.0512769222259521\n",
      "Step: 247, Loss: 1.051261305809021\n",
      "Step: 248, Loss: 1.0518383979797363\n",
      "Step: 249, Loss: 1.0544151067733765\n",
      "Step: 250, Loss: 1.0499240159988403\n",
      "Step: 251, Loss: 1.0521961450576782\n",
      "Step: 252, Loss: 1.053431749343872\n",
      "Step: 253, Loss: 1.0521091222763062\n",
      "Step: 254, Loss: 1.051517128944397\n",
      "Step: 255, Loss: 1.0534203052520752\n",
      "Step: 256, Loss: 1.0529245138168335\n",
      "Step: 257, Loss: 1.0534833669662476\n",
      "Step: 258, Loss: 1.0544164180755615\n",
      "Step: 259, Loss: 1.0522887706756592\n",
      "Step: 260, Loss: 1.0508813858032227\n",
      "Step: 261, Loss: 1.0523114204406738\n",
      "Step: 262, Loss: 1.053029179573059\n",
      "Step: 263, Loss: 1.052881121635437\n",
      "Step: 264, Loss: 1.05497407913208\n",
      "Step: 265, Loss: 1.0532454252243042\n",
      "Step: 266, Loss: 1.0535529851913452\n",
      "Step: 267, Loss: 1.0518014430999756\n",
      "Step: 268, Loss: 1.0521438121795654\n",
      "Step: 269, Loss: 1.0517197847366333\n",
      "Step: 270, Loss: 1.0514485836029053\n",
      "Step: 271, Loss: 1.0513286590576172\n",
      "Step: 272, Loss: 1.0512888431549072\n",
      "Step: 273, Loss: 1.0533217191696167\n",
      "Step: 274, Loss: 1.0516797304153442\n",
      "Step: 275, Loss: 1.053609013557434\n",
      "Step: 276, Loss: 1.0523080825805664\n",
      "Step: 277, Loss: 1.0514088869094849\n",
      "Step: 278, Loss: 1.0540790557861328\n",
      "Step: 279, Loss: 1.0511780977249146\n",
      "Step: 280, Loss: 1.0520856380462646\n",
      "Step: 281, Loss: 1.0526376962661743\n",
      "Step: 282, Loss: 1.0514514446258545\n",
      "Step: 283, Loss: 1.0516166687011719\n",
      "Step: 284, Loss: 1.0509401559829712\n",
      "Step: 285, Loss: 1.0522780418395996\n",
      "Step: 286, Loss: 1.0520392656326294\n",
      "Step: 287, Loss: 1.0532331466674805\n",
      "Step: 288, Loss: 1.0533291101455688\n",
      "Step: 289, Loss: 1.0510667562484741\n",
      "Step: 290, Loss: 1.0524603128433228\n",
      "Step: 291, Loss: 1.052944540977478\n",
      "Step: 292, Loss: 1.0543513298034668\n",
      "Step: 293, Loss: 1.05186128616333\n",
      "Step: 294, Loss: 1.0537052154541016\n",
      "Step: 295, Loss: 1.0504242181777954\n",
      "Step: 296, Loss: 1.0524060726165771\n",
      "Step: 297, Loss: 1.052592396736145\n",
      "Step: 298, Loss: 1.0536552667617798\n",
      "Step: 299, Loss: 1.0523440837860107\n",
      "Step: 300, Loss: 1.051619291305542\n",
      "Step: 301, Loss: 1.05202054977417\n",
      "Step: 302, Loss: 1.0536552667617798\n",
      "Step: 303, Loss: 1.0518823862075806\n",
      "Step: 304, Loss: 1.0523300170898438\n",
      "Step: 305, Loss: 1.0530306100845337\n",
      "Step: 306, Loss: 1.0521694421768188\n",
      "Step: 307, Loss: 1.0514918565750122\n",
      "Step: 308, Loss: 1.0521219968795776\n",
      "Step: 309, Loss: 1.0518145561218262\n",
      "Step: 310, Loss: 1.053152322769165\n",
      "Step: 311, Loss: 1.0519225597381592\n",
      "Step: 312, Loss: 1.0532782077789307\n",
      "Step: 313, Loss: 1.0524182319641113\n",
      "Step: 314, Loss: 1.0510607957839966\n",
      "Step: 315, Loss: 1.049705147743225\n",
      "Step: 316, Loss: 1.0534982681274414\n",
      "Step: 317, Loss: 1.0532435178756714\n",
      "Step: 318, Loss: 1.0534846782684326\n",
      "Step: 319, Loss: 1.0525134801864624\n",
      "Step: 320, Loss: 1.0530855655670166\n",
      "Step: 321, Loss: 1.0527915954589844\n",
      "Step: 322, Loss: 1.0555212497711182\n",
      "Step: 323, Loss: 1.0540096759796143\n",
      "Step: 324, Loss: 1.0519911050796509\n",
      "Step: 325, Loss: 1.052404761314392\n",
      "Step: 326, Loss: 1.052844762802124\n",
      "Step: 327, Loss: 1.0533347129821777\n",
      "Step: 328, Loss: 1.051363468170166\n",
      "Step: 329, Loss: 1.0526247024536133\n",
      "Step: 330, Loss: 1.0520250797271729\n",
      "Step: 331, Loss: 1.0536128282546997\n",
      "Step: 332, Loss: 1.0519392490386963\n",
      "Step: 333, Loss: 1.0523712635040283\n",
      "Step: 334, Loss: 1.053614854812622\n",
      "Step: 335, Loss: 1.05317223072052\n",
      "Step: 336, Loss: 1.0513155460357666\n",
      "Step: 337, Loss: 1.0529242753982544\n",
      "Step: 338, Loss: 1.0546146631240845\n",
      "Step: 339, Loss: 1.0539069175720215\n",
      "Step: 340, Loss: 1.0539385080337524\n",
      "Step: 341, Loss: 1.0540249347686768\n",
      "Step: 342, Loss: 1.0513652563095093\n",
      "Step: 343, Loss: 1.0519537925720215\n",
      "Step: 344, Loss: 1.0513219833374023\n",
      "Step: 345, Loss: 1.054059624671936\n",
      "Step: 346, Loss: 1.051748275756836\n",
      "Step: 347, Loss: 1.0531891584396362\n",
      "Step: 348, Loss: 1.05222487449646\n",
      "Step: 349, Loss: 1.053760290145874\n",
      "Step: 350, Loss: 1.0559827089309692\n",
      "Step: 351, Loss: 1.051182746887207\n",
      "Step: 352, Loss: 1.052919626235962\n",
      "Step: 353, Loss: 1.0547311305999756\n",
      "Step: 354, Loss: 1.054386854171753\n",
      "Step: 355, Loss: 1.053720474243164\n",
      "Step: 356, Loss: 1.0523432493209839\n",
      "Step: 357, Loss: 1.0508129596710205\n",
      "Step: 358, Loss: 1.0518437623977661\n",
      "Step: 359, Loss: 1.0520102977752686\n",
      "Step: 360, Loss: 1.050588607788086\n",
      "Step: 361, Loss: 1.0510811805725098\n",
      "Step: 362, Loss: 1.055034875869751\n",
      "Step: 363, Loss: 1.0540012121200562\n",
      "Step: 364, Loss: 1.054672122001648\n",
      "Step: 365, Loss: 1.053314447402954\n",
      "Step: 366, Loss: 1.0540753602981567\n",
      "Step: 367, Loss: 1.0542912483215332\n",
      "Step: 368, Loss: 1.0535660982131958\n",
      "Step: 369, Loss: 1.0544240474700928\n",
      "Step: 370, Loss: 1.0533077716827393\n",
      "Step: 371, Loss: 1.05229914188385\n",
      "Step: 372, Loss: 1.052504062652588\n",
      "Step: 373, Loss: 1.0533944368362427\n",
      "Step: 374, Loss: 1.0522624254226685\n",
      "Step: 375, Loss: 1.0538345575332642\n",
      "Step: 376, Loss: 1.0515190362930298\n",
      "Step: 377, Loss: 1.0514897108078003\n",
      "Step: 378, Loss: 1.0520213842391968\n",
      "Step: 379, Loss: 1.052244782447815\n",
      "Step: 380, Loss: 1.053972601890564\n",
      "Step: 381, Loss: 1.0534981489181519\n",
      "Step: 382, Loss: 1.0511729717254639\n",
      "Step: 383, Loss: 1.0528037548065186\n",
      "Step: 384, Loss: 1.0529860258102417\n",
      "Step: 385, Loss: 1.0542664527893066\n",
      "Step: 386, Loss: 1.0514729022979736\n",
      "Step: 387, Loss: 1.0527551174163818\n",
      "Step: 388, Loss: 1.0514249801635742\n",
      "Step: 389, Loss: 1.0541895627975464\n",
      "Step: 390, Loss: 1.0541561841964722\n",
      "Step: 391, Loss: 1.0523546934127808\n",
      "Step: 392, Loss: 1.0509552955627441\n",
      "Step: 393, Loss: 1.053388237953186\n",
      "Step: 394, Loss: 1.0527867078781128\n",
      "Step: 395, Loss: 1.0534266233444214\n",
      "Step: 396, Loss: 1.0539761781692505\n",
      "Step: 397, Loss: 1.050926685333252\n",
      "Step: 398, Loss: 1.0523885488510132\n",
      "Step: 399, Loss: 1.0495705604553223\n",
      "Step: 400, Loss: 1.0534337759017944\n",
      "Step: 401, Loss: 1.0547739267349243\n",
      "Step: 402, Loss: 1.0545544624328613\n",
      "Step: 403, Loss: 1.0527271032333374\n",
      "Step: 404, Loss: 1.0504695177078247\n",
      "Step: 405, Loss: 1.050365924835205\n",
      "Step: 406, Loss: 1.0540950298309326\n",
      "Step: 407, Loss: 1.0552289485931396\n",
      "Step: 408, Loss: 1.0523369312286377\n",
      "Step: 409, Loss: 1.0490473508834839\n",
      "Step: 410, Loss: 1.05253267288208\n",
      "Step: 411, Loss: 1.0528398752212524\n",
      "Step: 412, Loss: 1.0512466430664062\n",
      "Step: 413, Loss: 1.0542720556259155\n",
      "Step: 414, Loss: 1.0527597665786743\n",
      "Step: 415, Loss: 1.0539665222167969\n",
      "Step: 416, Loss: 1.0528905391693115\n",
      "Step: 417, Loss: 1.05086350440979\n",
      "Step: 418, Loss: 1.0543333292007446\n",
      "Step: 419, Loss: 1.0523912906646729\n",
      "Step: 420, Loss: 1.051432728767395\n",
      "Step: 421, Loss: 1.0551730394363403\n",
      "Step: 422, Loss: 1.0534759759902954\n",
      "Step: 423, Loss: 1.0515397787094116\n",
      "Step: 424, Loss: 1.0531411170959473\n",
      "Step: 425, Loss: 1.053191065788269\n",
      "Step: 426, Loss: 1.0517301559448242\n",
      "Step: 427, Loss: 1.0525920391082764\n",
      "Step: 428, Loss: 1.05220627784729\n",
      "Step: 429, Loss: 1.05155611038208\n",
      "Step: 430, Loss: 1.0524085760116577\n",
      "Step: 431, Loss: 1.053571343421936\n",
      "Step: 432, Loss: 1.0537149906158447\n",
      "Step: 433, Loss: 1.0537480115890503\n",
      "Step: 434, Loss: 1.0517327785491943\n",
      "Step: 435, Loss: 1.0523337125778198\n",
      "Step: 436, Loss: 1.0525891780853271\n",
      "Step: 437, Loss: 1.0541481971740723\n",
      "Step: 438, Loss: 1.0542535781860352\n",
      "Step: 439, Loss: 1.0525639057159424\n",
      "Step: 440, Loss: 1.0503984689712524\n",
      "Step: 441, Loss: 1.0520387887954712\n",
      "Step: 442, Loss: 1.05437171459198\n",
      "Step: 443, Loss: 1.0506598949432373\n",
      "Step: 444, Loss: 1.052511215209961\n",
      "Step: 445, Loss: 1.0533570051193237\n",
      "Step: 446, Loss: 1.0540916919708252\n",
      "Step: 447, Loss: 1.0518503189086914\n",
      "Step: 448, Loss: 1.0532865524291992\n",
      "Step: 449, Loss: 1.05514395236969\n",
      "Step: 450, Loss: 1.0541958808898926\n",
      "Step: 451, Loss: 1.0515180826187134\n",
      "Step: 452, Loss: 1.0532691478729248\n",
      "Step: 453, Loss: 1.0524393320083618\n",
      "Step: 454, Loss: 1.051294207572937\n",
      "Step: 455, Loss: 1.0524548292160034\n",
      "Step: 456, Loss: 1.0521433353424072\n",
      "Step: 457, Loss: 1.0525072813034058\n",
      "Step: 458, Loss: 1.053680658340454\n",
      "Step: 459, Loss: 1.051900029182434\n",
      "Step: 460, Loss: 1.0523244142532349\n",
      "Step: 461, Loss: 1.052893877029419\n",
      "Step: 462, Loss: 1.0540574789047241\n",
      "Step: 463, Loss: 1.0527290105819702\n",
      "Step: 464, Loss: 1.052431344985962\n",
      "Step: 465, Loss: 1.0544296503067017\n",
      "Step: 466, Loss: 1.0518592596054077\n",
      "Step: 467, Loss: 1.0517627000808716\n",
      "Step: 468, Loss: 1.0545378923416138\n",
      "Step: 469, Loss: 1.054010272026062\n",
      "Step: 470, Loss: 1.051210880279541\n",
      "Step: 471, Loss: 1.0524002313613892\n",
      "Step: 472, Loss: 1.049516201019287\n",
      "Step: 473, Loss: 1.0520027875900269\n",
      "Step: 474, Loss: 1.0526654720306396\n",
      "Step: 475, Loss: 1.0511387586593628\n",
      "Step: 476, Loss: 1.0513136386871338\n",
      "Step: 477, Loss: 1.0540926456451416\n",
      "Step: 478, Loss: 1.0511776208877563\n",
      "Step: 479, Loss: 1.0520225763320923\n",
      "Step: 480, Loss: 1.0530753135681152\n",
      "Step: 481, Loss: 1.0523457527160645\n",
      "Step: 482, Loss: 1.0534493923187256\n",
      "Step: 483, Loss: 1.0520509481430054\n",
      "Step: 484, Loss: 1.051624059677124\n",
      "Step: 485, Loss: 1.0519838333129883\n",
      "Step: 486, Loss: 1.0523817539215088\n",
      "Step: 487, Loss: 1.0524319410324097\n",
      "Step: 488, Loss: 1.0510141849517822\n",
      "Step: 489, Loss: 1.0554031133651733\n",
      "Step: 490, Loss: 1.052992343902588\n",
      "Step: 491, Loss: 1.0535866022109985\n",
      "Step: 492, Loss: 1.0519764423370361\n",
      "Step: 493, Loss: 1.0528404712677002\n",
      "Step: 494, Loss: 1.054145097732544\n",
      "Step: 495, Loss: 1.053138017654419\n",
      "Step: 496, Loss: 1.0545333623886108\n",
      "Step: 497, Loss: 1.0529619455337524\n",
      "Step: 498, Loss: 1.0507216453552246\n",
      "Step: 499, Loss: 1.0533807277679443\n",
      "Step: 0, Loss: 2.6707286834716797\n",
      "Step: 1, Loss: 2.639937162399292\n",
      "Step: 2, Loss: 2.6095895767211914\n",
      "Step: 3, Loss: 2.566802740097046\n",
      "Step: 4, Loss: 2.5365450382232666\n",
      "Step: 5, Loss: 2.498840808868408\n",
      "Step: 6, Loss: 2.4658846855163574\n",
      "Step: 7, Loss: 2.4281346797943115\n",
      "Step: 8, Loss: 2.400754451751709\n",
      "Step: 9, Loss: 2.3594791889190674\n",
      "Step: 10, Loss: 2.328032970428467\n",
      "Step: 11, Loss: 2.302799940109253\n",
      "Step: 12, Loss: 2.270095109939575\n",
      "Step: 13, Loss: 2.2396938800811768\n",
      "Step: 14, Loss: 2.2102408409118652\n",
      "Step: 15, Loss: 2.182905673980713\n",
      "Step: 16, Loss: 2.149355411529541\n",
      "Step: 17, Loss: 2.123382329940796\n",
      "Step: 18, Loss: 2.0977261066436768\n",
      "Step: 19, Loss: 2.066936492919922\n",
      "Step: 20, Loss: 2.0380046367645264\n",
      "Step: 21, Loss: 2.0149006843566895\n",
      "Step: 22, Loss: 1.9887003898620605\n",
      "Step: 23, Loss: 1.9605921506881714\n",
      "Step: 24, Loss: 1.937207579612732\n",
      "Step: 25, Loss: 1.9169948101043701\n",
      "Step: 26, Loss: 1.8911694288253784\n",
      "Step: 27, Loss: 1.8645293712615967\n",
      "Step: 28, Loss: 1.846750020980835\n",
      "Step: 29, Loss: 1.8238986730575562\n",
      "Step: 30, Loss: 1.7997173070907593\n",
      "Step: 31, Loss: 1.7817133665084839\n",
      "Step: 32, Loss: 1.762003779411316\n",
      "Step: 33, Loss: 1.738131046295166\n",
      "Step: 34, Loss: 1.7188653945922852\n",
      "Step: 35, Loss: 1.7003984451293945\n",
      "Step: 36, Loss: 1.6800832748413086\n",
      "Step: 37, Loss: 1.6608469486236572\n",
      "Step: 38, Loss: 1.6406587362289429\n",
      "Step: 39, Loss: 1.6235899925231934\n",
      "Step: 40, Loss: 1.607097864151001\n",
      "Step: 41, Loss: 1.5874603986740112\n",
      "Step: 42, Loss: 1.5730798244476318\n",
      "Step: 43, Loss: 1.5569700002670288\n",
      "Step: 44, Loss: 1.5338919162750244\n",
      "Step: 45, Loss: 1.518166422843933\n",
      "Step: 46, Loss: 1.5034819841384888\n",
      "Step: 47, Loss: 1.485558271408081\n",
      "Step: 48, Loss: 1.467372179031372\n",
      "Step: 49, Loss: 1.4525492191314697\n",
      "Step: 50, Loss: 1.433454990386963\n",
      "Step: 51, Loss: 1.41668701171875\n",
      "Step: 52, Loss: 1.4032750129699707\n",
      "Step: 53, Loss: 1.3838753700256348\n",
      "Step: 54, Loss: 1.369505763053894\n",
      "Step: 55, Loss: 1.3535010814666748\n",
      "Step: 56, Loss: 1.3388218879699707\n",
      "Step: 57, Loss: 1.321184515953064\n",
      "Step: 58, Loss: 1.3071763515472412\n",
      "Step: 59, Loss: 1.2909387350082397\n",
      "Step: 60, Loss: 1.2785760164260864\n",
      "Step: 61, Loss: 1.2607169151306152\n",
      "Step: 62, Loss: 1.250733733177185\n",
      "Step: 63, Loss: 1.2322262525558472\n",
      "Step: 64, Loss: 1.2197321653366089\n",
      "Step: 65, Loss: 1.2066084146499634\n",
      "Step: 66, Loss: 1.1899994611740112\n",
      "Step: 67, Loss: 1.1775764226913452\n",
      "Step: 68, Loss: 1.1661691665649414\n",
      "Step: 69, Loss: 1.1529541015625\n",
      "Step: 70, Loss: 1.1432493925094604\n",
      "Step: 71, Loss: 1.1292883157730103\n",
      "Step: 72, Loss: 1.1173195838928223\n",
      "Step: 73, Loss: 1.1062144041061401\n",
      "Step: 74, Loss: 1.097151279449463\n",
      "Step: 75, Loss: 1.084322452545166\n",
      "Step: 76, Loss: 1.073990821838379\n",
      "Step: 77, Loss: 1.0654106140136719\n",
      "Step: 78, Loss: 1.0546578168869019\n",
      "Step: 79, Loss: 1.0450141429901123\n",
      "Step: 80, Loss: 1.0382938385009766\n",
      "Step: 81, Loss: 1.027003288269043\n",
      "Step: 82, Loss: 1.0215469598770142\n",
      "Step: 83, Loss: 1.0142732858657837\n",
      "Step: 84, Loss: 1.0057796239852905\n",
      "Step: 85, Loss: 0.9983283281326294\n",
      "Step: 86, Loss: 0.9905208945274353\n",
      "Step: 87, Loss: 0.9842862486839294\n",
      "Step: 88, Loss: 0.9791770577430725\n",
      "Step: 89, Loss: 0.976551353931427\n",
      "Step: 90, Loss: 0.968201756477356\n",
      "Step: 91, Loss: 0.9640122652053833\n",
      "Step: 92, Loss: 0.9592142701148987\n",
      "Step: 93, Loss: 0.9569210410118103\n",
      "Step: 94, Loss: 0.9515008926391602\n",
      "Step: 95, Loss: 0.9491828680038452\n",
      "Step: 96, Loss: 0.9451711177825928\n",
      "Step: 97, Loss: 0.941710889339447\n",
      "Step: 98, Loss: 0.9408826231956482\n",
      "Step: 99, Loss: 0.9375906586647034\n",
      "Step: 100, Loss: 0.9354181289672852\n",
      "Step: 101, Loss: 0.9339249134063721\n",
      "Step: 102, Loss: 0.9334088563919067\n",
      "Step: 103, Loss: 0.9304147958755493\n",
      "Step: 104, Loss: 0.9303431510925293\n",
      "Step: 105, Loss: 0.9283587336540222\n",
      "Step: 106, Loss: 0.9268046617507935\n",
      "Step: 107, Loss: 0.9261278510093689\n",
      "Step: 108, Loss: 0.9257633686065674\n",
      "Step: 109, Loss: 0.9249815344810486\n",
      "Step: 110, Loss: 0.9236617684364319\n",
      "Step: 111, Loss: 0.9243146181106567\n",
      "Step: 112, Loss: 0.9227726459503174\n",
      "Step: 113, Loss: 0.9229193329811096\n",
      "Step: 114, Loss: 0.9231500625610352\n",
      "Step: 115, Loss: 0.921161413192749\n",
      "Step: 116, Loss: 0.9226897358894348\n",
      "Step: 117, Loss: 0.9213575720787048\n",
      "Step: 118, Loss: 0.9211424589157104\n",
      "Step: 119, Loss: 0.9206727147102356\n",
      "Step: 120, Loss: 0.9211898446083069\n",
      "Step: 121, Loss: 0.9207789301872253\n",
      "Step: 122, Loss: 0.9218734502792358\n",
      "Step: 123, Loss: 0.9203035831451416\n",
      "Step: 124, Loss: 0.9198800325393677\n",
      "Step: 125, Loss: 0.9195283651351929\n",
      "Step: 126, Loss: 0.9188912510871887\n",
      "Step: 127, Loss: 0.9190714359283447\n",
      "Step: 128, Loss: 0.9187626838684082\n",
      "Step: 129, Loss: 0.9195780158042908\n",
      "Step: 130, Loss: 0.9204637408256531\n",
      "Step: 131, Loss: 0.9182389974594116\n",
      "Step: 132, Loss: 0.9177663922309875\n",
      "Step: 133, Loss: 0.9184274673461914\n",
      "Step: 134, Loss: 0.9178899526596069\n",
      "Step: 135, Loss: 0.9185726642608643\n",
      "Step: 136, Loss: 0.9166431427001953\n",
      "Step: 137, Loss: 0.9169484972953796\n",
      "Step: 138, Loss: 0.9182122945785522\n",
      "Step: 139, Loss: 0.9174052476882935\n",
      "Step: 140, Loss: 0.9168683886528015\n",
      "Step: 141, Loss: 0.9168630242347717\n",
      "Step: 142, Loss: 0.9165398478507996\n",
      "Step: 143, Loss: 0.9175492525100708\n",
      "Step: 144, Loss: 0.9175232648849487\n",
      "Step: 145, Loss: 0.9160970449447632\n",
      "Step: 146, Loss: 0.9169797301292419\n",
      "Step: 147, Loss: 0.9170599579811096\n",
      "Step: 148, Loss: 0.9169005751609802\n",
      "Step: 149, Loss: 0.9167929291725159\n",
      "Step: 150, Loss: 0.9165294766426086\n",
      "Step: 151, Loss: 0.9156964421272278\n",
      "Step: 152, Loss: 0.9164707064628601\n",
      "Step: 153, Loss: 0.9166508316993713\n",
      "Step: 154, Loss: 0.9161490201950073\n",
      "Step: 155, Loss: 0.9172577857971191\n",
      "Step: 156, Loss: 0.9163243174552917\n",
      "Step: 157, Loss: 0.9170386791229248\n",
      "Step: 158, Loss: 0.9158075451850891\n",
      "Step: 159, Loss: 0.9154390692710876\n",
      "Step: 160, Loss: 0.9157580137252808\n",
      "Step: 161, Loss: 0.9155462384223938\n",
      "Step: 162, Loss: 0.9147645235061646\n",
      "Step: 163, Loss: 0.915130078792572\n",
      "Step: 164, Loss: 0.9157989025115967\n",
      "Step: 165, Loss: 0.9144499897956848\n",
      "Step: 166, Loss: 0.9141473770141602\n",
      "Step: 167, Loss: 0.9141297936439514\n",
      "Step: 168, Loss: 0.9147634506225586\n",
      "Step: 169, Loss: 0.9146972894668579\n",
      "Step: 170, Loss: 0.9142069220542908\n",
      "Step: 171, Loss: 0.9137887954711914\n",
      "Step: 172, Loss: 0.9148598909378052\n",
      "Step: 173, Loss: 0.9148654937744141\n",
      "Step: 174, Loss: 0.9140276908874512\n",
      "Step: 175, Loss: 0.9148558974266052\n",
      "Step: 176, Loss: 0.9148968458175659\n",
      "Step: 177, Loss: 0.9132429957389832\n",
      "Step: 178, Loss: 0.9135477542877197\n",
      "Step: 179, Loss: 0.9151632785797119\n",
      "Step: 180, Loss: 0.913963794708252\n",
      "Step: 181, Loss: 0.9145235419273376\n",
      "Step: 182, Loss: 0.9134036898612976\n",
      "Step: 183, Loss: 0.9139814972877502\n",
      "Step: 184, Loss: 0.9126380681991577\n",
      "Step: 185, Loss: 0.9149723649024963\n",
      "Step: 186, Loss: 0.9139459729194641\n",
      "Step: 187, Loss: 0.914544403553009\n",
      "Step: 188, Loss: 0.91335129737854\n",
      "Step: 189, Loss: 0.9129520654678345\n",
      "Step: 190, Loss: 0.9139449000358582\n",
      "Step: 191, Loss: 0.913059413433075\n",
      "Step: 192, Loss: 0.9134923815727234\n",
      "Step: 193, Loss: 0.9131907224655151\n",
      "Step: 194, Loss: 0.9123766422271729\n",
      "Step: 195, Loss: 0.9136810302734375\n",
      "Step: 196, Loss: 0.9133075475692749\n",
      "Step: 197, Loss: 0.9134896993637085\n",
      "Step: 198, Loss: 0.9132668972015381\n",
      "Step: 199, Loss: 0.9132449626922607\n",
      "Step: 200, Loss: 0.9130733609199524\n",
      "Step: 201, Loss: 0.9135125875473022\n",
      "Step: 202, Loss: 0.9129424691200256\n",
      "Step: 203, Loss: 0.9118611812591553\n",
      "Step: 204, Loss: 0.9132302403450012\n",
      "Step: 205, Loss: 0.9131316542625427\n",
      "Step: 206, Loss: 0.9119188189506531\n",
      "Step: 207, Loss: 0.9126307964324951\n",
      "Step: 208, Loss: 0.9137719869613647\n",
      "Step: 209, Loss: 0.913470983505249\n",
      "Step: 210, Loss: 0.9133235216140747\n",
      "Step: 211, Loss: 0.9120825529098511\n",
      "Step: 212, Loss: 0.9128178358078003\n",
      "Step: 213, Loss: 0.9137822985649109\n",
      "Step: 214, Loss: 0.9129843711853027\n",
      "Step: 215, Loss: 0.9135575294494629\n",
      "Step: 216, Loss: 0.9130674004554749\n",
      "Step: 217, Loss: 0.9129951000213623\n",
      "Step: 218, Loss: 0.9126858115196228\n",
      "Step: 219, Loss: 0.9127455949783325\n",
      "Step: 220, Loss: 0.9117076396942139\n",
      "Step: 221, Loss: 0.9131177663803101\n",
      "Step: 222, Loss: 0.9127804636955261\n",
      "Step: 223, Loss: 0.9132279753684998\n",
      "Step: 224, Loss: 0.9121560454368591\n",
      "Step: 225, Loss: 0.9123035073280334\n",
      "Step: 226, Loss: 0.9119336009025574\n",
      "Step: 227, Loss: 0.9112699627876282\n",
      "Step: 228, Loss: 0.9121218919754028\n",
      "Step: 229, Loss: 0.9119135737419128\n",
      "Step: 230, Loss: 0.9114130139350891\n",
      "Step: 231, Loss: 0.9113233685493469\n",
      "Step: 232, Loss: 0.9109101295471191\n",
      "Step: 233, Loss: 0.9113695025444031\n",
      "Step: 234, Loss: 0.9117172956466675\n",
      "Step: 235, Loss: 0.9121771454811096\n",
      "Step: 236, Loss: 0.9111161231994629\n",
      "Step: 237, Loss: 0.9107758402824402\n",
      "Step: 238, Loss: 0.9117228388786316\n",
      "Step: 239, Loss: 0.9121185541152954\n",
      "Step: 240, Loss: 0.9113235473632812\n",
      "Step: 241, Loss: 0.9113191962242126\n",
      "Step: 242, Loss: 0.9114952683448792\n",
      "Step: 243, Loss: 0.9112772345542908\n",
      "Step: 244, Loss: 0.911538302898407\n",
      "Step: 245, Loss: 0.9112443923950195\n",
      "Step: 246, Loss: 0.9111483693122864\n",
      "Step: 247, Loss: 0.9116909503936768\n",
      "Step: 248, Loss: 0.9104663729667664\n",
      "Step: 249, Loss: 0.9102597832679749\n",
      "Step: 250, Loss: 0.911095142364502\n",
      "Step: 251, Loss: 0.9120346307754517\n",
      "Step: 252, Loss: 0.9108622670173645\n",
      "Step: 253, Loss: 0.9114649295806885\n",
      "Step: 254, Loss: 0.9101470112800598\n",
      "Step: 255, Loss: 0.9115918278694153\n",
      "Step: 256, Loss: 0.9111805558204651\n",
      "Step: 257, Loss: 0.9105533957481384\n",
      "Step: 258, Loss: 0.9105369448661804\n",
      "Step: 259, Loss: 0.9106663465499878\n",
      "Step: 260, Loss: 0.9104199409484863\n",
      "Step: 261, Loss: 0.9099656939506531\n",
      "Step: 262, Loss: 0.9117618799209595\n",
      "Step: 263, Loss: 0.9112744331359863\n",
      "Step: 264, Loss: 0.9107075929641724\n",
      "Step: 265, Loss: 0.9106709361076355\n",
      "Step: 266, Loss: 0.9113155007362366\n",
      "Step: 267, Loss: 0.9114601612091064\n",
      "Step: 268, Loss: 0.9117432832717896\n",
      "Step: 269, Loss: 0.911075234413147\n",
      "Step: 270, Loss: 0.911624550819397\n",
      "Step: 271, Loss: 0.9108553528785706\n",
      "Step: 272, Loss: 0.9105857610702515\n",
      "Step: 273, Loss: 0.9109302759170532\n",
      "Step: 274, Loss: 0.9110245108604431\n",
      "Step: 275, Loss: 0.9104992151260376\n",
      "Step: 276, Loss: 0.9105553030967712\n",
      "Step: 277, Loss: 0.9106982350349426\n",
      "Step: 278, Loss: 0.9112666845321655\n",
      "Step: 279, Loss: 0.9110047817230225\n",
      "Step: 280, Loss: 0.9099764227867126\n",
      "Step: 281, Loss: 0.9100751876831055\n",
      "Step: 282, Loss: 0.9096783995628357\n",
      "Step: 283, Loss: 0.9115806818008423\n",
      "Step: 284, Loss: 0.9095757007598877\n",
      "Step: 285, Loss: 0.9094858765602112\n",
      "Step: 286, Loss: 0.9105876684188843\n",
      "Step: 287, Loss: 0.909612774848938\n",
      "Step: 288, Loss: 0.9094934463500977\n",
      "Step: 289, Loss: 0.9087766408920288\n",
      "Step: 290, Loss: 0.9105983376502991\n",
      "Step: 291, Loss: 0.910449206829071\n",
      "Step: 292, Loss: 0.910552978515625\n",
      "Step: 293, Loss: 0.9098638892173767\n",
      "Step: 294, Loss: 0.9100528359413147\n",
      "Step: 295, Loss: 0.9107630848884583\n",
      "Step: 296, Loss: 0.9104796648025513\n",
      "Step: 297, Loss: 0.9101483225822449\n",
      "Step: 298, Loss: 0.9101188778877258\n",
      "Step: 299, Loss: 0.9098396897315979\n",
      "Step: 300, Loss: 0.9102401733398438\n",
      "Step: 301, Loss: 0.9105818867683411\n",
      "Step: 302, Loss: 0.909705400466919\n",
      "Step: 303, Loss: 0.9108240008354187\n",
      "Step: 304, Loss: 0.9100075960159302\n",
      "Step: 305, Loss: 0.9099960327148438\n",
      "Step: 306, Loss: 0.9103037118911743\n",
      "Step: 307, Loss: 0.9091737866401672\n",
      "Step: 308, Loss: 0.9100179672241211\n",
      "Step: 309, Loss: 0.9101181626319885\n",
      "Step: 310, Loss: 0.9104417562484741\n",
      "Step: 311, Loss: 0.9108829498291016\n",
      "Step: 312, Loss: 0.9103434681892395\n",
      "Step: 313, Loss: 0.9091595411300659\n",
      "Step: 314, Loss: 0.9093983769416809\n",
      "Step: 315, Loss: 0.9098288416862488\n",
      "Step: 316, Loss: 0.9090290665626526\n",
      "Step: 317, Loss: 0.9099205136299133\n",
      "Step: 318, Loss: 0.9106265902519226\n",
      "Step: 319, Loss: 0.9095278382301331\n",
      "Step: 320, Loss: 0.9092063307762146\n",
      "Step: 321, Loss: 0.9101464152336121\n",
      "Step: 322, Loss: 0.9100943803787231\n",
      "Step: 323, Loss: 0.9087420105934143\n",
      "Step: 324, Loss: 0.9094235897064209\n",
      "Step: 325, Loss: 0.9089789986610413\n",
      "Step: 326, Loss: 0.9102068543434143\n",
      "Step: 327, Loss: 0.9099519848823547\n",
      "Step: 328, Loss: 0.9111778140068054\n",
      "Step: 329, Loss: 0.9104271531105042\n",
      "Step: 330, Loss: 0.9101598262786865\n",
      "Step: 331, Loss: 0.9103681445121765\n",
      "Step: 332, Loss: 0.9104770421981812\n",
      "Step: 333, Loss: 0.9086165428161621\n",
      "Step: 334, Loss: 0.9105627536773682\n",
      "Step: 335, Loss: 0.9098879098892212\n",
      "Step: 336, Loss: 0.9096012115478516\n",
      "Step: 337, Loss: 0.908966600894928\n",
      "Step: 338, Loss: 0.909799337387085\n",
      "Step: 339, Loss: 0.9091629981994629\n",
      "Step: 340, Loss: 0.9086290597915649\n",
      "Step: 341, Loss: 0.9102035760879517\n",
      "Step: 342, Loss: 0.9097188711166382\n",
      "Step: 343, Loss: 0.9103803038597107\n",
      "Step: 344, Loss: 0.9096003174781799\n",
      "Step: 345, Loss: 0.9093782305717468\n",
      "Step: 346, Loss: 0.9085996150970459\n",
      "Step: 347, Loss: 0.9102922081947327\n",
      "Step: 348, Loss: 0.9085363149642944\n",
      "Step: 349, Loss: 0.9103222489356995\n",
      "Step: 350, Loss: 0.9101186990737915\n",
      "Step: 351, Loss: 0.9070789217948914\n",
      "Step: 352, Loss: 0.908565104007721\n",
      "Step: 353, Loss: 0.9082165360450745\n",
      "Step: 354, Loss: 0.9094483852386475\n",
      "Step: 355, Loss: 0.9094672203063965\n",
      "Step: 356, Loss: 0.9095808267593384\n",
      "Step: 357, Loss: 0.909288763999939\n",
      "Step: 358, Loss: 0.910300612449646\n",
      "Step: 359, Loss: 0.9089083671569824\n",
      "Step: 360, Loss: 0.9096059799194336\n",
      "Step: 361, Loss: 0.9091171026229858\n",
      "Step: 362, Loss: 0.9094247817993164\n",
      "Step: 363, Loss: 0.9093271493911743\n",
      "Step: 364, Loss: 0.9079575538635254\n",
      "Step: 365, Loss: 0.9104622602462769\n",
      "Step: 366, Loss: 0.9096295237541199\n",
      "Step: 367, Loss: 0.9091566205024719\n",
      "Step: 368, Loss: 0.908623456954956\n",
      "Step: 369, Loss: 0.9085641503334045\n",
      "Step: 370, Loss: 0.9090968370437622\n",
      "Step: 371, Loss: 0.9085485935211182\n",
      "Step: 372, Loss: 0.909984827041626\n",
      "Step: 373, Loss: 0.9097812175750732\n",
      "Step: 374, Loss: 0.9090626835823059\n",
      "Step: 375, Loss: 0.9086045622825623\n",
      "Step: 376, Loss: 0.9100898504257202\n",
      "Step: 377, Loss: 0.9093806147575378\n",
      "Step: 378, Loss: 0.9092099070549011\n",
      "Step: 379, Loss: 0.9090903401374817\n",
      "Step: 380, Loss: 0.9085528254508972\n",
      "Step: 381, Loss: 0.9087591767311096\n",
      "Step: 382, Loss: 0.9086363911628723\n",
      "Step: 383, Loss: 0.9084784984588623\n",
      "Step: 384, Loss: 0.9093963503837585\n",
      "Step: 385, Loss: 0.9095982313156128\n",
      "Step: 386, Loss: 0.9081130027770996\n",
      "Step: 387, Loss: 0.9087188243865967\n",
      "Step: 388, Loss: 0.9095599055290222\n",
      "Step: 389, Loss: 0.9090295433998108\n",
      "Step: 390, Loss: 0.9087197184562683\n",
      "Step: 391, Loss: 0.9081257581710815\n",
      "Step: 392, Loss: 0.909440815448761\n",
      "Step: 393, Loss: 0.9082424640655518\n",
      "Step: 394, Loss: 0.9073588252067566\n",
      "Step: 395, Loss: 0.9096426963806152\n",
      "Step: 396, Loss: 0.9084071516990662\n",
      "Step: 397, Loss: 0.9086150527000427\n",
      "Step: 398, Loss: 0.9090145230293274\n",
      "Step: 399, Loss: 0.9101224541664124\n",
      "Step: 400, Loss: 0.9080911874771118\n",
      "Step: 401, Loss: 0.9089875817298889\n",
      "Step: 402, Loss: 0.9083596467971802\n",
      "Step: 403, Loss: 0.9097269773483276\n",
      "Step: 404, Loss: 0.9096269607543945\n",
      "Step: 405, Loss: 0.9096640348434448\n",
      "Step: 406, Loss: 0.9092739820480347\n",
      "Step: 407, Loss: 0.9076346755027771\n",
      "Step: 408, Loss: 0.9097197651863098\n",
      "Step: 409, Loss: 0.9082367420196533\n",
      "Step: 410, Loss: 0.9083107709884644\n",
      "Step: 411, Loss: 0.9086624979972839\n",
      "Step: 412, Loss: 0.9093378782272339\n",
      "Step: 413, Loss: 0.9086116552352905\n",
      "Step: 414, Loss: 0.9091517329216003\n",
      "Step: 415, Loss: 0.9101201891899109\n",
      "Step: 416, Loss: 0.90948486328125\n",
      "Step: 417, Loss: 0.9079931974411011\n",
      "Step: 418, Loss: 0.9092142581939697\n",
      "Step: 419, Loss: 0.908815860748291\n",
      "Step: 420, Loss: 0.9084863066673279\n",
      "Step: 421, Loss: 0.9091078042984009\n",
      "Step: 422, Loss: 0.9078617095947266\n",
      "Step: 423, Loss: 0.908450722694397\n",
      "Step: 424, Loss: 0.9084842205047607\n",
      "Step: 425, Loss: 0.9088044762611389\n",
      "Step: 426, Loss: 0.9085033535957336\n",
      "Step: 427, Loss: 0.9083596467971802\n",
      "Step: 428, Loss: 0.9085488319396973\n",
      "Step: 429, Loss: 0.9090943932533264\n",
      "Step: 430, Loss: 0.907958984375\n",
      "Step: 431, Loss: 0.9095620512962341\n",
      "Step: 432, Loss: 0.9093018770217896\n",
      "Step: 433, Loss: 0.9083120822906494\n",
      "Step: 434, Loss: 0.9088448286056519\n",
      "Step: 435, Loss: 0.9077891111373901\n",
      "Step: 436, Loss: 0.9085872173309326\n",
      "Step: 437, Loss: 0.9093602299690247\n",
      "Step: 438, Loss: 0.9098733067512512\n",
      "Step: 439, Loss: 0.9087207913398743\n",
      "Step: 440, Loss: 0.9091655015945435\n",
      "Step: 441, Loss: 0.9082368016242981\n",
      "Step: 442, Loss: 0.9084510803222656\n",
      "Step: 443, Loss: 0.9092928171157837\n",
      "Step: 444, Loss: 0.9087584018707275\n",
      "Step: 445, Loss: 0.9091720581054688\n",
      "Step: 446, Loss: 0.9082659482955933\n",
      "Step: 447, Loss: 0.9093314409255981\n",
      "Step: 448, Loss: 0.908377468585968\n",
      "Step: 449, Loss: 0.9082112908363342\n",
      "Step: 450, Loss: 0.9077842831611633\n",
      "Step: 451, Loss: 0.9088089466094971\n",
      "Step: 452, Loss: 0.9085928201675415\n",
      "Step: 453, Loss: 0.9086138606071472\n",
      "Step: 454, Loss: 0.9081290364265442\n",
      "Step: 455, Loss: 0.90843665599823\n",
      "Step: 456, Loss: 0.9079415798187256\n",
      "Step: 457, Loss: 0.9082013964653015\n",
      "Step: 458, Loss: 0.9089232683181763\n",
      "Step: 459, Loss: 0.9085890054702759\n",
      "Step: 460, Loss: 0.9090173244476318\n",
      "Step: 461, Loss: 0.9083919525146484\n",
      "Step: 462, Loss: 0.9092127680778503\n",
      "Step: 463, Loss: 0.907731831073761\n",
      "Step: 464, Loss: 0.9088922142982483\n",
      "Step: 465, Loss: 0.9084039926528931\n",
      "Step: 466, Loss: 0.9095460176467896\n",
      "Step: 467, Loss: 0.9081815481185913\n",
      "Step: 468, Loss: 0.9088227152824402\n",
      "Step: 469, Loss: 0.9079960584640503\n",
      "Step: 470, Loss: 0.9089271426200867\n",
      "Step: 471, Loss: 0.9088748693466187\n",
      "Step: 472, Loss: 0.9087874889373779\n",
      "Step: 473, Loss: 0.9084522724151611\n",
      "Step: 474, Loss: 0.9085162281990051\n",
      "Step: 475, Loss: 0.9089483618736267\n",
      "Step: 476, Loss: 0.9091464877128601\n",
      "Step: 477, Loss: 0.9082377552986145\n",
      "Step: 478, Loss: 0.908810555934906\n",
      "Step: 479, Loss: 0.9086891412734985\n",
      "Step: 480, Loss: 0.9081168174743652\n",
      "Step: 481, Loss: 0.9090120196342468\n",
      "Step: 482, Loss: 0.9088080525398254\n",
      "Step: 483, Loss: 0.908654510974884\n",
      "Step: 484, Loss: 0.9071133732795715\n",
      "Step: 485, Loss: 0.9091089963912964\n",
      "Step: 486, Loss: 0.9077090620994568\n",
      "Step: 487, Loss: 0.9087273478507996\n",
      "Step: 488, Loss: 0.9093807339668274\n",
      "Step: 489, Loss: 0.9084521532058716\n",
      "Step: 490, Loss: 0.9091145992279053\n",
      "Step: 491, Loss: 0.908543050289154\n",
      "Step: 492, Loss: 0.9091633558273315\n",
      "Step: 493, Loss: 0.9085509777069092\n",
      "Step: 494, Loss: 0.9086922407150269\n",
      "Step: 495, Loss: 0.9083317518234253\n",
      "Step: 496, Loss: 0.9082704186439514\n",
      "Step: 497, Loss: 0.9080884456634521\n",
      "Step: 498, Loss: 0.9088388681411743\n",
      "Step: 499, Loss: 0.9078782200813293\n",
      "Step: 0, Loss: 2.913578748703003\n",
      "Step: 1, Loss: 2.871795654296875\n",
      "Step: 2, Loss: 2.82712984085083\n",
      "Step: 3, Loss: 2.789533853530884\n",
      "Step: 4, Loss: 2.759634494781494\n",
      "Step: 5, Loss: 2.7159199714660645\n",
      "Step: 6, Loss: 2.6731667518615723\n",
      "Step: 7, Loss: 2.6411120891571045\n",
      "Step: 8, Loss: 2.605955123901367\n",
      "Step: 9, Loss: 2.566290855407715\n",
      "Step: 10, Loss: 2.532449722290039\n",
      "Step: 11, Loss: 2.499096393585205\n",
      "Step: 12, Loss: 2.463649272918701\n",
      "Step: 13, Loss: 2.430691957473755\n",
      "Step: 14, Loss: 2.3963334560394287\n",
      "Step: 15, Loss: 2.3616890907287598\n",
      "Step: 16, Loss: 2.329306125640869\n",
      "Step: 17, Loss: 2.295293092727661\n",
      "Step: 18, Loss: 2.2608768939971924\n",
      "Step: 19, Loss: 2.2268171310424805\n",
      "Step: 20, Loss: 2.20107364654541\n",
      "Step: 21, Loss: 2.1695685386657715\n",
      "Step: 22, Loss: 2.1380841732025146\n",
      "Step: 23, Loss: 2.1173388957977295\n",
      "Step: 24, Loss: 2.0825393199920654\n",
      "Step: 25, Loss: 2.0523135662078857\n",
      "Step: 26, Loss: 2.0296826362609863\n",
      "Step: 27, Loss: 1.9979201555252075\n",
      "Step: 28, Loss: 1.9704300165176392\n",
      "Step: 29, Loss: 1.9454643726348877\n",
      "Step: 30, Loss: 1.9212015867233276\n",
      "Step: 31, Loss: 1.8945660591125488\n",
      "Step: 32, Loss: 1.8724794387817383\n",
      "Step: 33, Loss: 1.848014235496521\n",
      "Step: 34, Loss: 1.8249101638793945\n",
      "Step: 35, Loss: 1.7999284267425537\n",
      "Step: 36, Loss: 1.7787466049194336\n",
      "Step: 37, Loss: 1.7567225694656372\n",
      "Step: 38, Loss: 1.733731985092163\n",
      "Step: 39, Loss: 1.7128676176071167\n",
      "Step: 40, Loss: 1.6929129362106323\n",
      "Step: 41, Loss: 1.6727193593978882\n",
      "Step: 42, Loss: 1.6495054960250854\n",
      "Step: 43, Loss: 1.6288046836853027\n",
      "Step: 44, Loss: 1.6114667654037476\n",
      "Step: 45, Loss: 1.5887497663497925\n",
      "Step: 46, Loss: 1.5726876258850098\n",
      "Step: 47, Loss: 1.5494765043258667\n",
      "Step: 48, Loss: 1.5335092544555664\n",
      "Step: 49, Loss: 1.514487385749817\n",
      "Step: 50, Loss: 1.4985013008117676\n",
      "Step: 51, Loss: 1.4781609773635864\n",
      "Step: 52, Loss: 1.463910460472107\n",
      "Step: 53, Loss: 1.4422993659973145\n",
      "Step: 54, Loss: 1.4271196126937866\n",
      "Step: 55, Loss: 1.408308506011963\n",
      "Step: 56, Loss: 1.3907806873321533\n",
      "Step: 57, Loss: 1.3734643459320068\n",
      "Step: 58, Loss: 1.355877161026001\n",
      "Step: 59, Loss: 1.3401347398757935\n",
      "Step: 60, Loss: 1.325225830078125\n",
      "Step: 61, Loss: 1.3048806190490723\n",
      "Step: 62, Loss: 1.289841890335083\n",
      "Step: 63, Loss: 1.2729734182357788\n",
      "Step: 64, Loss: 1.261672854423523\n",
      "Step: 65, Loss: 1.245421051979065\n",
      "Step: 66, Loss: 1.2278881072998047\n",
      "Step: 67, Loss: 1.215285301208496\n",
      "Step: 68, Loss: 1.1995657682418823\n",
      "Step: 69, Loss: 1.1861329078674316\n",
      "Step: 70, Loss: 1.1704216003417969\n",
      "Step: 71, Loss: 1.1562892198562622\n",
      "Step: 72, Loss: 1.1440850496292114\n",
      "Step: 73, Loss: 1.1326223611831665\n",
      "Step: 74, Loss: 1.1188760995864868\n",
      "Step: 75, Loss: 1.107467770576477\n",
      "Step: 76, Loss: 1.0941907167434692\n",
      "Step: 77, Loss: 1.0837597846984863\n",
      "Step: 78, Loss: 1.072077989578247\n",
      "Step: 79, Loss: 1.0587061643600464\n",
      "Step: 80, Loss: 1.0503135919570923\n",
      "Step: 81, Loss: 1.040506362915039\n",
      "Step: 82, Loss: 1.0296448469161987\n",
      "Step: 83, Loss: 1.022189736366272\n",
      "Step: 84, Loss: 1.0138071775436401\n",
      "Step: 85, Loss: 1.004791259765625\n",
      "Step: 86, Loss: 0.9977695345878601\n",
      "Step: 87, Loss: 0.9901372790336609\n",
      "Step: 88, Loss: 0.9808610677719116\n",
      "Step: 89, Loss: 0.9771217703819275\n",
      "Step: 90, Loss: 0.97165447473526\n",
      "Step: 91, Loss: 0.9637216925621033\n",
      "Step: 92, Loss: 0.9598907232284546\n",
      "Step: 93, Loss: 0.9543393850326538\n",
      "Step: 94, Loss: 0.951617419719696\n",
      "Step: 95, Loss: 0.9471681714057922\n",
      "Step: 96, Loss: 0.9433174133300781\n",
      "Step: 97, Loss: 0.9402245283126831\n",
      "Step: 98, Loss: 0.9374468326568604\n",
      "Step: 99, Loss: 0.9346767663955688\n",
      "Step: 100, Loss: 0.9336838722229004\n",
      "Step: 101, Loss: 0.9321485757827759\n",
      "Step: 102, Loss: 0.9291086196899414\n",
      "Step: 103, Loss: 0.9273583889007568\n",
      "Step: 104, Loss: 0.9264198541641235\n",
      "Step: 105, Loss: 0.9257357120513916\n",
      "Step: 106, Loss: 0.9249152541160583\n",
      "Step: 107, Loss: 0.9247676134109497\n",
      "Step: 108, Loss: 0.924144446849823\n",
      "Step: 109, Loss: 0.9232484698295593\n",
      "Step: 110, Loss: 0.9213310480117798\n",
      "Step: 111, Loss: 0.9215674996376038\n",
      "Step: 112, Loss: 0.9216888546943665\n",
      "Step: 113, Loss: 0.9219661951065063\n",
      "Step: 114, Loss: 0.9227685928344727\n",
      "Step: 115, Loss: 0.9201424717903137\n",
      "Step: 116, Loss: 0.9198690056800842\n",
      "Step: 117, Loss: 0.9203885197639465\n",
      "Step: 118, Loss: 0.9199835658073425\n",
      "Step: 119, Loss: 0.919279932975769\n",
      "Step: 120, Loss: 0.9201062321662903\n",
      "Step: 121, Loss: 0.9196131825447083\n",
      "Step: 122, Loss: 0.919560968875885\n",
      "Step: 123, Loss: 0.9187835454940796\n",
      "Step: 124, Loss: 0.9187490940093994\n",
      "Step: 125, Loss: 0.9189209342002869\n",
      "Step: 126, Loss: 0.9182291030883789\n",
      "Step: 127, Loss: 0.9175841808319092\n",
      "Step: 128, Loss: 0.9177572131156921\n",
      "Step: 129, Loss: 0.9172709584236145\n",
      "Step: 130, Loss: 0.9166081547737122\n",
      "Step: 131, Loss: 0.9173309206962585\n",
      "Step: 132, Loss: 0.9164382219314575\n",
      "Step: 133, Loss: 0.9166805744171143\n",
      "Step: 134, Loss: 0.916854202747345\n",
      "Step: 135, Loss: 0.916536271572113\n",
      "Step: 136, Loss: 0.9153800010681152\n",
      "Step: 137, Loss: 0.9154031276702881\n",
      "Step: 138, Loss: 0.9159005284309387\n",
      "Step: 139, Loss: 0.9159776568412781\n",
      "Step: 140, Loss: 0.9151573181152344\n",
      "Step: 141, Loss: 0.9156792759895325\n",
      "Step: 142, Loss: 0.9149054884910583\n",
      "Step: 143, Loss: 0.915479838848114\n",
      "Step: 144, Loss: 0.9161115288734436\n",
      "Step: 145, Loss: 0.9144766330718994\n",
      "Step: 146, Loss: 0.9134669899940491\n",
      "Step: 147, Loss: 0.9154031276702881\n",
      "Step: 148, Loss: 0.9133977890014648\n",
      "Step: 149, Loss: 0.9144229888916016\n",
      "Step: 150, Loss: 0.9131705164909363\n",
      "Step: 151, Loss: 0.9161466360092163\n",
      "Step: 152, Loss: 0.9144620895385742\n",
      "Step: 153, Loss: 0.913851797580719\n",
      "Step: 154, Loss: 0.9142952561378479\n",
      "Step: 155, Loss: 0.915154218673706\n",
      "Step: 156, Loss: 0.9135424494743347\n",
      "Step: 157, Loss: 0.9135401844978333\n",
      "Step: 158, Loss: 0.9140732884407043\n",
      "Step: 159, Loss: 0.913236141204834\n",
      "Step: 160, Loss: 0.9136278629302979\n",
      "Step: 161, Loss: 0.9140246510505676\n",
      "Step: 162, Loss: 0.9127640724182129\n",
      "Step: 163, Loss: 0.9135840535163879\n",
      "Step: 164, Loss: 0.9130313992500305\n",
      "Step: 165, Loss: 0.9146057367324829\n",
      "Step: 166, Loss: 0.9133085012435913\n",
      "Step: 167, Loss: 0.9136589169502258\n",
      "Step: 168, Loss: 0.9122969508171082\n",
      "Step: 169, Loss: 0.9123630523681641\n",
      "Step: 170, Loss: 0.9132497906684875\n",
      "Step: 171, Loss: 0.9125122427940369\n",
      "Step: 172, Loss: 0.9125171303749084\n",
      "Step: 173, Loss: 0.9129937291145325\n",
      "Step: 174, Loss: 0.9127834439277649\n",
      "Step: 175, Loss: 0.9116917848587036\n",
      "Step: 176, Loss: 0.9123960733413696\n",
      "Step: 177, Loss: 0.9131288528442383\n",
      "Step: 178, Loss: 0.9120938777923584\n",
      "Step: 179, Loss: 0.9125573039054871\n",
      "Step: 180, Loss: 0.9132044315338135\n",
      "Step: 181, Loss: 0.9116583466529846\n",
      "Step: 182, Loss: 0.9120982885360718\n",
      "Step: 183, Loss: 0.9123551845550537\n",
      "Step: 184, Loss: 0.9112342000007629\n",
      "Step: 185, Loss: 0.9122366309165955\n",
      "Step: 186, Loss: 0.912282407283783\n",
      "Step: 187, Loss: 0.9128649234771729\n",
      "Step: 188, Loss: 0.9114168882369995\n",
      "Step: 189, Loss: 0.9113390445709229\n",
      "Step: 190, Loss: 0.9106178283691406\n",
      "Step: 191, Loss: 0.9121444821357727\n",
      "Step: 192, Loss: 0.9116683006286621\n",
      "Step: 193, Loss: 0.9114437103271484\n",
      "Step: 194, Loss: 0.9113259315490723\n",
      "Step: 195, Loss: 0.9107597470283508\n",
      "Step: 196, Loss: 0.9110689163208008\n",
      "Step: 197, Loss: 0.9116291999816895\n",
      "Step: 198, Loss: 0.911384642124176\n",
      "Step: 199, Loss: 0.9110568761825562\n",
      "Step: 200, Loss: 0.911318838596344\n",
      "Step: 201, Loss: 0.9117119908332825\n",
      "Step: 202, Loss: 0.9114381670951843\n",
      "Step: 203, Loss: 0.9116696715354919\n",
      "Step: 204, Loss: 0.9109112620353699\n",
      "Step: 205, Loss: 0.9110068678855896\n",
      "Step: 206, Loss: 0.9104235172271729\n",
      "Step: 207, Loss: 0.9114634394645691\n",
      "Step: 208, Loss: 0.9104098677635193\n",
      "Step: 209, Loss: 0.91086745262146\n",
      "Step: 210, Loss: 0.9099380373954773\n",
      "Step: 211, Loss: 0.9111233353614807\n",
      "Step: 212, Loss: 0.9097833037376404\n",
      "Step: 213, Loss: 0.9109557271003723\n",
      "Step: 214, Loss: 0.9110522270202637\n",
      "Step: 215, Loss: 0.9098805785179138\n",
      "Step: 216, Loss: 0.9104266166687012\n",
      "Step: 217, Loss: 0.9093537330627441\n",
      "Step: 218, Loss: 0.910189151763916\n",
      "Step: 219, Loss: 0.9096080660820007\n",
      "Step: 220, Loss: 0.9091389179229736\n",
      "Step: 221, Loss: 0.9102658629417419\n",
      "Step: 222, Loss: 0.9094157814979553\n",
      "Step: 223, Loss: 0.9095653295516968\n",
      "Step: 224, Loss: 0.9106245040893555\n",
      "Step: 225, Loss: 0.9102820158004761\n",
      "Step: 226, Loss: 0.9096750020980835\n",
      "Step: 227, Loss: 0.9096260666847229\n",
      "Step: 228, Loss: 0.9103593230247498\n",
      "Step: 229, Loss: 0.9100224375724792\n",
      "Step: 230, Loss: 0.9105792045593262\n",
      "Step: 231, Loss: 0.9096699357032776\n",
      "Step: 232, Loss: 0.9093772768974304\n",
      "Step: 233, Loss: 0.9090206027030945\n",
      "Step: 234, Loss: 0.9099240899085999\n",
      "Step: 235, Loss: 0.9095128178596497\n",
      "Step: 236, Loss: 0.9091700911521912\n",
      "Step: 237, Loss: 0.9086222648620605\n",
      "Step: 238, Loss: 0.9091418981552124\n",
      "Step: 239, Loss: 0.9090552926063538\n",
      "Step: 240, Loss: 0.9101021885871887\n",
      "Step: 241, Loss: 0.9092099070549011\n",
      "Step: 242, Loss: 0.9097275733947754\n",
      "Step: 243, Loss: 0.908868134021759\n",
      "Step: 244, Loss: 0.9095696210861206\n",
      "Step: 245, Loss: 0.9082755446434021\n",
      "Step: 246, Loss: 0.9088523983955383\n",
      "Step: 247, Loss: 0.9085002541542053\n",
      "Step: 248, Loss: 0.9084625840187073\n",
      "Step: 249, Loss: 0.9096969366073608\n",
      "Step: 250, Loss: 0.9095252156257629\n",
      "Step: 251, Loss: 0.9078099727630615\n",
      "Step: 252, Loss: 0.907904326915741\n",
      "Step: 253, Loss: 0.9096447825431824\n",
      "Step: 254, Loss: 0.9090505242347717\n",
      "Step: 255, Loss: 0.9086641073226929\n",
      "Step: 256, Loss: 0.908497154712677\n",
      "Step: 257, Loss: 0.9079598188400269\n",
      "Step: 258, Loss: 0.9077749848365784\n",
      "Step: 259, Loss: 0.9091934561729431\n",
      "Step: 260, Loss: 0.9086752533912659\n",
      "Step: 261, Loss: 0.9083095192909241\n",
      "Step: 262, Loss: 0.9077473282814026\n",
      "Step: 263, Loss: 0.9077762961387634\n",
      "Step: 264, Loss: 0.9089301228523254\n",
      "Step: 265, Loss: 0.9088948369026184\n",
      "Step: 266, Loss: 0.9074528217315674\n",
      "Step: 267, Loss: 0.9090545773506165\n",
      "Step: 268, Loss: 0.9080922603607178\n",
      "Step: 269, Loss: 0.9078386425971985\n",
      "Step: 270, Loss: 0.9087215662002563\n",
      "Step: 271, Loss: 0.9076088666915894\n",
      "Step: 272, Loss: 0.907400369644165\n",
      "Step: 273, Loss: 0.9083153605461121\n",
      "Step: 274, Loss: 0.9073985815048218\n",
      "Step: 275, Loss: 0.9078958630561829\n",
      "Step: 276, Loss: 0.9079042077064514\n",
      "Step: 277, Loss: 0.9079806804656982\n",
      "Step: 278, Loss: 0.9082531929016113\n",
      "Step: 279, Loss: 0.9076807498931885\n",
      "Step: 280, Loss: 0.9089978933334351\n",
      "Step: 281, Loss: 0.9073769450187683\n",
      "Step: 282, Loss: 0.90847247838974\n",
      "Step: 283, Loss: 0.908164381980896\n",
      "Step: 284, Loss: 0.907759428024292\n",
      "Step: 285, Loss: 0.9079724550247192\n",
      "Step: 286, Loss: 0.9083003401756287\n",
      "Step: 287, Loss: 0.9077383279800415\n",
      "Step: 288, Loss: 0.9076175689697266\n",
      "Step: 289, Loss: 0.9072443842887878\n",
      "Step: 290, Loss: 0.9079810380935669\n",
      "Step: 291, Loss: 0.9072973728179932\n",
      "Step: 292, Loss: 0.9082668423652649\n",
      "Step: 293, Loss: 0.907651960849762\n",
      "Step: 294, Loss: 0.9058538675308228\n",
      "Step: 295, Loss: 0.9076092839241028\n",
      "Step: 296, Loss: 0.9072567820549011\n",
      "Step: 297, Loss: 0.9071654081344604\n",
      "Step: 298, Loss: 0.907111644744873\n",
      "Step: 299, Loss: 0.9073552489280701\n",
      "Step: 300, Loss: 0.9083174467086792\n",
      "Step: 301, Loss: 0.9076656699180603\n",
      "Step: 302, Loss: 0.9067735075950623\n",
      "Step: 303, Loss: 0.9072890877723694\n",
      "Step: 304, Loss: 0.9054665565490723\n",
      "Step: 305, Loss: 0.906834602355957\n",
      "Step: 306, Loss: 0.9068479537963867\n",
      "Step: 307, Loss: 0.9075451493263245\n",
      "Step: 308, Loss: 0.9076138138771057\n",
      "Step: 309, Loss: 0.9071160554885864\n",
      "Step: 310, Loss: 0.9076986908912659\n",
      "Step: 311, Loss: 0.9076480865478516\n",
      "Step: 312, Loss: 0.9071804881095886\n",
      "Step: 313, Loss: 0.9063414931297302\n",
      "Step: 314, Loss: 0.9064726829528809\n",
      "Step: 315, Loss: 0.9067269563674927\n",
      "Step: 316, Loss: 0.9077959060668945\n",
      "Step: 317, Loss: 0.9065309166908264\n",
      "Step: 318, Loss: 0.9065338969230652\n",
      "Step: 319, Loss: 0.9074752926826477\n",
      "Step: 320, Loss: 0.906200110912323\n",
      "Step: 321, Loss: 0.9075411558151245\n",
      "Step: 322, Loss: 0.9080948829650879\n",
      "Step: 323, Loss: 0.9073798060417175\n",
      "Step: 324, Loss: 0.9070772528648376\n",
      "Step: 325, Loss: 0.9065455794334412\n",
      "Step: 326, Loss: 0.9076542854309082\n",
      "Step: 327, Loss: 0.9067940711975098\n",
      "Step: 328, Loss: 0.9063218832015991\n",
      "Step: 329, Loss: 0.9071797132492065\n",
      "Step: 330, Loss: 0.9068629145622253\n",
      "Step: 331, Loss: 0.9077135324478149\n",
      "Step: 332, Loss: 0.9050479531288147\n",
      "Step: 333, Loss: 0.9057856798171997\n",
      "Step: 334, Loss: 0.905549943447113\n",
      "Step: 335, Loss: 0.9068936705589294\n",
      "Step: 336, Loss: 0.9060810208320618\n",
      "Step: 337, Loss: 0.9071403741836548\n",
      "Step: 338, Loss: 0.9057903289794922\n",
      "Step: 339, Loss: 0.908150851726532\n",
      "Step: 340, Loss: 0.9052053689956665\n",
      "Step: 341, Loss: 0.9060549736022949\n",
      "Step: 342, Loss: 0.9060471057891846\n",
      "Step: 343, Loss: 0.9061799645423889\n",
      "Step: 344, Loss: 0.9059101343154907\n",
      "Step: 345, Loss: 0.905643105506897\n",
      "Step: 346, Loss: 0.9060502052307129\n",
      "Step: 347, Loss: 0.9061869382858276\n",
      "Step: 348, Loss: 0.9067120552062988\n",
      "Step: 349, Loss: 0.9051205515861511\n",
      "Step: 350, Loss: 0.9061160683631897\n",
      "Step: 351, Loss: 0.9053196907043457\n",
      "Step: 352, Loss: 0.905887246131897\n",
      "Step: 353, Loss: 0.9052490592002869\n",
      "Step: 354, Loss: 0.906299352645874\n",
      "Step: 355, Loss: 0.9053231477737427\n",
      "Step: 356, Loss: 0.9065157175064087\n",
      "Step: 357, Loss: 0.906130850315094\n",
      "Step: 358, Loss: 0.9058924913406372\n",
      "Step: 359, Loss: 0.9060000777244568\n",
      "Step: 360, Loss: 0.9056656360626221\n",
      "Step: 361, Loss: 0.90608149766922\n",
      "Step: 362, Loss: 0.9055410027503967\n",
      "Step: 363, Loss: 0.9065597057342529\n",
      "Step: 364, Loss: 0.9055933952331543\n",
      "Step: 365, Loss: 0.9059618711471558\n",
      "Step: 366, Loss: 0.9058582782745361\n",
      "Step: 367, Loss: 0.9055881500244141\n",
      "Step: 368, Loss: 0.906431257724762\n",
      "Step: 369, Loss: 0.9063164591789246\n",
      "Step: 370, Loss: 0.9060946106910706\n",
      "Step: 371, Loss: 0.9062978029251099\n",
      "Step: 372, Loss: 0.9065380096435547\n",
      "Step: 373, Loss: 0.9046730399131775\n",
      "Step: 374, Loss: 0.9057127237319946\n",
      "Step: 375, Loss: 0.9052549004554749\n",
      "Step: 376, Loss: 0.9055798053741455\n",
      "Step: 377, Loss: 0.9054352641105652\n",
      "Step: 378, Loss: 0.9061838388442993\n",
      "Step: 379, Loss: 0.9053664803504944\n",
      "Step: 380, Loss: 0.9056364893913269\n",
      "Step: 381, Loss: 0.9056155681610107\n",
      "Step: 382, Loss: 0.9053930640220642\n",
      "Step: 383, Loss: 0.906056821346283\n",
      "Step: 384, Loss: 0.9055782556533813\n",
      "Step: 385, Loss: 0.9054973721504211\n",
      "Step: 386, Loss: 0.9062207937240601\n",
      "Step: 387, Loss: 0.9063528180122375\n",
      "Step: 388, Loss: 0.9052625894546509\n",
      "Step: 389, Loss: 0.9064919352531433\n",
      "Step: 390, Loss: 0.9047184586524963\n",
      "Step: 391, Loss: 0.9062932729721069\n",
      "Step: 392, Loss: 0.9057097434997559\n",
      "Step: 393, Loss: 0.9056066274642944\n",
      "Step: 394, Loss: 0.9055132269859314\n",
      "Step: 395, Loss: 0.9069835543632507\n",
      "Step: 396, Loss: 0.905156672000885\n",
      "Step: 397, Loss: 0.9054660797119141\n",
      "Step: 398, Loss: 0.9057480096817017\n",
      "Step: 399, Loss: 0.9067703485488892\n",
      "Step: 400, Loss: 0.9058318734169006\n",
      "Step: 401, Loss: 0.9066420197486877\n",
      "Step: 402, Loss: 0.906125545501709\n",
      "Step: 403, Loss: 0.9065249562263489\n",
      "Step: 404, Loss: 0.9050934910774231\n",
      "Step: 405, Loss: 0.9064492583274841\n",
      "Step: 406, Loss: 0.9054861664772034\n",
      "Step: 407, Loss: 0.9058572053909302\n",
      "Step: 408, Loss: 0.905765950679779\n",
      "Step: 409, Loss: 0.9058389663696289\n",
      "Step: 410, Loss: 0.90455162525177\n",
      "Step: 411, Loss: 0.9064991474151611\n",
      "Step: 412, Loss: 0.90531325340271\n",
      "Step: 413, Loss: 0.9056810736656189\n",
      "Step: 414, Loss: 0.9057159423828125\n",
      "Step: 415, Loss: 0.906779944896698\n",
      "Step: 416, Loss: 0.9058963060379028\n",
      "Step: 417, Loss: 0.905185878276825\n",
      "Step: 418, Loss: 0.9052435755729675\n",
      "Step: 419, Loss: 0.9058676362037659\n",
      "Step: 420, Loss: 0.9066739678382874\n",
      "Step: 421, Loss: 0.9050400257110596\n",
      "Step: 422, Loss: 0.9056345224380493\n",
      "Step: 423, Loss: 0.9059405326843262\n",
      "Step: 424, Loss: 0.9068760275840759\n",
      "Step: 425, Loss: 0.9059206247329712\n",
      "Step: 426, Loss: 0.9052532911300659\n",
      "Step: 427, Loss: 0.9064304828643799\n",
      "Step: 428, Loss: 0.904921293258667\n",
      "Step: 429, Loss: 0.9042047262191772\n",
      "Step: 430, Loss: 0.9048018455505371\n",
      "Step: 431, Loss: 0.9058762788772583\n",
      "Step: 432, Loss: 0.9053313136100769\n",
      "Step: 433, Loss: 0.9053882360458374\n",
      "Step: 434, Loss: 0.9053570628166199\n",
      "Step: 435, Loss: 0.90526282787323\n",
      "Step: 436, Loss: 0.9050065875053406\n",
      "Step: 437, Loss: 0.9056375026702881\n",
      "Step: 438, Loss: 0.9055078625679016\n",
      "Step: 439, Loss: 0.9057748913764954\n",
      "Step: 440, Loss: 0.9060314893722534\n",
      "Step: 441, Loss: 0.9053391218185425\n",
      "Step: 442, Loss: 0.9049737453460693\n",
      "Step: 443, Loss: 0.9050988554954529\n",
      "Step: 444, Loss: 0.905579686164856\n",
      "Step: 445, Loss: 0.9046560525894165\n",
      "Step: 446, Loss: 0.9049960970878601\n",
      "Step: 447, Loss: 0.9053915739059448\n",
      "Step: 448, Loss: 0.9056414365768433\n",
      "Step: 449, Loss: 0.9052008390426636\n",
      "Step: 450, Loss: 0.9050657153129578\n",
      "Step: 451, Loss: 0.9046183228492737\n",
      "Step: 452, Loss: 0.9052370190620422\n",
      "Step: 453, Loss: 0.9063823223114014\n",
      "Step: 454, Loss: 0.9057187438011169\n",
      "Step: 455, Loss: 0.9048485159873962\n",
      "Step: 456, Loss: 0.9050586223602295\n",
      "Step: 457, Loss: 0.906385600566864\n",
      "Step: 458, Loss: 0.9057983160018921\n",
      "Step: 459, Loss: 0.9051424264907837\n",
      "Step: 460, Loss: 0.9055594205856323\n",
      "Step: 461, Loss: 0.9042069911956787\n",
      "Step: 462, Loss: 0.905642032623291\n",
      "Step: 463, Loss: 0.9051080942153931\n",
      "Step: 464, Loss: 0.9047054052352905\n",
      "Step: 465, Loss: 0.9057295322418213\n",
      "Step: 466, Loss: 0.9056980013847351\n",
      "Step: 467, Loss: 0.9052432179450989\n",
      "Step: 468, Loss: 0.9051893949508667\n",
      "Step: 469, Loss: 0.9059553146362305\n",
      "Step: 470, Loss: 0.905785858631134\n",
      "Step: 471, Loss: 0.9063369035720825\n",
      "Step: 472, Loss: 0.9048712849617004\n",
      "Step: 473, Loss: 0.9049357771873474\n",
      "Step: 474, Loss: 0.9055437445640564\n",
      "Step: 475, Loss: 0.9059494733810425\n",
      "Step: 476, Loss: 0.9048865437507629\n",
      "Step: 477, Loss: 0.9055772423744202\n",
      "Step: 478, Loss: 0.9051077961921692\n",
      "Step: 479, Loss: 0.905956506729126\n",
      "Step: 480, Loss: 0.9058110117912292\n",
      "Step: 481, Loss: 0.9053187966346741\n",
      "Step: 482, Loss: 0.9048383235931396\n",
      "Step: 483, Loss: 0.9055629968643188\n",
      "Step: 484, Loss: 0.9055435061454773\n",
      "Step: 485, Loss: 0.9057809710502625\n",
      "Step: 486, Loss: 0.9056101441383362\n",
      "Step: 487, Loss: 0.9039450287818909\n",
      "Step: 488, Loss: 0.9052616953849792\n",
      "Step: 489, Loss: 0.9049103260040283\n",
      "Step: 490, Loss: 0.9052164554595947\n",
      "Step: 491, Loss: 0.9051230549812317\n",
      "Step: 492, Loss: 0.9054238200187683\n",
      "Step: 493, Loss: 0.9050036072731018\n",
      "Step: 494, Loss: 0.9045662879943848\n",
      "Step: 495, Loss: 0.9069344997406006\n",
      "Step: 496, Loss: 0.9047853946685791\n",
      "Step: 497, Loss: 0.9045388698577881\n",
      "Step: 498, Loss: 0.9038397669792175\n",
      "Step: 499, Loss: 0.9047816395759583\n",
      "Step: 0, Loss: 2.6735057830810547\n",
      "Step: 1, Loss: 2.6326100826263428\n",
      "Step: 2, Loss: 2.5841946601867676\n",
      "Step: 3, Loss: 2.5427334308624268\n",
      "Step: 4, Loss: 2.4978981018066406\n",
      "Step: 5, Loss: 2.4598398208618164\n",
      "Step: 6, Loss: 2.414067029953003\n",
      "Step: 7, Loss: 2.3809216022491455\n",
      "Step: 8, Loss: 2.335846185684204\n",
      "Step: 9, Loss: 2.3017032146453857\n",
      "Step: 10, Loss: 2.266143798828125\n",
      "Step: 11, Loss: 2.2281301021575928\n",
      "Step: 12, Loss: 2.194408655166626\n",
      "Step: 13, Loss: 2.1590981483459473\n",
      "Step: 14, Loss: 2.122846841812134\n",
      "Step: 15, Loss: 2.094399929046631\n",
      "Step: 16, Loss: 2.061617612838745\n",
      "Step: 17, Loss: 2.032759666442871\n",
      "Step: 18, Loss: 2.0025413036346436\n",
      "Step: 19, Loss: 1.9725372791290283\n",
      "Step: 20, Loss: 1.9447720050811768\n",
      "Step: 21, Loss: 1.9128583669662476\n",
      "Step: 22, Loss: 1.8915178775787354\n",
      "Step: 23, Loss: 1.8639724254608154\n",
      "Step: 24, Loss: 1.836280345916748\n",
      "Step: 25, Loss: 1.8103569746017456\n",
      "Step: 26, Loss: 1.7892847061157227\n",
      "Step: 27, Loss: 1.7676162719726562\n",
      "Step: 28, Loss: 1.743876576423645\n",
      "Step: 29, Loss: 1.7218437194824219\n",
      "Step: 30, Loss: 1.7017650604248047\n",
      "Step: 31, Loss: 1.6825881004333496\n",
      "Step: 32, Loss: 1.6615391969680786\n",
      "Step: 33, Loss: 1.6432069540023804\n",
      "Step: 34, Loss: 1.6233638525009155\n",
      "Step: 35, Loss: 1.6055725812911987\n",
      "Step: 36, Loss: 1.5878403186798096\n",
      "Step: 37, Loss: 1.5697426795959473\n",
      "Step: 38, Loss: 1.550920844078064\n",
      "Step: 39, Loss: 1.5344568490982056\n",
      "Step: 40, Loss: 1.5192421674728394\n",
      "Step: 41, Loss: 1.5013134479522705\n",
      "Step: 42, Loss: 1.4880319833755493\n",
      "Step: 43, Loss: 1.469173550605774\n",
      "Step: 44, Loss: 1.4542920589447021\n",
      "Step: 45, Loss: 1.437515377998352\n",
      "Step: 46, Loss: 1.4234787225723267\n",
      "Step: 47, Loss: 1.4072272777557373\n",
      "Step: 48, Loss: 1.3923271894454956\n",
      "Step: 49, Loss: 1.3795719146728516\n",
      "Step: 50, Loss: 1.3620030879974365\n",
      "Step: 51, Loss: 1.3477518558502197\n",
      "Step: 52, Loss: 1.3324185609817505\n",
      "Step: 53, Loss: 1.3179550170898438\n",
      "Step: 54, Loss: 1.3044772148132324\n",
      "Step: 55, Loss: 1.2907780408859253\n",
      "Step: 56, Loss: 1.2774847745895386\n",
      "Step: 57, Loss: 1.262532114982605\n",
      "Step: 58, Loss: 1.250978946685791\n",
      "Step: 59, Loss: 1.2383803129196167\n",
      "Step: 60, Loss: 1.2246772050857544\n",
      "Step: 61, Loss: 1.212095022201538\n",
      "Step: 62, Loss: 1.2011967897415161\n",
      "Step: 63, Loss: 1.189632534980774\n",
      "Step: 64, Loss: 1.175384283065796\n",
      "Step: 65, Loss: 1.1655890941619873\n",
      "Step: 66, Loss: 1.155225157737732\n",
      "Step: 67, Loss: 1.1430169343948364\n",
      "Step: 68, Loss: 1.1331552267074585\n",
      "Step: 69, Loss: 1.1225897073745728\n",
      "Step: 70, Loss: 1.1128363609313965\n",
      "Step: 71, Loss: 1.102771282196045\n",
      "Step: 72, Loss: 1.093571424484253\n",
      "Step: 73, Loss: 1.0860424041748047\n",
      "Step: 74, Loss: 1.0768568515777588\n",
      "Step: 75, Loss: 1.0659035444259644\n",
      "Step: 76, Loss: 1.059314489364624\n",
      "Step: 77, Loss: 1.050573706626892\n",
      "Step: 78, Loss: 1.0418225526809692\n",
      "Step: 79, Loss: 1.034964680671692\n",
      "Step: 80, Loss: 1.028679370880127\n",
      "Step: 81, Loss: 1.0222067832946777\n",
      "Step: 82, Loss: 1.0145957469940186\n",
      "Step: 83, Loss: 1.0079113245010376\n",
      "Step: 84, Loss: 1.001013159751892\n",
      "Step: 85, Loss: 0.9958834648132324\n",
      "Step: 86, Loss: 0.9906693696975708\n",
      "Step: 87, Loss: 0.9857417941093445\n",
      "Step: 88, Loss: 0.9805114269256592\n",
      "Step: 89, Loss: 0.9757383465766907\n",
      "Step: 90, Loss: 0.9710303544998169\n",
      "Step: 91, Loss: 0.9691447615623474\n",
      "Step: 92, Loss: 0.9636812806129456\n",
      "Step: 93, Loss: 0.96030592918396\n",
      "Step: 94, Loss: 0.955538272857666\n",
      "Step: 95, Loss: 0.9535638689994812\n",
      "Step: 96, Loss: 0.951177716255188\n",
      "Step: 97, Loss: 0.9466665387153625\n",
      "Step: 98, Loss: 0.9450498819351196\n",
      "Step: 99, Loss: 0.9421431422233582\n",
      "Step: 100, Loss: 0.9400281310081482\n",
      "Step: 101, Loss: 0.936772882938385\n",
      "Step: 102, Loss: 0.9355838894844055\n",
      "Step: 103, Loss: 0.9351347088813782\n",
      "Step: 104, Loss: 0.9338230490684509\n",
      "Step: 105, Loss: 0.9322513937950134\n",
      "Step: 106, Loss: 0.9303926825523376\n",
      "Step: 107, Loss: 0.9295778274536133\n",
      "Step: 108, Loss: 0.9280250072479248\n",
      "Step: 109, Loss: 0.9273231029510498\n",
      "Step: 110, Loss: 0.927047073841095\n",
      "Step: 111, Loss: 0.9256961941719055\n",
      "Step: 112, Loss: 0.9257086515426636\n",
      "Step: 113, Loss: 0.92430180311203\n",
      "Step: 114, Loss: 0.9227930307388306\n",
      "Step: 115, Loss: 0.9233700633049011\n",
      "Step: 116, Loss: 0.9231011271476746\n",
      "Step: 117, Loss: 0.9232029914855957\n",
      "Step: 118, Loss: 0.922139585018158\n",
      "Step: 119, Loss: 0.9231860637664795\n",
      "Step: 120, Loss: 0.9220472574234009\n",
      "Step: 121, Loss: 0.9219838976860046\n",
      "Step: 122, Loss: 0.9209325909614563\n",
      "Step: 123, Loss: 0.9211438298225403\n",
      "Step: 124, Loss: 0.922080934047699\n",
      "Step: 125, Loss: 0.9215652942657471\n",
      "Step: 126, Loss: 0.9206158518791199\n",
      "Step: 127, Loss: 0.920502781867981\n",
      "Step: 128, Loss: 0.9204328656196594\n",
      "Step: 129, Loss: 0.9205079674720764\n",
      "Step: 130, Loss: 0.9203994274139404\n",
      "Step: 131, Loss: 0.9204452633857727\n",
      "Step: 132, Loss: 0.9201508164405823\n",
      "Step: 133, Loss: 0.9192713499069214\n",
      "Step: 134, Loss: 0.9187042713165283\n",
      "Step: 135, Loss: 0.9195460677146912\n",
      "Step: 136, Loss: 0.9199404716491699\n",
      "Step: 137, Loss: 0.9193371534347534\n",
      "Step: 138, Loss: 0.9188417196273804\n",
      "Step: 139, Loss: 0.9192009568214417\n",
      "Step: 140, Loss: 0.92015540599823\n",
      "Step: 141, Loss: 0.919327974319458\n",
      "Step: 142, Loss: 0.9187774062156677\n",
      "Step: 143, Loss: 0.9183327555656433\n",
      "Step: 144, Loss: 0.9182271957397461\n",
      "Step: 145, Loss: 0.9188709259033203\n",
      "Step: 146, Loss: 0.9187576770782471\n",
      "Step: 147, Loss: 0.9177867770195007\n",
      "Step: 148, Loss: 0.9177607297897339\n",
      "Step: 149, Loss: 0.9179649353027344\n",
      "Step: 150, Loss: 0.917716383934021\n",
      "Step: 151, Loss: 0.9173007607460022\n",
      "Step: 152, Loss: 0.9169172048568726\n",
      "Step: 153, Loss: 0.917326807975769\n",
      "Step: 154, Loss: 0.9175180196762085\n",
      "Step: 155, Loss: 0.9169111847877502\n",
      "Step: 156, Loss: 0.9176537394523621\n",
      "Step: 157, Loss: 0.917360246181488\n",
      "Step: 158, Loss: 0.9171916246414185\n",
      "Step: 159, Loss: 0.9175272583961487\n",
      "Step: 160, Loss: 0.916885256767273\n",
      "Step: 161, Loss: 0.9169527888298035\n",
      "Step: 162, Loss: 0.9167357087135315\n",
      "Step: 163, Loss: 0.9166375994682312\n",
      "Step: 164, Loss: 0.9179394245147705\n",
      "Step: 165, Loss: 0.9162425994873047\n",
      "Step: 166, Loss: 0.9163290858268738\n",
      "Step: 167, Loss: 0.9173836708068848\n",
      "Step: 168, Loss: 0.9174361824989319\n",
      "Step: 169, Loss: 0.9163908958435059\n",
      "Step: 170, Loss: 0.9159449338912964\n",
      "Step: 171, Loss: 0.9178116917610168\n",
      "Step: 172, Loss: 0.915842592716217\n",
      "Step: 173, Loss: 0.9163225293159485\n",
      "Step: 174, Loss: 0.9159630537033081\n",
      "Step: 175, Loss: 0.9152860641479492\n",
      "Step: 176, Loss: 0.9170777797698975\n",
      "Step: 177, Loss: 0.9157623648643494\n",
      "Step: 178, Loss: 0.9150160551071167\n",
      "Step: 179, Loss: 0.9153115153312683\n",
      "Step: 180, Loss: 0.915494978427887\n",
      "Step: 181, Loss: 0.9152851700782776\n",
      "Step: 182, Loss: 0.9149898290634155\n",
      "Step: 183, Loss: 0.9149666428565979\n",
      "Step: 184, Loss: 0.9153405427932739\n",
      "Step: 185, Loss: 0.9152330160140991\n",
      "Step: 186, Loss: 0.9152671098709106\n",
      "Step: 187, Loss: 0.9150580763816833\n",
      "Step: 188, Loss: 0.9156311750411987\n",
      "Step: 189, Loss: 0.9139366149902344\n",
      "Step: 190, Loss: 0.9144267439842224\n",
      "Step: 191, Loss: 0.9142261743545532\n",
      "Step: 192, Loss: 0.9138970375061035\n",
      "Step: 193, Loss: 0.9144939184188843\n",
      "Step: 194, Loss: 0.9150396585464478\n",
      "Step: 195, Loss: 0.9143378734588623\n",
      "Step: 196, Loss: 0.9142954349517822\n",
      "Step: 197, Loss: 0.9136898517608643\n",
      "Step: 198, Loss: 0.9143822193145752\n",
      "Step: 199, Loss: 0.9132773280143738\n",
      "Step: 200, Loss: 0.9134261012077332\n",
      "Step: 201, Loss: 0.9141892194747925\n",
      "Step: 202, Loss: 0.9130764007568359\n",
      "Step: 203, Loss: 0.9131889343261719\n",
      "Step: 204, Loss: 0.9134214520454407\n",
      "Step: 205, Loss: 0.9138679504394531\n",
      "Step: 206, Loss: 0.9127983450889587\n",
      "Step: 207, Loss: 0.9131343960762024\n",
      "Step: 208, Loss: 0.9143626689910889\n",
      "Step: 209, Loss: 0.9131605625152588\n",
      "Step: 210, Loss: 0.912552535533905\n",
      "Step: 211, Loss: 0.9120824337005615\n",
      "Step: 212, Loss: 0.9127325415611267\n",
      "Step: 213, Loss: 0.9126466512680054\n",
      "Step: 214, Loss: 0.9131845831871033\n",
      "Step: 215, Loss: 0.9126309156417847\n",
      "Step: 216, Loss: 0.9129959940910339\n",
      "Step: 217, Loss: 0.9129399061203003\n",
      "Step: 218, Loss: 0.9121698141098022\n",
      "Step: 219, Loss: 0.9122212529182434\n",
      "Step: 220, Loss: 0.9130493998527527\n",
      "Step: 221, Loss: 0.9131575226783752\n",
      "Step: 222, Loss: 0.9120838642120361\n",
      "Step: 223, Loss: 0.9124870300292969\n",
      "Step: 224, Loss: 0.9117143750190735\n",
      "Step: 225, Loss: 0.9131216406822205\n",
      "Step: 226, Loss: 0.9118269681930542\n",
      "Step: 227, Loss: 0.9120965600013733\n",
      "Step: 228, Loss: 0.9115110039710999\n",
      "Step: 229, Loss: 0.9118516445159912\n",
      "Step: 230, Loss: 0.9122896194458008\n",
      "Step: 231, Loss: 0.9105373620986938\n",
      "Step: 232, Loss: 0.9124932289123535\n",
      "Step: 233, Loss: 0.9115875363349915\n",
      "Step: 234, Loss: 0.9117521047592163\n",
      "Step: 235, Loss: 0.9110085964202881\n",
      "Step: 236, Loss: 0.9115661382675171\n",
      "Step: 237, Loss: 0.9121156930923462\n",
      "Step: 238, Loss: 0.9120568633079529\n",
      "Step: 239, Loss: 0.9118305444717407\n",
      "Step: 240, Loss: 0.9121665358543396\n",
      "Step: 241, Loss: 0.9115571975708008\n",
      "Step: 242, Loss: 0.9115276336669922\n",
      "Step: 243, Loss: 0.9115210175514221\n",
      "Step: 244, Loss: 0.9111393094062805\n",
      "Step: 245, Loss: 0.9106289744377136\n",
      "Step: 246, Loss: 0.9109443426132202\n",
      "Step: 247, Loss: 0.9104633331298828\n",
      "Step: 248, Loss: 0.9116718769073486\n",
      "Step: 249, Loss: 0.911214292049408\n",
      "Step: 250, Loss: 0.9107663035392761\n",
      "Step: 251, Loss: 0.9109480381011963\n",
      "Step: 252, Loss: 0.9110034108161926\n",
      "Step: 253, Loss: 0.9108384251594543\n",
      "Step: 254, Loss: 0.9105552434921265\n",
      "Step: 255, Loss: 0.9104739427566528\n",
      "Step: 256, Loss: 0.9098796248435974\n",
      "Step: 257, Loss: 0.9107001423835754\n",
      "Step: 258, Loss: 0.9102644920349121\n",
      "Step: 259, Loss: 0.9104253649711609\n",
      "Step: 260, Loss: 0.9105855822563171\n",
      "Step: 261, Loss: 0.9098688364028931\n",
      "Step: 262, Loss: 0.909988522529602\n",
      "Step: 263, Loss: 0.9097910523414612\n",
      "Step: 264, Loss: 0.9094208478927612\n",
      "Step: 265, Loss: 0.9105195999145508\n",
      "Step: 266, Loss: 0.9095975756645203\n",
      "Step: 267, Loss: 0.9107913374900818\n",
      "Step: 268, Loss: 0.9097194075584412\n",
      "Step: 269, Loss: 0.91026371717453\n",
      "Step: 270, Loss: 0.9103963375091553\n",
      "Step: 271, Loss: 0.9095847010612488\n",
      "Step: 272, Loss: 0.9089201092720032\n",
      "Step: 273, Loss: 0.909548819065094\n",
      "Step: 274, Loss: 0.9093641042709351\n",
      "Step: 275, Loss: 0.9098118543624878\n",
      "Step: 276, Loss: 0.9087748527526855\n",
      "Step: 277, Loss: 0.9090251922607422\n",
      "Step: 278, Loss: 0.9103288054466248\n",
      "Step: 279, Loss: 0.9097406268119812\n",
      "Step: 280, Loss: 0.9094783663749695\n",
      "Step: 281, Loss: 0.9090426564216614\n",
      "Step: 282, Loss: 0.9092379808425903\n",
      "Step: 283, Loss: 0.9100678563117981\n",
      "Step: 284, Loss: 0.9093789458274841\n",
      "Step: 285, Loss: 0.9092571139335632\n",
      "Step: 286, Loss: 0.9085702300071716\n",
      "Step: 287, Loss: 0.9094476699829102\n",
      "Step: 288, Loss: 0.9090676307678223\n",
      "Step: 289, Loss: 0.9088863730430603\n",
      "Step: 290, Loss: 0.9087561964988708\n",
      "Step: 291, Loss: 0.9096673130989075\n",
      "Step: 292, Loss: 0.908477246761322\n",
      "Step: 293, Loss: 0.9086230993270874\n",
      "Step: 294, Loss: 0.9090113043785095\n",
      "Step: 295, Loss: 0.907835066318512\n",
      "Step: 296, Loss: 0.9082993865013123\n",
      "Step: 297, Loss: 0.9091722369194031\n",
      "Step: 298, Loss: 0.9086548686027527\n",
      "Step: 299, Loss: 0.9087479710578918\n",
      "Step: 300, Loss: 0.9082376956939697\n",
      "Step: 301, Loss: 0.9094560742378235\n",
      "Step: 302, Loss: 0.9095130562782288\n",
      "Step: 303, Loss: 0.908808708190918\n",
      "Step: 304, Loss: 0.9085966348648071\n",
      "Step: 305, Loss: 0.909038782119751\n",
      "Step: 306, Loss: 0.9078362584114075\n",
      "Step: 307, Loss: 0.9094229936599731\n",
      "Step: 308, Loss: 0.9088096618652344\n",
      "Step: 309, Loss: 0.9080697894096375\n",
      "Step: 310, Loss: 0.9074390530586243\n",
      "Step: 311, Loss: 0.9077728390693665\n",
      "Step: 312, Loss: 0.908149003982544\n",
      "Step: 313, Loss: 0.9084442853927612\n",
      "Step: 314, Loss: 0.9075960516929626\n",
      "Step: 315, Loss: 0.9074516892433167\n",
      "Step: 316, Loss: 0.9090218544006348\n",
      "Step: 317, Loss: 0.9085445404052734\n",
      "Step: 318, Loss: 0.908821165561676\n",
      "Step: 319, Loss: 0.9091640710830688\n",
      "Step: 320, Loss: 0.9069969058036804\n",
      "Step: 321, Loss: 0.9090365767478943\n",
      "Step: 322, Loss: 0.9074884653091431\n",
      "Step: 323, Loss: 0.9080766439437866\n",
      "Step: 324, Loss: 0.9083706736564636\n",
      "Step: 325, Loss: 0.9082919955253601\n",
      "Step: 326, Loss: 0.9078519940376282\n",
      "Step: 327, Loss: 0.907256543636322\n",
      "Step: 328, Loss: 0.9080670475959778\n",
      "Step: 329, Loss: 0.9062047004699707\n",
      "Step: 330, Loss: 0.9071953296661377\n",
      "Step: 331, Loss: 0.9080321788787842\n",
      "Step: 332, Loss: 0.9074726104736328\n",
      "Step: 333, Loss: 0.9083855152130127\n",
      "Step: 334, Loss: 0.9081520438194275\n",
      "Step: 335, Loss: 0.9070832133293152\n",
      "Step: 336, Loss: 0.9067513942718506\n",
      "Step: 337, Loss: 0.9064555168151855\n",
      "Step: 338, Loss: 0.9079802632331848\n",
      "Step: 339, Loss: 0.9083421230316162\n",
      "Step: 340, Loss: 0.9071961045265198\n",
      "Step: 341, Loss: 0.9068182110786438\n",
      "Step: 342, Loss: 0.9076684713363647\n",
      "Step: 343, Loss: 0.9064796566963196\n",
      "Step: 344, Loss: 0.9078212380409241\n",
      "Step: 345, Loss: 0.9071226119995117\n",
      "Step: 346, Loss: 0.9079825282096863\n",
      "Step: 347, Loss: 0.9066717028617859\n",
      "Step: 348, Loss: 0.9073554873466492\n",
      "Step: 349, Loss: 0.907484233379364\n",
      "Step: 350, Loss: 0.9080370664596558\n",
      "Step: 351, Loss: 0.9075788259506226\n",
      "Step: 352, Loss: 0.908123791217804\n",
      "Step: 353, Loss: 0.9082844257354736\n",
      "Step: 354, Loss: 0.9078719019889832\n",
      "Step: 355, Loss: 0.9074098467826843\n",
      "Step: 356, Loss: 0.9073786735534668\n",
      "Step: 357, Loss: 0.9080514311790466\n",
      "Step: 358, Loss: 0.9079709053039551\n",
      "Step: 359, Loss: 0.9068329930305481\n",
      "Step: 360, Loss: 0.9076138138771057\n",
      "Step: 361, Loss: 0.9073084592819214\n",
      "Step: 362, Loss: 0.9066567420959473\n",
      "Step: 363, Loss: 0.9069521427154541\n",
      "Step: 364, Loss: 0.9070287942886353\n",
      "Step: 365, Loss: 0.9072309732437134\n",
      "Step: 366, Loss: 0.9070535898208618\n",
      "Step: 367, Loss: 0.9071657657623291\n",
      "Step: 368, Loss: 0.9069701433181763\n",
      "Step: 369, Loss: 0.9076980948448181\n",
      "Step: 370, Loss: 0.9076464772224426\n",
      "Step: 371, Loss: 0.9067569375038147\n",
      "Step: 372, Loss: 0.9069808125495911\n",
      "Step: 373, Loss: 0.9077918529510498\n",
      "Step: 374, Loss: 0.9068894386291504\n",
      "Step: 375, Loss: 0.9070913195610046\n",
      "Step: 376, Loss: 0.9071480631828308\n",
      "Step: 377, Loss: 0.9066210985183716\n",
      "Step: 378, Loss: 0.9061641097068787\n",
      "Step: 379, Loss: 0.9069847464561462\n",
      "Step: 380, Loss: 0.9069415926933289\n",
      "Step: 381, Loss: 0.9072068333625793\n",
      "Step: 382, Loss: 0.907495379447937\n",
      "Step: 383, Loss: 0.9064960479736328\n",
      "Step: 384, Loss: 0.9068093299865723\n",
      "Step: 385, Loss: 0.9072527289390564\n",
      "Step: 386, Loss: 0.9072657227516174\n",
      "Step: 387, Loss: 0.9057406187057495\n",
      "Step: 388, Loss: 0.9064255356788635\n",
      "Step: 389, Loss: 0.9067381024360657\n",
      "Step: 390, Loss: 0.9065876603126526\n",
      "Step: 391, Loss: 0.9070143699645996\n",
      "Step: 392, Loss: 0.9071414470672607\n",
      "Step: 393, Loss: 0.9070327281951904\n",
      "Step: 394, Loss: 0.9063289165496826\n",
      "Step: 395, Loss: 0.9061721563339233\n",
      "Step: 396, Loss: 0.9076733589172363\n",
      "Step: 397, Loss: 0.9064690470695496\n",
      "Step: 398, Loss: 0.9066635370254517\n",
      "Step: 399, Loss: 0.9072564244270325\n",
      "Step: 400, Loss: 0.9068072438240051\n",
      "Step: 401, Loss: 0.9069280624389648\n",
      "Step: 402, Loss: 0.9080001711845398\n",
      "Step: 403, Loss: 0.90619957447052\n",
      "Step: 404, Loss: 0.906795859336853\n",
      "Step: 405, Loss: 0.9075251817703247\n",
      "Step: 406, Loss: 0.9078083634376526\n",
      "Step: 407, Loss: 0.9070824980735779\n",
      "Step: 408, Loss: 0.9060685038566589\n",
      "Step: 409, Loss: 0.9072349071502686\n",
      "Step: 410, Loss: 0.9057621359825134\n",
      "Step: 411, Loss: 0.9065482020378113\n",
      "Step: 412, Loss: 0.9059832096099854\n",
      "Step: 413, Loss: 0.9060609936714172\n",
      "Step: 414, Loss: 0.90667724609375\n",
      "Step: 415, Loss: 0.9068437814712524\n",
      "Step: 416, Loss: 0.9060312509536743\n",
      "Step: 417, Loss: 0.9060056209564209\n",
      "Step: 418, Loss: 0.9063128232955933\n",
      "Step: 419, Loss: 0.9069207906723022\n",
      "Step: 420, Loss: 0.9067065715789795\n",
      "Step: 421, Loss: 0.9057715535163879\n",
      "Step: 422, Loss: 0.9052978754043579\n",
      "Step: 423, Loss: 0.9065750241279602\n",
      "Step: 424, Loss: 0.9063687920570374\n",
      "Step: 425, Loss: 0.9066072702407837\n",
      "Step: 426, Loss: 0.90642911195755\n",
      "Step: 427, Loss: 0.9059474468231201\n",
      "Step: 428, Loss: 0.9069216847419739\n",
      "Step: 429, Loss: 0.9073371291160583\n",
      "Step: 430, Loss: 0.9067908525466919\n",
      "Step: 431, Loss: 0.907600998878479\n",
      "Step: 432, Loss: 0.9065544605255127\n",
      "Step: 433, Loss: 0.9070400595664978\n",
      "Step: 434, Loss: 0.9063231945037842\n",
      "Step: 435, Loss: 0.9064100980758667\n",
      "Step: 436, Loss: 0.9059339165687561\n",
      "Step: 437, Loss: 0.9063910245895386\n",
      "Step: 438, Loss: 0.9056158065795898\n",
      "Step: 439, Loss: 0.9065195322036743\n",
      "Step: 440, Loss: 0.9062066674232483\n",
      "Step: 441, Loss: 0.9058889746665955\n",
      "Step: 442, Loss: 0.9071575999259949\n",
      "Step: 443, Loss: 0.907002329826355\n",
      "Step: 444, Loss: 0.906825840473175\n",
      "Step: 445, Loss: 0.9063541293144226\n",
      "Step: 446, Loss: 0.9065997004508972\n",
      "Step: 447, Loss: 0.9057264924049377\n",
      "Step: 448, Loss: 0.9066269993782043\n",
      "Step: 449, Loss: 0.906899094581604\n",
      "Step: 450, Loss: 0.9073309898376465\n",
      "Step: 451, Loss: 0.9060068130493164\n",
      "Step: 452, Loss: 0.9070268869400024\n",
      "Step: 453, Loss: 0.9063311815261841\n",
      "Step: 454, Loss: 0.9056058526039124\n",
      "Step: 455, Loss: 0.9067738652229309\n",
      "Step: 456, Loss: 0.906534731388092\n",
      "Step: 457, Loss: 0.9060524702072144\n",
      "Step: 458, Loss: 0.9060801863670349\n",
      "Step: 459, Loss: 0.9056518077850342\n",
      "Step: 460, Loss: 0.90664142370224\n",
      "Step: 461, Loss: 0.9057248830795288\n",
      "Step: 462, Loss: 0.9059501886367798\n",
      "Step: 463, Loss: 0.90785813331604\n",
      "Step: 464, Loss: 0.9064756035804749\n",
      "Step: 465, Loss: 0.90657639503479\n",
      "Step: 466, Loss: 0.906259298324585\n",
      "Step: 467, Loss: 0.9063471555709839\n",
      "Step: 468, Loss: 0.9065787196159363\n",
      "Step: 469, Loss: 0.9059029817581177\n",
      "Step: 470, Loss: 0.9070930480957031\n",
      "Step: 471, Loss: 0.9067816138267517\n",
      "Step: 472, Loss: 0.9059562683105469\n",
      "Step: 473, Loss: 0.9066025018692017\n",
      "Step: 474, Loss: 0.9067642092704773\n",
      "Step: 475, Loss: 0.9059498310089111\n",
      "Step: 476, Loss: 0.9060044288635254\n",
      "Step: 477, Loss: 0.9070686101913452\n",
      "Step: 478, Loss: 0.9062833189964294\n",
      "Step: 479, Loss: 0.9065158367156982\n",
      "Step: 480, Loss: 0.9065380096435547\n",
      "Step: 481, Loss: 0.9061166644096375\n",
      "Step: 482, Loss: 0.9066352248191833\n",
      "Step: 483, Loss: 0.9059030413627625\n",
      "Step: 484, Loss: 0.9053418040275574\n",
      "Step: 485, Loss: 0.9065420031547546\n",
      "Step: 486, Loss: 0.9065341949462891\n",
      "Step: 487, Loss: 0.906343400478363\n",
      "Step: 488, Loss: 0.9058331251144409\n",
      "Step: 489, Loss: 0.905972421169281\n",
      "Step: 490, Loss: 0.9060657620429993\n",
      "Step: 491, Loss: 0.9060940146446228\n",
      "Step: 492, Loss: 0.9056089520454407\n",
      "Step: 493, Loss: 0.9064276218414307\n",
      "Step: 494, Loss: 0.9062778353691101\n",
      "Step: 495, Loss: 0.906204104423523\n",
      "Step: 496, Loss: 0.906462550163269\n",
      "Step: 497, Loss: 0.906178891658783\n",
      "Step: 498, Loss: 0.9063588976860046\n",
      "Step: 499, Loss: 0.904822051525116\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "for model in models_crps:\n",
    "    models_crps[model].fit(X_train, y_train, variances_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup1[\"forecast_distribution\"] = \"mixture\"\n",
    "setup1[\"distribution_1\"] = \"distr_trunc_normal\"\n",
    "setup1[\"distribution_2\"] = \"distr_log_normal\"\n",
    "\n",
    "mixture_trunc_log_crps = EMOS(setup1)\n",
    "mixture\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
