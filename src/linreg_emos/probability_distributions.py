import tensorflow as tf
import tensorflow_probability as tfp

class DistributionMixture(tfp.distributions.Distribution):
    """
    A class representing a mixture of two distributions.
     
    Attributes:
        distribution_1 (tfp.distributions.Distribution): The first distribution in the mixture
        distribution_2 (tfp.distributions.Distribution): The second distribution in the mixture
        weight (tf.Tensor): The weight of the first distribution in the mixture
    """
    def __init__(self, distribution_1, distribution_2, weight):
        parameters = dict(locals())
        super(DistributionMixture, self).__init__(
            dtype=distribution_1.dtype,  # The type of the event samples.
            reparameterization_type=tfp.distributions.FULLY_REPARAMETERIZED,  # Indicates that samples can be reparameterized.
            validate_args=False,  # When True distribution parameters are checked for validity despite possibly degrading runtime performance
            allow_nan_stats=True,  # When True, statistics (e.g., mean, mode, variance) use the value NaN to indicate the result is undefined.
            parameters=parameters,
            name="DistributionMixture"
        )
        self.distribution_1 = distribution_1
        self.distribution_2 = distribution_2
        self.weight = weight

    def _batch_shape(self):
        return tf.broadcast_static_shape(self.distribution_1.batch_shape, self.distribution_2.batch_shape)
    
    def _event_shape(self):
        return tf.broadcast_static_shape(self.distribution_1.event_shape, self.distribution_2.event_shape)
    
    def _batch_shape_tensor(self):
        return tf.broadcast_dynamic_shape(self.distribution_1.batch_shape_tensor(), self.distribution_2.batch_shape_tensor())
    
    def _event_shape_tensor(self):
        return tf.broadcast_dynamic_shape(self.distribution_1.event_shape_tensor(), self.distribution_2.event_shape_tensor())

    def _log_prob(self, x):
        return tf.math.log(self._prob(x))

    def _cdf(self, x):
        return self.weight * self.distribution_1.cdf(x) + (1 - self.weight) * self.distribution_2.cdf(x)
    
    def _prob(self, x):
        return self.weight * self.distribution_1.prob(x) + (1 - self.weight) * self.distribution_2.prob(x)

    def _sample_n(self, n, seed=None):
        """
        We sample from the mixture distribution by sampling from the first distribution with probability `weight` and from the second distribution with probability `1 - weight`.
        We use a soft mask to determine which distribution to sample from, where the mask is generated by sampling from a uniform distribution and applying a sigmoid function.
        We do it this way to ensure that the samples are differentiable with respect to the parameters of the distributions and the weight.

        Args:
        -n (int): The number of samples to generate
        -seed (int): The seed for the random number generator

        Returns:
        -samples (tf.Tensor): The samples from the mixture distribution
        """

        samples_1 = self.distribution_1.sample(n, seed=seed)
        samples_2 = self.distribution_2.sample(n, seed=seed)
        
        uniform_samples = tf.random.uniform([n, self.distribution_1.batch_shape[0]], seed=seed)
        # uniform_samples = tf.random.uniform([n], seed=seed)

        # Create a soft mask using a sigmoid function
        mask = tf.sigmoid((self.weight - uniform_samples) * 10000)

        # mask = tf.reshape(mask, [-1, 1])

        return mask * samples_1 + (1 - mask) * samples_2

        # # This code can be used to check the distribution of the mask
        # lesser = tf.reduce_sum(tf.cast(mask < 0.01, tf.int32)).numpy()
        # greater = tf.reduce_sum(tf.cast(mask > 0.99, tf.int32)).numpy()
        # num_not_in_between = lesser + greater
        # total = n * self.distribution_1.batch_shape[0]
        # ratio = lesser / total


        # return self.mixture.sample(n)
        # return self.weight * self.distribution_1.sample(n) + (1 - self.weight) * self.distribution_2.sample(n)    
    
    def _mean(self):
        return self.weight * self.distribution_1.mean() + (1 - self.weight) * self.distribution_2.mean()
    
    


class TruncGEV(tfp.distributions.Distribution):
    def __init__(self, loc, scale, shape):
        super(TruncGEV, self).__init__(
            dtype=tf.float32,  # The type of the event samples.
            reparameterization_type=tfp.distributions.FULLY_REPARAMETERIZED,  # Indicates that samples can be reparameterized.
            validate_args=False,  # When True distribution parameters are checked for validity despite possibly degrading runtime performance
            allow_nan_stats=True  # When True, statistics (e.g., mean, mode, variance) use the value NaN to indicate the result is undefined.
        )
        
        self._loc = loc
        self._scale = scale
        self._shape = shape
        self._low = tf.zeros_like(loc, dtype=tf.float32)
        self._high = tf.ones_like(loc, dtype=tf.float32) * 1000
        self._gev = tfp.distributions.GeneralizedExtremeValue(loc, scale, shape)

        self.cdf_low = self._gev.cdf(self._low)
        # self.cdf_high = self._gev.cdf(self._high)

    def _log_prob(self, x):
        return self._gev.log_prob(x) - (tf.math.log(1 - self.cdf_low))
    
    def _prob(self, x):
        return self._gev.prob(x) / (1 - self.cdf_low)

    def _cdf(self, x):
        return (self._gev.cdf(x) - self.cdf_low) / (1 - self.cdf_low)
    
    def _sample_n(self, n, seed):
        cdf_0 = self._gev.cdf(self._low)

        # check if cdf_0 contains nan. If it contains nan, replace it with 0 in case self._shape > 0 and with 1 in case self._shape < 0
        cdf_0 = tf.where(tf.math.is_nan(cdf_0), tf.where(self._shape > 0, 0.0, 1.0), cdf_0)

        # generate uniform randomnumbers between cdf_0 and 1
        u = tf.random.uniform([n, self._gev.batch_shape[0]], minval=cdf_0, maxval=1, seed=seed)
        # inverse cdf
        return self._gev.quantile(u)

    def _event_shape(self):
        return tf.TensorShape([])
    
    def _batch_shape(self):
        return tf.broadcast_static_shape(self._loc.shape, self._scale.shape)

    
